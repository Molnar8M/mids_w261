{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#MIDS---w261-Machine-Learning-At-Scale\" data-toc-modified-id=\"MIDS---w261-Machine-Learning-At-Scale-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>MIDS - w261 Machine Learning At Scale</a></div><div class=\"lev2 toc-item\"><a href=\"#Assignment---HW1\" data-toc-modified-id=\"Assignment---HW1-11\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Assignment - HW1</a></div><div class=\"lev2 toc-item\"><a href=\"#INSTRUCTIONS-for-SUBMISSION\" data-toc-modified-id=\"INSTRUCTIONS-for-SUBMISSION-12\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>INSTRUCTIONS for SUBMISSION</a></div><div class=\"lev2 toc-item\"><a href=\"#CONFIGURATION\" data-toc-modified-id=\"CONFIGURATION-13\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>CONFIGURATION</a></div><div class=\"lev1 toc-item\"><a href=\"#HW-1---Questions\" data-toc-modified-id=\"HW-1---Questions-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>HW 1 - Questions</a></div><div class=\"lev2 toc-item\"><a href=\"#HW1.0\" data-toc-modified-id=\"HW1.0-21\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>HW1.0</a></div><div class=\"lev3 toc-item\"><a href=\"#HW1.0.1--Self-Introduction\" data-toc-modified-id=\"HW1.0.1--Self-Introduction-211\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>HW1.0.1  Self-Introduction</a></div><div class=\"lev3 toc-item\"><a href=\"#HW1.0.2.-Big-data\" data-toc-modified-id=\"HW1.0.2.-Big-data-212\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>HW1.0.2. Big data</a></div><div class=\"lev3 toc-item\"><a href=\"#HW1.0.3.--Bias-Variance\" data-toc-modified-id=\"HW1.0.3.--Bias-Variance-213\"><span class=\"toc-item-num\">2.1.3&nbsp;&nbsp;</span>HW1.0.3.  Bias Variance</a></div><div class=\"lev2 toc-item\"><a href=\"#HW1.1-WordCount-using-a-single-thread\" data-toc-modified-id=\"HW1.1-WordCount-using-a-single-thread-22\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>HW1.1 WordCount using a single thread</a></div><div class=\"lev3 toc-item\"><a href=\"#HW1.1.1-How-many-times-does-the-word-alice-occur-in-the-book?\" data-toc-modified-id=\"HW1.1.1-How-many-times-does-the-word-alice-occur-in-the-book?-221\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>HW1.1.1 How many times does the word alice occur in the book?</a></div><div class=\"lev2 toc-item\"><a href=\"#HW1.2-Command-Line-Map-Reduce-Framework\" data-toc-modified-id=\"HW1.2-Command-Line-Map-Reduce-Framework-23\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>HW1.2 Command Line Map Reduce Framework</a></div><div class=\"lev2 toc-item\"><a href=\"#HW1.3-WordCount-via-Command-Line-Map-Reduce-Framework\" data-toc-modified-id=\"HW1.3-WordCount-via-Command-Line-Map-Reduce-Framework-24\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>HW1.3 WordCount via Command Line Map Reduce Framework</a></div><div class=\"lev2 toc-item\"><a href=\"#HW1.4-(OPTIONAL)---Count-words-staring-with-uppercase-and-words-starting-with-lowercase\" data-toc-modified-id=\"HW1.4-(OPTIONAL)---Count-words-staring-with-uppercase-and-words-starting-with-lowercase-25\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>HW1.4 (OPTIONAL) - Count words staring with uppercase and words starting with lowercase</a></div><div class=\"lev2 toc-item\"><a href=\"#HW1.5-(OPTIONAL)---Bias-Variance\" data-toc-modified-id=\"HW1.5-(OPTIONAL)---Bias-Variance-26\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>HW1.5 (OPTIONAL) - Bias-Variance</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIDS - w261 Machine Learning At Scale \n",
    "__Course Lead:__ Dr James G. Shanahan (__email__ Jimi via  James.Shanahan _AT_ gmail.com)\n",
    "\n",
    "## Assignment - HW1\n",
    "Version 2017-08-30 \n",
    "\n",
    "---\n",
    "__Name:__  *Jennifer Casper*   \n",
    "__Class:__ MIDS w261 (Section *Fall 2017 Group 2*)     \n",
    "__Email:__  *jenncasper@berkeley.edu*@iSchool.Berkeley.edu     \n",
    "__StudentId__  123457    __End of StudentId__     \n",
    "__Week:__   1\n",
    "\n",
    "__NOTE:__ please replace `1234567` with your student id above      \n",
    "\n",
    "## INSTRUCTIONS for SUBMISSION\n",
    "\n",
    "HW1 can be completed locally on your computer. __Please submit your notebook to your classroom github repository 24 hours prior to the next live session.__ Your submission should follow the naming and file structure conventions described in the `README.md` for HW1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONFIGURATION \n",
    "Before starting your homework run the following cells to confirm your setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make sure you are in HW1 directory\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# confirm your version of python\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 1 - Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW1.0\n",
    "\n",
    "### HW1.0.1  Self-Introduction\n",
    "W1.0.0 Prepare your bio and include it in this HW submission. Please limit to 100 words. Count the words in your bio and print the length of your bio (in terms of words) in a separate cell.\n",
    "\n",
    "Fill in the following information [Optional]\n",
    "* Your Location \n",
    "* When did you start MIDS  and what is your target finish date\n",
    "* What you want to get out of w261?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# START STUDENT SOLUTION HW1.0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# END STUDENT SOLUTION HW1.0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW1.0.2. Big data\n",
    "Define big data. Provide an example of a big data problem in your domain of expertise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# START STUDENT SOLUTION HW1.0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# END STUDENT SOLUTION HW1.0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW1.0.3.  Bias Variance\n",
    "What is  bias-variance decomposition in the context machine learning? How is it used in machine learning? Please use mathematical equations and/or diagrams to support your explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# START STUDENT SOLUTION HW1.0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# START STUDENT SOLUTION HW1.0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW1.1 WordCount using a single thread  \n",
    "\n",
    "For this homework problem you will write a program called alice_words.py that creates a text file named __alice_words.txt__ containing an alphabetical tab separated listing of all the words and the number of times each occurs, in the text version of Alice’s Adventures in Wonderland. The cells below will guide you though the following steps...\n",
    "* Download the free plain text version of the book from Project Gutenberg([linked here](http://www.gutenberg.org/cache/epub/11/pg11.txt)) \n",
    "* Read through the provided code examples of the `re` module and `defaultDict` python class.\n",
    "* Add your own code to complete the `hw11` function defined inside the file `alice_words.py` which will compute word counts for all the words in the book.\n",
    "* Use the provided code to run your program, save and print your results.The first 10 lines of your output file should look something like this (the counts are not totally precise):\n",
    "<pre>\n",
    "a          690\n",
    "abide      2\n",
    "able       1\n",
    "about      102\n",
    "above      3\n",
    "absence    1\n",
    "absurd     2\n",
    "accept     1\n",
    "acceptance 1\n",
    "accepted   2\n",
    "</pre>\n",
    "\n",
    "* Finally, in __HW 1.1.1__ you will add your own code to complete the `hw111` function defined inside the file `hw111.py` which will extract the number of occurances of a specific word from a provided word counts file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Load the data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !curl 'http://www.gutenberg.org/cache/epub/11/pg11.txt' -o alicesTExtFilename.txt\n",
    "# sometimes the above link produces junk characters. However, the direct link works as expected:\n",
    "!curl 'http://www.gutenberg.org/files/11/11-0.txt' -o alicesTExtFilename.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display the first few lines\n",
    "!head alicesTExtFilename.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__CODE TIP #1:__ run the cell below to see an example of using regular expressions to extract words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example of a regular expression to detect words in a string. \n",
    "import re\n",
    "line = \"\"\" 0017.2000-01-17.beck\t0\t global risk management operations\t\" congratulations, sally!!!  kk  ----------------------forwarded by kathy kokas/corp/enron on 01/17/2000  08:08 pm---------------------------  from: rick causey 01/17/2000 06:04 pm  sent by: enron announcements  to: all enron worldwide  cc:  subject: global risk management operations  recognizing enron \u0001, s increasing worldwide presence in the wholesale energy  business and the need to insure outstanding internal controls for all of our  risk management activities, regardless of location, a global risk management  operations function has been created under the direction of sally w. beck,  vice president. in this role, sally will report to rick causey, executive  vice president and chief accounting officer.  sally \u0001, s responsibilities with regard to global risk management operations  will mirror those of other recently created enron global functions. in this  role, sally will work closely with all enron geographic regions and wholesale  companies to insure that each entity receives individualized regional support  while also focusing on the following global responsibilities:  1. enhance communication among risk management operations professionals.  2. assure the proliferation of best operational practices around the globe.  3. facilitate the allocation of human resources.  4. provide training for risk management operations personnel.  5. coordinate user requirements for shared operational systems.  6. oversee the creation of a global internal control audit plan for risk  management activities.  7. establish procedures for opening new risk management operations offices  and create key benchmarks for measuring on-going risk controls.  each regional operations team will continue its direct reporting relationship  within its business unit, and will collaborate with sally in the delivery of  these critical items. the houston-based risk management operations team under  sue frusco \u0001, s leadership, which currently supports risk management activities  for south america and australia, will also report directly to sally.  sally retains her role as vice president of energy operations for enron  north america, reporting to the ena office of the chairman. she has been in  her current role over energy operations since 1997, where she manages risk  consolidation and reporting, risk management administration, physical product  delivery, confirmations and cash management for ena \u0001, s physical commodity  trading, energy derivatives trading and financial products trading.  sally has been with enron since 1992, when she joined the company as a  manager in global credit. prior to joining enron, sally had four years  experience as a commercial banker and spent seven years as a registered  securities principal with a regional investment banking firm. she also owned  and managed a retail business for several years.  please join me in supporting sally in this additional coordination role for  global risk management operations.\"\"\"\n",
    "re.findall(r'[a-z]+', line.lower()) [0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__CODE TIP #2:__ run the cell below to see an example of using `defaultDict` to count words.\n",
    "\n",
    "> Dictionaries (e.g. `wordCounts={}`) are one way to do word counting but can be annoying to work with.  A defaultdict is like a regular dictionary, except that when you try to look up a key it doesn’t contain, it first adds a value for it using a zero-argument function you provided when you created it. In order to use defaultdicts, you have to import them from the `collections` module. Run the code below to see it in action & refer to the python documentation for more help if you need it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is an example of wordcounting with a defaultdict (dictionary structure with a nice \n",
    "# default behaviours when a key does not exist in the dictionary\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "line = \"\"\" 0017.2000-01-17.beck\t0\t global risk management operations\t\" congratulations, sally!!!  kk  ----------------------forwarded by kathy kokas/corp/enron on 01/17/2000  08:08 pm---------------------------  from: rick causey 01/17/2000 06:04 pm  sent by: enron announcements  to: all enron worldwide  cc:  subject: global risk management operations  recognizing enron \u0001, s increasing worldwide presence in the wholesale energy  business and the need to insure outstanding internal controls for all of our  risk management activities, regardless of location, a global risk management  operations function has been created under the direction of sally w. beck,  vice president. in this role, sally will report to rick causey, executive  vice president and chief accounting officer.  sally \u0001, s responsibilities with regard to global risk management operations  will mirror those of other recently created enron global functions. in this  role, sally will work closely with all enron geographic regions and wholesale  companies to insure that each entity receives individualized regional support  while also focusing on the following global responsibilities:  1. enhance communication among risk management operations professionals.  2. assure the proliferation of best operational practices around the globe.  3. facilitate the allocation of human resources.  4. provide training for risk management operations personnel.  5. coordinate user requirements for shared operational systems.  6. oversee the creation of a global internal control audit plan for risk  management activities.  7. establish procedures for opening new risk management operations offices  and create key benchmarks for measuring on-going risk controls.  each regional operations team will continue its direct reporting relationship  within its business unit, and will collaborate with sally in the delivery of  these critical items. the houston-based risk management operations team under  sue frusco \u0001, s leadership, which currently supports risk management activities  for south america and australia, will also report directly to sally.  sally retains her role as vice president of energy operations for enron  north america, reporting to the ena office of the chairman. she has been in  her current role over energy operations since 1997, where she manages risk  consolidation and reporting, risk management administration, physical product  delivery, confirmations and cash management for ena \u0001, s physical commodity  trading, energy derivatives trading and financial products trading.  sally has been with enron since 1992, when she joined the company as a  manager in global credit. prior to joining enron, sally had four years  experience as a commercial banker and spent seven years as a registered  securities principal with a regional investment banking firm. she also owned  and managed a retail business for several years.  please join me in supporting sally in this additional coordination role for  global risk management operations.\"\"\"\n",
    "wordCounts=defaultdict(int)\n",
    "for word in re.findall(r'[a-z]+', line.lower()):\n",
    "    wordCounts[word] += 1\n",
    "for key in sorted(wordCounts)[0:10]:\n",
    "    print (key, wordCounts[key])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Fill in the code block below, then execute the cell as well as the cell below it.__    \n",
    "\n",
    "<i>This will write a file named alice_words.py and run it.</i>\n",
    "\n",
    "__The output per line should be a tab separated key-value pair with the following format WORD TAB count:__\n",
    "<pre>\n",
    "a          2333333\n",
    "abide      2\n",
    "able       1\n",
    "about      102\n",
    "above      3\n",
    "absence    1\n",
    "absurd     2\n",
    "accept     1\n",
    "acceptance 1\n",
    "accepted   2\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile alice_words.py\n",
    "import re\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "\n",
    "pathToFile = sys.argv[1]\n",
    "wordCounts = defaultdict(int)\n",
    "\n",
    "\n",
    "def hw11(pathToFile):\n",
    "    # takes the path to the file as command line argument\n",
    "    # prints sorted tab separated list of words and counts\n",
    "    # ex) print word,'\\t',count\n",
    "    # returns sorted list of tuples of words and counts: wordList\n",
    "    # ex) wordList = [('a', 690),('abide', 2),...]\n",
    "  \n",
    "    wordList = []\n",
    "\n",
    "    # START STUDENT CODE HW1.1\n",
    "  \n",
    "\n",
    "    # END STUDENT CODE HW1.1\n",
    "  \n",
    "    return wordList\n",
    "\n",
    "hw11(pathToFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python alice_words.py 'alicesTExtFilename.txt' > alice_words.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Pretty print top 10 results from alice_words.txt__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#str.format() is a handy funcion for human friendly pretty printing:\n",
    "#Examples: https://docs.python.org/2/library/string.html#format-examples\n",
    "print '{:15}{}'.format('Word', 'Count')\n",
    "print '='*20\n",
    "\n",
    "with open(\"alice_words.txt\") as f:\n",
    "    idx = 0\n",
    "    for line in f.readlines():\n",
    "        line = line.strip()\n",
    "        word, count = line.split('\\t')\n",
    "        # print the top 10 lines\n",
    "        if idx < 10:\n",
    "            print '{:17}{:3d}'.format(word, int(count))\n",
    "        idx += 1  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW1.1.1 How many times does the word alice occur in the book?\n",
    "_ HINT: read the file with python, or use subprocess to access the commandline from within the python function_\n",
    "\n",
    "__ As before, fill in the code block below, then execute the cell as well as the cell below it. This will write a file named hw111.py and run it.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile hw111.py\n",
    "import re\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "\n",
    "word = sys.argv[1]\n",
    "pathToFile = sys.argv[2]\n",
    "\n",
    "def hw111(word,pathToFile):\n",
    "  # takes a word and the path to the file as arguments\n",
    "  # returns the line containing the word and count\n",
    "  \n",
    "  # START STUDENT CODE HW1.1.1\n",
    "  \n",
    "  \n",
    "  \n",
    "  # END STUDENT CODE HW1.1.1\n",
    "  \n",
    "print hw111(word,pathToFile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python hw111.py 'alice' 'alice_words.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## HW1.2 Command Line Map Reduce Framework\n",
    "\n",
    "For this HW question:\n",
    "* Read through the provided mapreduce shell script (pWordCount.sh) provided below and all of its comments. When you are comfortable with their purpose and function, respond to the remaining homework questions below. \n",
    "* Run all the code blocks.\n",
    "* No need to modify anything in `pWordCount.sh` until you get to HW 1.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile pWordCount.sh\n",
    "#!/bin/bash\n",
    "## pWordCount.sh\n",
    "## Author: James G. Shanahan\n",
    "## Usage: pWordCount.sh m wordlist testFile.txt\n",
    "## Input:\n",
    "##       m = number of processes (maps), e.g., 4\n",
    "##       word = a word in quotes, e.g., \"alice\"\n",
    "##       inputFile = a text input file\n",
    "##\n",
    "###----------------------------------------------------------------------------------------\n",
    "## HW1.2 INSTRUCTIONS: \n",
    "##          Make no changes, just read this script and its comments closely.\n",
    "##          Do your best to understand the purpose of each command, and\n",
    "##          focus on how arguments are supplied to mapper.py/reducer.py,\n",
    "##          as this will determine how the python scripts take input.\n",
    "##\n",
    "## HW1.3 INSTRUCTIONS: \n",
    "##          Modify this script to include shuffle/sort/merge phase, which\n",
    "##          will collate wordCount records with the same key (i.e. word).\n",
    "##          run: man sort to learn more about the linux sort command\n",
    "##          Mark and comment your modifications clearly (eg. ## CHANGE 1 )\n",
    "##\n",
    "###----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "usage()\n",
    "{\n",
    "    echo ERROR: No arguments supplied\n",
    "    echo\n",
    "    echo To run use\n",
    "    echo \"pWordCount.sh m word inputFile\"\n",
    "    echo Input:\n",
    "    echo \"number of processes/maps, EG, 4\"\n",
    "    echo \"word = a word in quotes, e.g., 'alice'\"\n",
    "    echo \"inputFile = a text input file\"\n",
    "}\n",
    "\n",
    "if [ $# -eq 0 ]\n",
    "  then\n",
    "    usage  \n",
    "    exit 1\n",
    "fi\n",
    "    \n",
    "## collect user input\n",
    "m=$1 ## the number of parallel processes (maps) to run\n",
    "word=$2 ## if set to \"*\", then all words are used (HW 1.3)\n",
    "data=$3 ## a text file \n",
    "\n",
    "    \n",
    "## 'wc' determines the number of lines in the data\n",
    "## 'perl -pe' regex strips the piped wc output to a number\n",
    "linesindata=`wc -l $data | perl -pe 's/^.*?(\\d+).*?$/$1/'`\n",
    "\n",
    "## determine the lines per chunk for the desired number of processes\n",
    "linesinchunk=`echo \"$linesindata/$m+1\" | bc`\n",
    "\n",
    "## split the original file into chunks by line\n",
    "split -l $linesinchunk $data $data.chunk.\n",
    "\n",
    "\n",
    "############# ADD HW 1.3 STUDENT MODIFICATIONS BELOW ##############\n",
    "    \n",
    "## assign python mappers (mapper.py) to the chunks of data\n",
    "## and emit their output to temporary files\n",
    "for datachunk in $data.chunk.*; do\n",
    "    ## feed word list to the python mapper here and redirect STDOUT to a temporary file on disk\n",
    "    ./mapper.py  \"$word\" < $datachunk > $datachunk.counts &\n",
    "done\n",
    "## wait for the mappers to finish their work\n",
    "wait\n",
    "\n",
    "    \n",
    "## 'ls' makes a list of the temporary count files\n",
    "## 'perl -pe' regex replaces line breaks with spaces\n",
    "countfiles=`\\ls $data.chunk.*.counts | perl -pe 's/\\n/ /'`\n",
    "\n",
    "## feed the list of countfiles to the python reducer and redirect STDOUT to disk\n",
    "cat $countfiles | ./reducer.py  > $data.output\n",
    "\n",
    "## clean up the data chunks and temporary count files\n",
    "\\rm $data.chunk.*\n",
    "    \n",
    "## display the content of the output file:\n",
    "cat $data.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head pWordCount.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the execution priviledges to make the shell script executable by all\n",
    "!chmod a+x pWordCount.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Test the framework without parameters:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ./pWordCount.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Run the following two cells to generate mapper and reducer files, then run the shell script again with arguments.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile mapper.py\n",
    "#!/usr/bin/python\n",
    "import sys\n",
    "import re\n",
    "count = 0\n",
    "\n",
    "findword = sys.argv[1]\n",
    "for line in sys.stdin:\n",
    "    # count all occurances of the word in each line:\n",
    "    count = count + line.lower().count(findword)\n",
    "print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile reducer.py\n",
    "#!/usr/bin/python\n",
    "## Description: reducer code for HW1.2\n",
    "import sys\n",
    "import re\n",
    "sum = 0\n",
    "\n",
    "for line in sys.stdin:\n",
    "    sum += int(line)\n",
    "\n",
    "print sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Make the files executable:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod a+x mapper.py\n",
    "!chmod a+x reducer.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Test the framework with parameters:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./pWordCount.sh 4 'alice' 'alicesTExtFilename.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## HW1.3 WordCount via Command Line Map Reduce Framework\n",
    "\n",
    "_Think about what would happen if you replaced `'alice'` with `'*'` in the call to `pWordCount.sh` above? Does this behavior make sense for a word counting application?_ For HW1.3 you'll modify the `pWordCount.sh` script in HW1.2 and write a new `mapper.py` & `reducer.py` so that your modified script can perform WordCount on multiple words at a time. Passing `'*'` to your modified script should yield a tab separatated list of all words and their counts. When designing your modifications, __don't forget to add a sort component to your MapReduce framework and leverage the sort order in your reducer (i.e., there will be no need for a sort in reducer.py).__ You may wish to refer to this [notebook](http://nbviewer.jupyter.org/urls/dl.dropbox.com/s/5zq0faibmvtjlbr/DivideAndConquer2-python-Plus-CmdLine.ipynb), or video section 1.12.1 1.12.1 Poor Man's MapReduce Using Command Line (Part 2) located at: \n",
    "https://learn.datascience.berkeley.edu/mod/page/view.php?id=10961\n",
    "\n",
    "To complete this question, make sure of the following:\n",
    "   \n",
    "* Your new mapper.py counts all occurrences of each word in the line.\n",
    "* In the `pWordCount.sh`, please insert a sort command to collate the output key-value pair records by key from the mappers. E.g., sort -k1,1. Use \"man sort\" to learn more about Unix sorts.\n",
    "* Your new reducer.py sums the count value from the collated records for each  word. There should be no sort in the reducer.py\n",
    "\n",
    "Your final output should match the output from __HW1.1.1__ (may vary a bit from the sample below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "a          690\n",
    "abide      2\n",
    "able       1\n",
    "about      102\n",
    "above      3\n",
    "absence    1\n",
    "absurd     2\n",
    "accept     1\n",
    "acceptance 1\n",
    "accepted   2\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile mapper.py\n",
    "#!/usr/bin/python\n",
    "\n",
    "# START STUDENT CODE HW1.3 MAPPER\n",
    "\n",
    "# END STUDENT CODE HW1.3 MAPPER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile reducer.py\n",
    "#!/usr/bin/python\n",
    "\n",
    "# START STUDENT CODE HW1.3 REDUCER\n",
    "\n",
    "# END STUDENT CODE HW1.3 REDUCER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell use the Unix chmod command to change the permissions of the mapper/reducer using the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!chmod +x mapper.py; \n",
    "!chmod +x reducer.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Run the command below with 4 mappers. You should get the same result as in HW1.1.1__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./pWordCount.sh 4 '*' 'alicesTExtFilename.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW1.4 (OPTIONAL) - Count words staring with uppercase and words starting with lowercase\n",
    "\n",
    "Change the mapper.py/reducer.py combination so that you get only the number of words starting with an uppercase letter, and the number of words starting with a lowercase letter for Alice in Wonderland available [here](http://www.gutenberg.org/cache/epub/11/pg11.txt). In other words, you need an output file with only 2 lines, one giving you the number of words staring with a lowercase ('a' to 'z'), and the other line indicating the number of words starting with an uppercase letter ('A' to 'Z'). In the pWordCount.sh, please insert a sort command to collate the output key-value pair records by key from the mappers. E.g., sort -k1,1. Use \"man sort\" to learn more about Unix sorts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# START STUDENT CODE HW1.4\n",
    "\n",
    "# END STUDENT CODE HW1.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW1.5 (OPTIONAL) - Bias-Variance \n",
    "\n",
    "Provide an example of bias variance in action for a similated function y = f(x). E.g., y = sin(x+x^2). Provide code, data, and graphs. \n",
    "\n",
    "Using a bias-variance decomposition analsysis on your choosen problem, describe how you would decide which model to choose when you dont know the true function and how does this choice compare to the choice you made using the true function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# START STUDENT CODE HW1.5\n",
    "\n",
    "# END STUDENT CODE HW1.5"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "297px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_position": {
    "height": "951px",
    "left": "0px",
    "right": "1561px",
    "top": "106px",
    "width": "600px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
