{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    " # Table of Contents\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\" id=\"toc-level0\"><li><span><a href=\"http://localhost:8889/notebooks/media/notebooks/HW5/MIDS-W261-HW-05-PHASE1-3031886443.ipynb#MIDS---w261-Machine-Learning-At-Scale\" data-toc-modified-id=\"MIDS---w261-Machine-Learning-At-Scale-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>MIDS - w261 Machine Learning At Scale</a></span><ul class=\"toc-item\"><li><span><a href=\"http://localhost:8889/notebooks/media/notebooks/HW5/MIDS-W261-HW-05-PHASE1-3031886443.ipynb#Assignment---HW5\" data-toc-modified-id=\"Assignment---HW5-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Assignment - HW5</a></span></li></ul></li><li><span><a href=\"http://localhost:8889/notebooks/media/notebooks/HW5/MIDS-W261-HW-05-PHASE1-3031886443.ipynb#1-Instructions\" data-toc-modified-id=\"1-Instructions-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>1 Instructions</a></span><ul class=\"toc-item\"><ul class=\"toc-item\"><li><span><a href=\"http://localhost:8889/notebooks/media/notebooks/HW5/MIDS-W261-HW-05-PHASE1-3031886443.ipynb#INSTRUCTIONS-for-SUBMISSIONS\" data-toc-modified-id=\"INSTRUCTIONS-for-SUBMISSIONS-2.0.1\"><span class=\"toc-item-num\">2.0.1&nbsp;&nbsp;</span>INSTRUCTIONS for SUBMISSIONS</a></span></li></ul></ul></li><li><span><a href=\"http://localhost:8889/notebooks/media/notebooks/HW5/MIDS-W261-HW-05-PHASE1-3031886443.ipynb#HW-Problems\" data-toc-modified-id=\"HW-Problems-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>HW Problems</a></span><ul class=\"toc-item\"><li><span><a href=\"http://localhost:8889/notebooks/media/notebooks/HW5/MIDS-W261-HW-05-PHASE1-3031886443.ipynb#HW5.0--data-warehouse;-star-schema-(~1hr)\" data-toc-modified-id=\"HW5.0--data-warehouse;-star-schema-(~1hr)-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>HW5.0  data warehouse; star schema (~1hr)</a></span></li><li><span><a href=\"http://localhost:8889/notebooks/media/notebooks/HW5/MIDS-W261-HW-05-PHASE1-3031886443.ipynb#HW5.1-Databases:-3NF;-denormalized-(~1hr)\" data-toc-modified-id=\"HW5.1-Databases:-3NF;-denormalized-(~1hr)-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>HW5.1 Databases: 3NF; denormalized (~1hr)</a></span></li><li><span><a href=\"http://localhost:8889/notebooks/media/notebooks/HW5/MIDS-W261-HW-05-PHASE1-3031886443.ipynb#HW5.2--Memory-backed-map-side-(~12hrs;-~10hrs-for-Altiscale-setup-and-issues)\" data-toc-modified-id=\"HW5.2--Memory-backed-map-side-(~12hrs;-~10hrs-for-Altiscale-setup-and-issues)-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>HW5.2  Memory-backed map-side (~12hrs; ~10hrs for Altiscale setup and issues)</a></span><ul class=\"toc-item\"><li><span><a href=\"http://localhost:8889/notebooks/media/notebooks/HW5/MIDS-W261-HW-05-PHASE1-3031886443.ipynb#Create-input-files:-transactions.dat-and-countries.dat\" data-toc-modified-id=\"Create-input-files:-transactions.dat-and-countries.dat-3.3.1\"><span class=\"toc-item-num\">3.3.1&nbsp;&nbsp;</span>Create input files: transactions.dat and countries.dat</a></span></li><li><span><a href=\"http://localhost:8889/notebooks/media/notebooks/HW5/MIDS-W261-HW-05-PHASE1-3031886443.ipynb#mapsidejoin-class-definition\" data-toc-modified-id=\"mapsidejoin-class-definition-3.3.2\"><span class=\"toc-item-num\">3.3.2&nbsp;&nbsp;</span>mapsidejoin class definition</a></span></li><li><span><a href=\"http://localhost:8889/notebooks/media/notebooks/HW5/MIDS-W261-HW-05-PHASE1-3031886443.ipynb#mapsidejoin-driver-function-definition\" data-toc-modified-id=\"mapsidejoin-driver-function-definition-3.3.3\"><span class=\"toc-item-num\">3.3.3&nbsp;&nbsp;</span>mapsidejoin driver function definition</a></span></li><li><span><a href=\"http://localhost:8889/notebooks/media/notebooks/HW5/MIDS-W261-HW-05-PHASE1-3031886443.ipynb#mapsidejoin-right\" data-toc-modified-id=\"mapsidejoin-right-3.3.4\"><span class=\"toc-item-num\">3.3.4&nbsp;&nbsp;</span>mapsidejoin right</a></span></li><li><span><a href=\"http://localhost:8889/notebooks/media/notebooks/HW5/MIDS-W261-HW-05-PHASE1-3031886443.ipynb#mapsidejoin-inner\" data-toc-modified-id=\"mapsidejoin-inner-3.3.5\"><span class=\"toc-item-num\">3.3.5&nbsp;&nbsp;</span>mapsidejoin inner</a></span></li><li><span><a href=\"http://localhost:8889/notebooks/media/notebooks/HW5/MIDS-W261-HW-05-PHASE1-3031886443.ipynb#mapsidejoin-left\" data-toc-modified-id=\"mapsidejoin-left-3.3.6\"><span class=\"toc-item-num\">3.3.6&nbsp;&nbsp;</span>mapsidejoin left</a></span></li><li><span><a href=\"http://localhost:8889/notebooks/media/notebooks/HW5/MIDS-W261-HW-05-PHASE1-3031886443.ipynb#HW5.2-NOTES\" data-toc-modified-id=\"HW5.2-NOTES-3.3.7\"><span class=\"toc-item-num\">3.3.7&nbsp;&nbsp;</span>HW5.2 NOTES</a></span></li></ul></li><li><span><a href=\"http://localhost:8889/notebooks/media/notebooks/HW5/MIDS-W261-HW-05-PHASE1-3031886443.ipynb#HW5.2.1-(OPTIONAL)-Almost-stateless-reducer-side-join\" data-toc-modified-id=\"HW5.2.1-(OPTIONAL)-Almost-stateless-reducer-side-join-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>HW5.2.1 (OPTIONAL) Almost stateless reducer-side join</a></span></li><li><span><a href=\"http://localhost:8889/notebooks/media/notebooks/HW5/MIDS-W261-HW-05-PHASE1-3031886443.ipynb#5.3-Pairwise-similarity----PHASE-1\" data-toc-modified-id=\"5.3-Pairwise-similarity----PHASE-1-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>5.3 Pairwise similarity  - PHASE 1</a></span><ul class=\"toc-item\"><li><span><a href=\"http://localhost:8889/notebooks/media/notebooks/HW5/MIDS-W261-HW-05-PHASE1-3031886443.ipynb#(1)-Using-the-systems-tests-data-sets,-write-mrjob-code-to-build-the-stripes\" data-toc-modified-id=\"(1)-Using-the-systems-tests-data-sets,-write-mrjob-code-to-build-the-stripes-3.5.1\"><span class=\"toc-item-num\">3.5.1&nbsp;&nbsp;</span>(1) Using the systems tests data sets, write mrjob code to build the stripes</a></span></li><li><span><a href=\"http://localhost:8889/notebooks/media/notebooks/HW5/MIDS-W261-HW-05-PHASE1-3031886443.ipynb#(2)-Write-mrjob-code-to-build-an-inverted-index-from-the-stripes\" data-toc-modified-id=\"(2)-Write-mrjob-code-to-build-an-inverted-index-from-the-stripes-3.5.2\"><span class=\"toc-item-num\">3.5.2&nbsp;&nbsp;</span>(2) Write mrjob code to build an inverted index from the stripes</a></span></li><li><span><a href=\"http://localhost:8889/notebooks/media/notebooks/HW5/MIDS-W261-HW-05-PHASE1-3031886443.ipynb#(3)-Using-two-(symmetric)-comparison-methods-of-your-choice-(e.g.,-correlations,-distances,-similarities),-pairwise-compare-all-stripes-(vectors),-and-output-to-a-file.\" data-toc-modified-id=\"(3)-Using-two-(symmetric)-comparison-methods-of-your-choice-(e.g.,-correlations,-distances,-similarities),-pairwise-compare-all-stripes-(vectors),-and-output-to-a-file.-3.5.3\"><span class=\"toc-item-num\">3.5.3&nbsp;&nbsp;</span>(3) Using two (symmetric) comparison methods of your choice (e.g., correlations, distances, similarities), pairwise compare all stripes (vectors), and output to a file.</a></span></li><li><span><a href=\"http://localhost:8889/notebooks/media/notebooks/HW5/MIDS-W261-HW-05-PHASE1-3031886443.ipynb#prep-the-input-for-buildStripes-(~4hr)\" data-toc-modified-id=\"prep-the-input-for-buildStripes-(~4hr)-3.5.4\"><span class=\"toc-item-num\">3.5.4&nbsp;&nbsp;</span>prep the input for buildStripes (~4hr)</a></span></li><li><span><a href=\"http://localhost:8889/notebooks/media/notebooks/HW5/MIDS-W261-HW-05-PHASE1-3031886443.ipynb#buildStripes.py-(~12hr)\" data-toc-modified-id=\"buildStripes.py-(~12hr)-3.5.5\"><span class=\"toc-item-num\">3.5.5&nbsp;&nbsp;</span>buildStripes.py (~12hr)</a></span></li><li><span><a href=\"http://localhost:8889/notebooks/media/notebooks/HW5/MIDS-W261-HW-05-PHASE1-3031886443.ipynb#invertedIndex.py-(~15hr)\" data-toc-modified-id=\"invertedIndex.py-(~15hr)-3.5.6\"><span class=\"toc-item-num\">3.5.6&nbsp;&nbsp;</span>invertedIndex.py (~15hr)</a></span></li><li><span><a href=\"http://localhost:8889/notebooks/media/notebooks/HW5/MIDS-W261-HW-05-PHASE1-3031886443.ipynb#similarity.py-(~15hr)\" data-toc-modified-id=\"similarity.py-(~15hr)-3.5.7\"><span class=\"toc-item-num\">3.5.7&nbsp;&nbsp;</span>similarity.py (~15hr)</a></span></li></ul></li><li><span><a href=\"http://localhost:8889/notebooks/media/notebooks/HW5/MIDS-W261-HW-05-PHASE1-3031886443.ipynb#HW5.3.1---Run-Systems-tests-locally-on-small-datasets-(PHASE1)\" data-toc-modified-id=\"HW5.3.1---Run-Systems-tests-locally-on-small-datasets-(PHASE1)-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>HW5.3.1   Run Systems tests locally on small datasets (PHASE1)</a></span><ul class=\"toc-item\"><ul class=\"toc-item\"><li><span><a href=\"http://localhost:8889/notebooks/media/notebooks/HW5/MIDS-W261-HW-05-PHASE1-3031886443.ipynb#1:-unit/systems-first-10-lines\" data-toc-modified-id=\"1:-unit/systems-first-10-lines-3.6.0.1\"><span class=\"toc-item-num\">3.6.0.1&nbsp;&nbsp;</span>1: unit/systems first-10-lines</a></span></li><li><span><a href=\"http://localhost:8889/notebooks/media/notebooks/HW5/MIDS-W261-HW-05-PHASE1-3031886443.ipynb#2:-unit/systems-atlas-boon\" data-toc-modified-id=\"2:-unit/systems-atlas-boon-3.6.0.2\"><span class=\"toc-item-num\">3.6.0.2&nbsp;&nbsp;</span>2: unit/systems atlas-boon</a></span></li><li><span><a href=\"http://localhost:8889/notebooks/media/notebooks/HW5/MIDS-W261-HW-05-PHASE1-3031886443.ipynb#3:-unit/systems-stripe-docs-test\" data-toc-modified-id=\"3:-unit/systems-stripe-docs-test-3.6.0.3\"><span class=\"toc-item-num\">3.6.0.3&nbsp;&nbsp;</span>3: unit/systems stripe-docs-test</a></span></li></ul><li><span><a href=\"http://localhost:8889/notebooks/media/notebooks/HW5/MIDS-W261-HW-05-PHASE1-3031886443.ipynb#(1)-build-stripes-for-all-the-test-data-sets---run-the-commands-and-insure-that-your-output-matches-the-output-below\" data-toc-modified-id=\"(1)-build-stripes-for-all-the-test-data-sets---run-the-commands-and-insure-that-your-output-matches-the-output-below-3.6.1\"><span class=\"toc-item-num\">3.6.1&nbsp;&nbsp;</span>(1) build stripes for all the test data sets - run the commands and insure that your output matches the output below</a></span></li><li><span><a href=\"http://localhost:8889/notebooks/media/notebooks/HW5/MIDS-W261-HW-05-PHASE1-3031886443.ipynb#(2)-Build-Inverted-Index---run-the-commands-and-insure-that-your-output-matches-the-output-below\" data-toc-modified-id=\"(2)-Build-Inverted-Index---run-the-commands-and-insure-that-your-output-matches-the-output-below-3.6.2\"><span class=\"toc-item-num\">3.6.2&nbsp;&nbsp;</span>(2) Build Inverted Index - run the commands and insure that your output matches the output below</a></span></li><li><span><a href=\"http://localhost:8889/notebooks/media/notebooks/HW5/MIDS-W261-HW-05-PHASE1-3031886443.ipynb#Inverted-Index\" data-toc-modified-id=\"Inverted-Index-3.6.3\"><span class=\"toc-item-num\">3.6.3&nbsp;&nbsp;</span>Inverted Index</a></span></li><li><span><a href=\"http://localhost:8889/notebooks/media/notebooks/HW5/MIDS-W261-HW-05-PHASE1-3031886443.ipynb#(3)-Calculate-similarities---run-the-commands-and-insure-that-your-output-matches-the-output-below\" data-toc-modified-id=\"(3)-Calculate-similarities---run-the-commands-and-insure-that-your-output-matches-the-output-below-3.6.4\"><span class=\"toc-item-num\">3.6.4&nbsp;&nbsp;</span>(3) Calculate similarities - run the commands and insure that your output matches the output below</a></span><ul class=\"toc-item\"><li><span><a href=\"http://localhost:8889/notebooks/media/notebooks/HW5/MIDS-W261-HW-05-PHASE1-3031886443.ipynb#NOTE:-you-must-run-in-hadoop-mode-to-generate-sorted-similarities\" data-toc-modified-id=\"NOTE:-you-must-run-in-hadoop-mode-to-generate-sorted-similarities-3.6.4.1\"><span class=\"toc-item-num\">3.6.4.1&nbsp;&nbsp;</span>NOTE: you must run in hadoop mode to generate sorted similarities</a></span></li></ul></li><li><span><a href=\"http://localhost:8889/notebooks/media/notebooks/HW5/MIDS-W261-HW-05-PHASE1-3031886443.ipynb#Pairwise-Similairity\" data-toc-modified-id=\"Pairwise-Similairity-3.6.5\"><span class=\"toc-item-num\">3.6.5&nbsp;&nbsp;</span>Pairwise Similairity</a></span></li></ul></li></ul></li><li><span><a href=\"http://localhost:8889/notebooks/media/notebooks/HW5/MIDS-W261-HW-05-PHASE1-3031886443.ipynb#===-END-OF-PHASE-1-===\" data-toc-modified-id=\"===-END-OF-PHASE-1-===-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>=== END OF PHASE 1 ===</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIDS - w261 Machine Learning At Scale\n",
    "__Course Lead:__ Dr James G. Shanahan (__email__ Jimi via  James.Shanahan _AT_ gmail.com)\n",
    "\n",
    "## Assignment - HW5\n",
    "\n",
    "\n",
    "---\n",
    "__Name:__  *Jennifer Casper*   \n",
    "__Class:__ MIDS w261 (Section *Fall 2017 Group 2*)     \n",
    "__Email:__  *jenncasper*@berkeley.edu     \n",
    "__StudentId__  3031886443    __End of StudentId__     \n",
    "__Week:__   5\n",
    "\n",
    "__NOTE:__ please replace `1234567` with your student id above      \n",
    "__Due Time:__ HW is due the Tuesday of the following week by 8AM (West coast time). I.e., Tuesday, Feb 14, 2017 in the case of this homework. \n",
    "\n",
    "* __HW5 Phase 1__ \n",
    "This can be done on a local machine (with a unit test on the cloud such as AltaScale's PaaS or on AWS) and is due Tuesday, Week 6 by 8AM (West coast time). It will primarily focus on building a unit/systems and for pairwise similarity calculations pipeline (for stripe documents)\n",
    "\n",
    "* __HW5 Phase 2__ \n",
    "This will require the Altiscale cluster and will be due Tuesday, Feb 21 by 8AM (West coast time). \n",
    "The focus of  HW5 Phase 2  will be to scale up the unit/systems tests to the Google 5 gram corpus. \n",
    "\n",
    "# 1 Instructions\n",
    "\n",
    "MIDS UC Berkeley, Machine Learning at Scale   \n",
    "DATSCIW261 ASSIGNMENT #5\n",
    "\n",
    "\n",
    "### INSTRUCTIONS for SUBMISSIONS \n",
    "Follow the instructions for submissions carefully.\n",
    "\n",
    "Each student has a `HW-<user>` repository for all assignments.   \n",
    "\n",
    "Push the following to your HW github repo into the master branch:\n",
    "* Your local HW5 directory. Your repo file structure should look like this:\n",
    "\n",
    "```\n",
    "HW-<user>\n",
    "    --HW3\n",
    "       |__MIDS-W261-HW-03-<Student_id>.ipynb\n",
    "       |__MIDS-W261-HW-03-<Student_id>.pdf\n",
    "       |__some other hw3 file\n",
    "    --HW4\n",
    "       |__MIDS-W261-HW-04-<Student_id>.ipynb\n",
    "       |__MIDS-W261-HW-04-<Student_id>.pdf\n",
    "       |__some other hw4 file\n",
    "    etc..\n",
    "```    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW5.0  data warehouse; star schema (~1hr)\n",
    "\n",
    "- What is a data warehouse? What is a Star schema? When is it used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "According to the async, a data warehouse serves as a vast repository of data that provides a foundation for business intelligence and data science. It is a system for reporting and data analysis. Data warehouses may support real time and batch processing. A star schema is a simple schema that consists of one or more fact tables (containing core measurements) that reference any number of dimensional tables. A star schema is core to data marts when serving up views of data to users. It is a core concept for data warehouses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW5.1 Databases: 3NF; denormalized (~1hr)\n",
    "\n",
    "- In the database world What is 3NF? Does machine learning use data in 3NF? If so why? \n",
    "- In what form does ML consume data?\n",
    "- Why would one use log files that are denormalized?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "According to the class slides, 3NF is a property that: 1) no row as multiple values, 2) each row has a primary key, 3) primary key contains multiple columns and non key columns rely on the whole key, and 4) non-key attributes do not depend on other key attributes. 3NF is useful for machine learning remove duplication when bringing together different data from different sources.\n",
    "\n",
    "Data is formed to meet the given ML objective - data may be structured or unstructured.\n",
    "\n",
    "Denormalized, presuming reference to the sync slides image, data with duplicate keys may be used to capture event instances for a user, for instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW5.2  Memory-backed map-side (~12hrs; ~10hrs for Altiscale setup and issues)\n",
    "\n",
    "Using MRJob, implement a hashside join (memory-backed map-side) for left, right and inner joins. Use the following tables for this HW and join based on the country code (third column of the transactions table and the second column of the Countries table:\n",
    "\n",
    "<pre>\n",
    "transactions.dat\n",
    "Alice Bob|$10|US\n",
    "Sam Sneed|$1|CA\n",
    "Jon Sneed|$20|CA\n",
    "Arnold Wesise|$400|UK\n",
    "Henry Bob|$2|US\n",
    "Yo Yo Ma|$2|CA\n",
    "Jon York|$44|CA\n",
    "Alex Ball|$5|UK\n",
    "Jim Davis|$66|JA\n",
    "\n",
    "Countries.dat\n",
    "United States|US\n",
    "Canada|CA\n",
    "United Kingdom|UK\n",
    "Italy|IT\n",
    "\n",
    "</pre>\n",
    "\n",
    "Justify which table you chose as the Left table in this hashside join.\n",
    "\n",
    "Please report the number of rows resulting from:\n",
    "\n",
    "- (1) Left joining Table Left with Table Right\n",
    "- (2) Right joining Table Left with Table Right\n",
    "- (3) Inner joining Table Left with Table Right\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create input files: transactions.dat and countries.dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing transactions.dat\n"
     ]
    }
   ],
   "source": [
    "%%writefile transactions.dat\n",
    "Alice Bob|$10|US\n",
    "Sam Sneed|$1|CA\n",
    "Jon Sneed|$20|CA\n",
    "Arnold Wesise|$400|UK\n",
    "Henry Bob|$2|US\n",
    "Yo Yo Ma|$2|CA\n",
    "Jon York|$44|CA\n",
    "Alex Ball|$5|UK\n",
    "Jim Davis|$66|JA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing countries.dat\n"
     ]
    }
   ],
   "source": [
    "%%writefile countries.dat\n",
    "United States|US\n",
    "Canada|CA\n",
    "United Kingdom|UK\n",
    "Italy|IT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mapsidejoin class definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mapsidejoin.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mapsidejoin.py\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import re\n",
    "import numpy as np\n",
    "from mrjob.compat import jobconf_from_env\n",
    "import os, sys\n",
    "\n",
    "class mapsidejoin(MRJob):\n",
    "    \n",
    "    left_table = {}\n",
    "    left_list = []\n",
    "    join_type = 'right'\n",
    "    \n",
    "    # purpose: define the extra passthrough option for join_type\n",
    "    def configure_options(self): \n",
    "        super(mapsidejoin, self).configure_options() \n",
    "        self.add_passthrough_option('--join-type', dest='join_type', type='str', default='left')\n",
    "    \n",
    "    # purpose: load the options given the join_type configured\n",
    "    def load_options(self, args):\n",
    "        super(mapsidejoin, self).load_options(args)\n",
    "        self.join_type = self.options.join_type\n",
    "    \n",
    "    # purpose: stages needed depending on the join_type\n",
    "    def steps(self):\n",
    "        if self.join_type == 'left':\n",
    "            return [\n",
    "                MRStep(mapper_init = self.mapper_init, \n",
    "                       mapper=self.mapper_left,\n",
    "                       mapper_final = self.mapper_final\n",
    "                )\n",
    "            ]\n",
    "        elif self.join_type == 'inner':\n",
    "            return [\n",
    "                MRStep(mapper_init = self.mapper_init, \n",
    "                       mapper=self.mapper_inner\n",
    "                )\n",
    "            ]\n",
    "        else: \n",
    "            return [\n",
    "                MRStep(mapper_init = self.mapper_init, \n",
    "                       mapper=self.mapper_right\n",
    "                )\n",
    "            ]\n",
    "\n",
    "    # purpose: keep the smaller table in memory within the mapper and reorg for the join key being first\n",
    "    # input: n/a\n",
    "    # output: countries.dat data stored in an in-memory dictionary\n",
    "    def mapper_init(self):\n",
    "        print \"current path:\", os.path.dirname(os.path.realpath(__file__))\n",
    "        self.left_table = {cc:ctry for ctry, cc in (s.split('\\n')[0].split('|') for s in open(\"countries.dat\").readlines())}\n",
    "        self.left_list = self.left_table.keys()\n",
    "        #print self.join_type\n",
    "        #print self.left_table\n",
    "        #print self.left_list\n",
    "    \n",
    "    # purpose: process the right table input lines, keep all the right table lines, and reorder with join key\n",
    "    # input: string line from the transactions.dat file\n",
    "    # output: emit key(cc, 'K' for keep), value(name, dollar, country|None)\n",
    "    def mapper_right(self, _, line):\n",
    "        cc, dollar, name = list(reversed(map(str, line.split('|'))))\n",
    "        if cc in self.left_table:\n",
    "            key = cc\n",
    "            value = (name, dollar, self.left_table[cc])\n",
    "        else:\n",
    "            key = cc\n",
    "            value = (name, dollar, None)\n",
    "        yield (cc,'K'), value\n",
    "\n",
    "    # purpose: process the right table input lines only outputting info from those existing in the left table\n",
    "    # input: string line from the transactions.dat file\n",
    "    # output: emit key(cc, 'K' for keep), value(name, dollar, country)\n",
    "    def mapper_left(self, _, line):\n",
    "        cc, dollar, name = list(reversed(map(str, line.split('|'))))\n",
    "        # check if the cc needs to be removed from the left list\n",
    "        if cc in self.left_list:\n",
    "            self.left_list.remove(cc)\n",
    "        if cc in self.left_table:\n",
    "            yield (cc,'K'), (name, dollar, self.left_table[cc])\n",
    "    \n",
    "    # purpose: process any of the left table records that were not joined with the right table input lines\n",
    "    # input: n/a\n",
    "    # output: emit the records in the left table that were not emitted while processing the right table lines\n",
    "    # note: 'L' included in the key to alert the driver function\n",
    "    def mapper_final(self):\n",
    "        for cc in self.left_list:\n",
    "            yield (cc,'L'), (None, None, self.left_table[cc])\n",
    "        \n",
    "    # purpose: process the right table input lines outputting info from those existing in both tables\n",
    "    # input: string line from the transactions.dat file\n",
    "    # output: emit key(cc, 'K' for keep), value(name, dollar, country)\n",
    "    def mapper_inner(self, _, line):\n",
    "        cc, dollar, name = list(reversed(map(str, line.split('|'))))\n",
    "        if cc in self.left_table:\n",
    "            yield (cc,'K'), (name, dollar, self.left_table[cc])\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    mapsidejoin.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\r\n",
      "Creating temp directory /tmp/mapsidejoin.jenncasper.20171001.164040.007037\r\n",
      "Running step 1 of 1...\r\n",
      "current path: /home/jenncasper/HW5\r\n",
      "current path: /home/jenncasper/HW5\r\n",
      "Streaming final output from /tmp/mapsidejoin.jenncasper.20171001.164040.007037/output...\r\n",
      "[\"US\",\"K\"]\t[\"Alice Bob\",\"$10\",\"United States\"]\r\n",
      "[\"CA\",\"K\"]\t[\"Sam Sneed\",\"$1\",\"Canada\"]\r\n",
      "[\"CA\",\"K\"]\t[\"Jon Sneed\",\"$20\",\"Canada\"]\r\n",
      "[\"UK\",\"K\"]\t[\"Arnold Wesise\",\"$400\",\"United Kingdom\"]\r\n",
      "[\"US\",\"K\"]\t[\"Henry Bob\",\"$2\",\"United States\"]\r\n",
      "[\"CA\",\"K\"]\t[\"Yo Yo Ma\",\"$2\",\"Canada\"]\r\n",
      "[\"CA\",\"K\"]\t[\"Jon York\",\"$44\",\"Canada\"]\r\n",
      "[\"UK\",\"K\"]\t[\"Alex Ball\",\"$5\",\"United Kingdom\"]\r\n",
      "Removing temp directory /tmp/mapsidejoin.jenncasper.20171001.164040.007037...\r\n"
     ]
    }
   ],
   "source": [
    "# test the mapsidejoin class with the additional join-type passthrough parameter\n",
    "!python mapsidejoin.py transactions.dat --join-type='inner' --file=countries.dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mapsidejoin driver function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting hw52_driver.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile hw52_driver.py\n",
    "from mapsidejoin import mapsidejoin\n",
    "import sys\n",
    "\n",
    "def main(argv):\n",
    "    if len(argv) != 1:\n",
    "        print 'hw52_driver.py <\\'inner\\',\\'right\\',\\'left >'\n",
    "        sys.exit(2)\n",
    "    mapsidejoin_driver(str(argv[0]))\n",
    "    \n",
    "def mapsidejoin_driver(join_type):   \n",
    "    count = 0\n",
    "    prev_key = None\n",
    "    mr_job = mapsidejoin(args=['transactions.dat', '--join-type', join_type, '--file', 'countries.dat']) \n",
    "    with mr_job.make_runner() as runner: \n",
    "        runner.run() \n",
    "        print \"\\nMapSideJoin Outputs:\" \n",
    "        for line in sorted(runner.stream_output()): \n",
    "            key, value = mr_job.parse_output_line(line) \n",
    "            #print key, value\n",
    "            \n",
    "            # drop unneccessary artifacts of mapside left join\n",
    "            if join_type == 'left' and key[0] == prev_key and key[1] == 'L': \n",
    "                prev_key = key[0]\n",
    "                prev_value = value\n",
    "                continue\n",
    "            \n",
    "            # count and output the relevant records\n",
    "            prev_key = key[0]               \n",
    "            count += 1\n",
    "            print '%s\\t%s, %s, %s' % (key[0], value[0], value[1], value[2])\n",
    "            \n",
    "    print '\\n%s joining left countries table with right transactions table: %d key-value outputs'  % (join_type, count)\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    main(sys.argv[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hw52_driver.py <'inner','right','left >\r\n"
     ]
    }
   ],
   "source": [
    "# test the driver function\n",
    "!python hw52_driver.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mapsidejoin right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current path: /home/jenncasper/HW5\r\n",
      "current path: /home/jenncasper/HW5\r\n",
      "\r\n",
      "MapSideJoin Outputs:\r\n",
      "CA\tJon Sneed, $20, Canada\r\n",
      "CA\tJon York, $44, Canada\r\n",
      "CA\tSam Sneed, $1, Canada\r\n",
      "CA\tYo Yo Ma, $2, Canada\r\n",
      "JA\tJim Davis, $66, None\r\n",
      "UK\tAlex Ball, $5, United Kingdom\r\n",
      "UK\tArnold Wesise, $400, United Kingdom\r\n",
      "US\tAlice Bob, $10, United States\r\n",
      "US\tHenry Bob, $2, United States\r\n",
      "\r\n",
      "right joining left countries table with right transactions table: 9 key-value outputs\r\n"
     ]
    }
   ],
   "source": [
    "!python hw52_driver.py 'right'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mapsidejoin inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current path: /home/jenncasper/HW5\r\n",
      "current path: /home/jenncasper/HW5\r\n",
      "\r\n",
      "MapSideJoin Outputs:\r\n",
      "CA\tJon Sneed, $20, Canada\r\n",
      "CA\tJon York, $44, Canada\r\n",
      "CA\tSam Sneed, $1, Canada\r\n",
      "CA\tYo Yo Ma, $2, Canada\r\n",
      "UK\tAlex Ball, $5, United Kingdom\r\n",
      "UK\tArnold Wesise, $400, United Kingdom\r\n",
      "US\tAlice Bob, $10, United States\r\n",
      "US\tHenry Bob, $2, United States\r\n",
      "\r\n",
      "inner joining left countries table with right transactions table: 8 key-value outputs\r\n"
     ]
    }
   ],
   "source": [
    "!python hw52_driver.py 'inner'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mapsidejoin left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current path: /home/jenncasper/HW5\r\n",
      "current path: /home/jenncasper/HW5\r\n",
      "\r\n",
      "MapSideJoin Outputs:\r\n",
      "CA\tJon Sneed, $20, Canada\r\n",
      "CA\tJon York, $44, Canada\r\n",
      "CA\tSam Sneed, $1, Canada\r\n",
      "CA\tYo Yo Ma, $2, Canada\r\n",
      "IT\tNone, None, Italy\r\n",
      "UK\tAlex Ball, $5, United Kingdom\r\n",
      "UK\tArnold Wesise, $400, United Kingdom\r\n",
      "US\tAlice Bob, $10, United States\r\n",
      "US\tHenry Bob, $2, United States\r\n",
      "\r\n",
      "left joining left countries table with right transactions table: 9 key-value outputs\r\n"
     ]
    }
   ],
   "source": [
    "!python hw52_driver.py 'left'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW5.2 NOTES\n",
    "\n",
    "The smaller of the two tables, countries in this case, is treated as the left table and held in memory, as a dictionary, by each mapper function.\n",
    "\n",
    "The output of the left mapside join is cleaned up in the driver function as the mappers will emit the left table records not referenced and there may be duplicates or irrelevant output being the mappers can't see each other. There is likely a better way of doing this. Perhaps a better way would be to partition input for mappers by country code in both countries and transactions files, then each mapper would have all the info needed to do any of the joins. This method may work for the option 5.2.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW5.2.1 (OPTIONAL) Almost stateless reducer-side join\n",
    "\n",
    "The following MRJob code, implements a reduce-side join for an inner join. The reducer is almost stateless, i.e., uses as little memory as possible. Use the tables from HW5.2 for this HW and join based on the country code (third column of the transactions table and the second column of the Countries table perform. Perform  an left, right, inner joins using the code provided below and report the number of rows resulting from:\n",
    "\n",
    "- (1) Left joining Table Left with Table Right\n",
    "- (2) Right joining Table Left with Table Right\n",
    "- (3) Inner joining Table Left with Table Right\n",
    "\n",
    "Again make smart decisions about which table should be the left table (i.e., crosscheck the code). \n",
    "\n",
    "__Some notes on the code__ \n",
    "Here, the mapper receives its set of input splits either from the transaction table or from the countries table and makes the appropriate transformations: splitting the line into fields, and emitting a key/value. The key is the join key - in this case, the country code field of both sets of records. The mapper knows which file and type of record it is receiving based on the length of the fields. The records it emits contain the join field as the key, which acts as the partitioning key; We use the SORT_VALUES option, which ensures the values are sorted as well. Then, we employ a trick to ensure that for each join key, country records are seen always before transaction records. We achieve this by adding an arbitrary key to the front of the value: 'A' for countries, 'B' for customers. This makes countries sort before customers for each and every join/partition key. After that trick, the join is simply a matter of storing countries ('A' records) and crossing this array with each customer record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, os, re\n",
    "from mrjob.job import MRJob\n",
    "\n",
    "class MRJoin(MRJob):\n",
    "\n",
    "  # Performs secondary sort\n",
    "  SORT_VALUES = True\n",
    "\n",
    "  def mapper(self, _, line):\n",
    "    splits = line.rstrip(\"\\n\").split(\"|\")\n",
    "\n",
    "    if len(splits) == 2: # country data\n",
    "      symbol = 'A' # make country sort before transaction data\n",
    "      country2digit = splits[1]\n",
    "      yield country2digit, [symbol, splits]\n",
    "    else: # person data\n",
    "      symbol = 'B'\n",
    "      country2digit = splits[2]\n",
    "      yield country2digit, [symbol, splits]\n",
    "\n",
    "  def reducer(self, key, values):\n",
    "    countries = [] # should come first, as they are sorted on artificia key 'A'\n",
    "    for value in values:\n",
    "      if value[0] == 'A':\n",
    "        countries.append(value)\n",
    "      if value[0] == 'B':\n",
    "        for country in countries:\n",
    "          yield key, country[1:] + value[1:]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  MRJoin.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Pairwise similarity  - PHASE 1\n",
    "\n",
    "In this part of the assignment we will focus on developing methods for detecting synonyms, using the Google 5-grams dataset. To accomplish this you must script two main tasks using MRJob:\n",
    "\n",
    "\n",
    "### (1) Using the systems tests data sets, write mrjob code to build the stripes\n",
    "### (2) Write mrjob code to build an inverted index from the stripes\n",
    "### (3) Using two (symmetric) comparison methods of your choice (e.g., correlations, distances, similarities), pairwise compare all stripes (vectors), and output to a file.   \n",
    "\n",
    "__==Design notes for (1)== __  \n",
    "For this task you will be able to modify the pattern we used in HW 3.2 (feel free to use the solution as reference). To total the word counts across the n-grams, output the support from the mappers using the total order inversion pattern:\n",
    "\n",
    "<*word,count>   \n",
    "\n",
    "to ensure that the support arrives before the cooccurrences.   \n",
    "\n",
    "In addition to ensuring the determination of the total word counts, the mapper must also output co-occurrence counts for the pairs of words inside of each n-gram. Treat these words as a basket, as we have in HW 3, but count all stripes or pairs in both orders, i.e., count both orderings: (word1,word2), and (word2,word1), to preserve\n",
    "symmetry in our output for (2).\n",
    "\n",
    "__==Design notes for (3)==__   \n",
    "For this task you will have to determine a method of comparison.\n",
    "Here are a few that you might consider:\n",
    "\n",
    " - Jaccard\n",
    " - Cosine similarity\n",
    " - Spearman correlation\n",
    " - Euclidean distance\n",
    " - Taxicab (Manhattan) distance\n",
    " - Shortest path graph distance (a graph, because our data is symmetric!)\n",
    " - Pearson correlation\n",
    " - Kendall correlation\n",
    " ...\n",
    "\n",
    "However, be cautioned that some comparison methods are more difficult to parallelize than others, and do not perform more associations than is necessary, since your choice of association will be symmetric.\n",
    "\n",
    "Please use the inverted index (discussed in live session #5) based pattern to compute the pairwise (term-by-term) similarity matrix. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prep the input for buildStripes (~4hr)\n",
    "\n",
    "Input format: (ngram) \\t (count) \\t (pages_count) \\t (books_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing atlas-boon-systems-test.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile atlas-boon-systems-test.txt\n",
    "atlas boon\t50\t50\t50\n",
    "boon cava dipped\t10\t10\t10\n",
    "atlas dipped\t15\t15\t15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 atlas-boon-systems-test.txt\r\n"
     ]
    }
   ],
   "source": [
    "# fix the newline issue in the input\n",
    "#!cat -e atlas-boon-systems-test.txt\n",
    "#!echo >> atlas-boon-systems-test.txt\n",
    "!wc -l atlas-boon-systems-test.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing googlebooks-eng-all-5gram-20090715-0-filtered-first-10-lines.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile googlebooks-eng-all-5gram-20090715-0-filtered-first-10-lines.txt\n",
    "A BILL FOR ESTABLISHING RELIGIOUS\t59\t59\t54\n",
    "A Biography of General George\t92\t90\t74\n",
    "A Case Study in Government\t102\t102\t78\n",
    "A Case Study of Female\t447\t447\t327\n",
    "A Case Study of Limited\t55\t55\t43\n",
    "A Child's Christmas in Wales\t1099\t1061\t866\n",
    "A Circumstantial Narrative of the\t62\t62\t50\n",
    "A City by the Sea\t62\t60\t49\n",
    "A Collection of Fairy Tales\t123\t117\t80\n",
    "A Collection of Forms of\t116\t103\t82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 googlebooks-eng-all-5gram-20090715-0-filtered-first-10-lines.txt\r\n"
     ]
    }
   ],
   "source": [
    "# fix the newline issue in the input\n",
    "#!cat -e googlebooks-eng-all-5gram-20090715-0-filtered-first-10-lines.txt\n",
    "#!echo >> googlebooks-eng-all-5gram-20090715-0-filtered-first-10-lines.txt\n",
    "!wc -l googlebooks-eng-all-5gram-20090715-0-filtered-first-10-lines.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### buildStripes.py (~12hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting buildStripes.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile buildStripes.py\n",
    "#!~/anaconda2/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import division\n",
    "import re\n",
    "import mrjob\n",
    "import json\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import sys, itertools\n",
    "from collections import Counter\n",
    "\n",
    "class MRbuildStripes(MRJob):\n",
    "  \n",
    "    #START SUDENT CODE531_STRIPES\n",
    "  \n",
    "    MRJob.SORT_VALUES = True\n",
    "    \n",
    "    # purpose: only need a mapper to coordinate ngram pairs with the count and reducer to combine   \n",
    "    def steps(self):\n",
    "        # restrict to one reducer so output is sorted; change this later\n",
    "        JOBCONF_STEP = {\n",
    "          \"mapred.reduce.tasks\":1\n",
    "        }\n",
    "        return [\n",
    "            MRStep(jobconf = JOBCONF_STEP,\n",
    "                   mapper=self.mapper,\n",
    "                   reducer=self.reducer,\n",
    "            )\n",
    "        ]\n",
    "    \n",
    "    # purpose: split out the word pair counts for the ngrams\n",
    "    # input: line from ngram input file - ngram \\t count \\t page count \\t book count\n",
    "    # output: key(word in ngram), value(dict of remaining ngram words with counts)\n",
    "    def mapper(self, _, line):\n",
    "        line = line.strip().split('\\t')\n",
    "        # capture the n-gram words\n",
    "        words = line[0].lower().split()        \n",
    "        # capture the count, pages_count, books_count values; only keep the count for use\n",
    "        count = int(line[1:][0])\n",
    "        # handle any ngrams with duplicate words\n",
    "        total_inst = dict(Counter(words))\n",
    "        # init the dictionary for emitting\n",
    "        H = {}\n",
    "        \n",
    "        # note the set will remove duplicate words in the ngram list - how should this be handled?\n",
    "        for subset in itertools.combinations(sorted(set(words)), 2):\n",
    "            # check the first in the pair and only keep the count\n",
    "            if subset[0] not in H.keys():\n",
    "                H[subset[0]] = {}\n",
    "                H[subset[0]][subset[1]] = total_inst[subset[1]] * count\n",
    "            elif subset[1] not in H[subset[0]]:\n",
    "                H[subset[0]][subset[1]] = total_inst[subset[1]] * count\n",
    "            else:\n",
    "                H[subset[0]][subset[1]] += (total_inst[subset[1]] * count)\n",
    "                \n",
    "            # check the second in the pair to capture the symmetry relationship\n",
    "            if subset[1] not in H.keys():\n",
    "                H[subset[1]] = {}\n",
    "                H[subset[1]][subset[0]] = total_inst[subset[1]] * count\n",
    "            elif subset[0] not in H[subset[1]]:\n",
    "                H[subset[1]][subset[0]] = total_inst[subset[1]] * count\n",
    "            else:\n",
    "                H[subset[1]][subset[0]] += (total_inst[subset[1]] * count)\n",
    " \n",
    "        for key in H.keys():\n",
    "            yield key, (H[key])\n",
    "    \n",
    "    # purpose: combine the sorted-by-key mapper outputs into stripes\n",
    "    # input: key(word in ngram), value(dict of remaining ngram words with counts)\n",
    "    # output: key(word in ngram), value(dict of remaining ngram words with total counts)\n",
    "    def reducer(self, key, value):\n",
    "        d = Counter()\n",
    "        for item in value:\n",
    "            item = {k:int(v) for k, v in item.iteritems()}\n",
    "            d = d + Counter(item)\n",
    "        yield key, dict(d)\n",
    "        \n",
    "    #END SUDENT CODE531_STRIPES\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRbuildStripes.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\r\n",
      "ignoring partitioner keyword arg (requires real Hadoop): 'org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner'\r\n",
      "Creating temp directory /tmp/buildStripes.jenncasper.20171004.161022.577308\r\n",
      "Running step 1 of 1...\r\n",
      "Streaming final output from /tmp/buildStripes.jenncasper.20171004.161022.577308/output...\r\n",
      "\"atlas\"\t{\"dipped\":15,\"boon\":50}\r\n",
      "\"boon\"\t{\"atlas\":50,\"dipped\":10,\"cava\":10}\r\n",
      "\"cava\"\t{\"dipped\":10,\"boon\":10}\r\n",
      "\"dipped\"\t{\"atlas\":15,\"boon\":10,\"cava\":10}\r\n",
      "Removing temp directory /tmp/buildStripes.jenncasper.20171004.161022.577308...\r\n"
     ]
    }
   ],
   "source": [
    "# test using the super small file\n",
    "!python buildStripes.py atlas-boon-systems-test.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"atlas\"   {\"dipped\": 15, \"boon\": 50}   \n",
    "\"boon\"    {\"atlas\": 50, \"dipped\": 10, \"cava\": 10}   \n",
    "\"cava\"    {\"dipped\": 10, \"boon\": 10} \n",
    "\"dipped\"  {\"atlas\": 15, \"boon\": 10, \"cava\": 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\r\n",
      "ignoring partitioner keyword arg (requires real Hadoop): 'org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner'\r\n",
      "Creating temp directory /tmp/buildStripes.jenncasper.20171004.161038.632098\r\n",
      "Running step 1 of 1...\r\n",
      "Streaming final output from /tmp/buildStripes.jenncasper.20171004.161038.632098/output...\r\n",
      "\"a\"\t{\"limited\":55,\"bill\":59,\"female\":447,\"study\":604,\"child's\":1099,\"collection\":239,\"general\":92,\"sea\":62,\"in\":1201,\"establishing\":59,\"religious\":59,\"george\":92,\"biography\":92,\"case\":604,\"city\":62,\"circumstantial\":62,\"fairy\":123,\"for\":59,\"of\":1011,\"tales\":123,\"government\":102,\"by\":62,\"forms\":116,\"narrative\":62,\"wales\":1099,\"the\":124,\"christmas\":1099}\r\n",
      "\"bill\"\t{\"a\":59,\"religious\":59,\"for\":59,\"establishing\":59}\r\n",
      "\"biography\"\t{\"a\":92,\"of\":92,\"george\":92,\"general\":92}\r\n",
      "\"by\"\t{\"a\":62,\"city\":62,\"the\":62,\"sea\":62}\r\n",
      "\"case\"\t{\"a\":604,\"limited\":55,\"female\":447,\"government\":102,\"of\":502,\"study\":604,\"in\":102}\r\n",
      "\"child's\"\t{\"a\":1099,\"wales\":1099,\"christmas\":1099,\"in\":1099}\r\n",
      "\"christmas\"\t{\"a\":1099,\"wales\":1099,\"child's\":1099,\"in\":1099}\r\n",
      "\"circumstantial\"\t{\"a\":62,\"of\":62,\"the\":62,\"narrative\":62}\r\n",
      "\"city\"\t{\"a\":62,\"the\":62,\"by\":62,\"sea\":62}\r\n",
      "\"collection\"\t{\"a\":239,\"forms\":116,\"fairy\":123,\"tales\":123,\"of\":355}\r\n",
      "\"establishing\"\t{\"a\":59,\"bill\":59,\"religious\":59,\"for\":59}\r\n",
      "\"fairy\"\t{\"a\":123,\"of\":123,\"tales\":123,\"collection\":123}\r\n",
      "\"female\"\t{\"a\":447,\"case\":447,\"study\":447,\"of\":447}\r\n",
      "\"for\"\t{\"a\":59,\"bill\":59,\"religious\":59,\"establishing\":59}\r\n",
      "\"forms\"\t{\"a\":116,\"of\":232,\"collection\":116}\r\n",
      "\"general\"\t{\"a\":92,\"of\":92,\"george\":92,\"biography\":92}\r\n",
      "\"george\"\t{\"a\":92,\"of\":92,\"biography\":92,\"general\":92}\r\n",
      "\"government\"\t{\"a\":102,\"case\":102,\"study\":102,\"in\":102}\r\n",
      "\"in\"\t{\"a\":1201,\"case\":102,\"government\":102,\"wales\":1099,\"study\":102,\"child's\":1099,\"christmas\":1099}\r\n",
      "\"limited\"\t{\"a\":55,\"case\":55,\"study\":55,\"of\":55}\r\n",
      "\"narrative\"\t{\"a\":62,\"of\":62,\"the\":62,\"circumstantial\":62}\r\n",
      "\"of\"\t{\"a\":1011,\"case\":502,\"circumstantial\":62,\"fairy\":123,\"limited\":55,\"tales\":123,\"collection\":355,\"general\":92,\"forms\":232,\"female\":447,\"narrative\":62,\"study\":502,\"the\":62,\"george\":92,\"biography\":92}\r\n",
      "\"religious\"\t{\"a\":59,\"bill\":59,\"for\":59,\"establishing\":59}\r\n",
      "\"sea\"\t{\"a\":62,\"city\":62,\"the\":62,\"by\":62}\r\n",
      "\"study\"\t{\"a\":604,\"case\":604,\"in\":102,\"female\":447,\"limited\":55,\"of\":502,\"government\":102}\r\n",
      "\"tales\"\t{\"a\":123,\"of\":123,\"fairy\":123,\"collection\":123}\r\n",
      "\"the\"\t{\"a\":124,\"city\":62,\"circumstantial\":62,\"sea\":62,\"narrative\":62,\"of\":62,\"by\":62}\r\n",
      "\"wales\"\t{\"a\":1099,\"child's\":1099,\"christmas\":1099,\"in\":1099}\r\n",
      "Removing temp directory /tmp/buildStripes.jenncasper.20171004.161038.632098...\r\n"
     ]
    }
   ],
   "source": [
    "# test using the sample file given\n",
    "!python buildStripes.py googlebooks-eng-all-5gram-20090715-0-filtered-first-10-lines.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\r\n",
      "ignoring partitioner keyword arg (requires real Hadoop): 'org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner'\r\n",
      "Creating temp directory /tmp/buildStripes.jenncasper.20171004.161054.324785\r\n",
      "Running step 1 of 1...\r\n",
      "Streaming final output from /tmp/buildStripes.jenncasper.20171004.161054.324785/output...\r\n",
      "\"a\"\t{\"forms\":116,\"of\":232,\"collection\":116}\r\n",
      "\"collection\"\t{\"a\":116,\"forms\":116,\"of\":232}\r\n",
      "\"forms\"\t{\"a\":116,\"of\":232,\"collection\":116}\r\n",
      "\"of\"\t{\"a\":232,\"forms\":232,\"collection\":232}\r\n",
      "Removing temp directory /tmp/buildStripes.jenncasper.20171004.161054.324785...\r\n"
     ]
    }
   ],
   "source": [
    "# test the duplicate ngram word line only\n",
    "!python buildStripes.py googlebooks-eng-all-5gram-20090715-0-filtered-first-10-last-1-lines.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### invertedIndex.py (~15hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting invertedIndex.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile invertedIndex.py\n",
    "#!~/anaconda2/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import division\n",
    "import collections\n",
    "import re\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import itertools\n",
    "import mrjob\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import sys, ast\n",
    "\n",
    "class MRinvertedIndex(MRJob):\n",
    "    \n",
    "    #START SUDENT CODE531_INV_INDEX\n",
    "    \n",
    "    MRJob.SORT_VALUES = True\n",
    "    \n",
    "    def steps(self):\n",
    "        # restrict to one reducer so output is sorted; change this later\n",
    "        JOBCONF_STEP = {\n",
    "          \"mapred.reduce.tasks\":1\n",
    "        }\n",
    "        return [\n",
    "            MRStep(jobconf = JOBCONF_STEP,\n",
    "                    mapper = self.mapper,\n",
    "                   reducer = self.reducer,\n",
    "            )\n",
    "        ]  \n",
    "\n",
    "    # purpose: split out the word pair counts for the ngrams\n",
    "    # input: line from stripes file\n",
    "    # output: key(word in ngram), value(doc and doc lengths)\n",
    "    def mapper(self, _, line):\n",
    "        # splice out the input from the stripes file      \n",
    "        items = line.strip().split('\\t')\n",
    "        doc = items[0].replace(\"\\\"\",\"\")\n",
    "        stripe = ast.literal_eval(items[1])\n",
    "        # determine the ngram length and output\n",
    "        length = len(stripe.keys())\n",
    "        for word, cnt in stripe.iteritems():\n",
    "            yield word, (doc, length)\n",
    "    \n",
    "    # purpose: take the sorted input and prep for output\n",
    "    # input: key(word in ngram), value(doc and doc lengths)\n",
    "    # output: key(word in ngram), value(list of doc and doc lengths)\n",
    "    def reducer(self, word, doc_len_list):\n",
    "        doc_lens = [i for i in doc_len_list]\n",
    "        yield word, doc_lens    \n",
    "\n",
    "    #END SUDENT CODE531_INV_INDEX \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRinvertedIndex.run() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\r\n",
      "ignoring partitioner keyword arg (requires real Hadoop): 'org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner'\r\n",
      "Creating temp directory /tmp/invertedIndex.jenncasper.20171004.161217.067584\r\n",
      "Running step 1 of 1...\r\n",
      "Streaming final output from /tmp/invertedIndex.jenncasper.20171004.161217.067584/output...\r\n",
      "Removing temp directory /tmp/invertedIndex.jenncasper.20171004.161217.067584...\r\n"
     ]
    }
   ],
   "source": [
    "!python invertedIndex.py systems_test_stripes_3 > systems_test_index.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### similarity.py (~15hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting similarity.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile similarity.py\n",
    "#!~/anaconda2/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import division\n",
    "import collections\n",
    "import re\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import itertools\n",
    "import mrjob\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "\n",
    "class MRsimilarity(MRJob):\n",
    "  \n",
    "    #START SUDENT CODE531_SIMILARITY\n",
    "\n",
    "    MRJob.SORT_VALUES = True \n",
    "    \n",
    "    def steps(self):\n",
    "        JOBCONF_STEP1 = {}\n",
    "        JOBCONF_STEP2 = { \n",
    "            ######### IMPORTANT: THIS WILL HAVE NO EFFECT IN -r local MODE. MUST USE -r hadoop FOR SORTING #############\n",
    "            'mapreduce.job.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "            'mapreduce.partition.keycomparator.options':'-k1,1nr',\n",
    "        }\n",
    "        return [MRStep(jobconf = JOBCONF_STEP1,\n",
    "                    mapper = self.mapper_pair_sim,\n",
    "                    reducer = self.reducer_pair_sim,\n",
    "                ),\n",
    "                MRStep(jobconf = JOBCONF_STEP2,\n",
    "                    mapper = None,   \n",
    "                    reducer = self.reducer_sort\n",
    "                )\n",
    "        ]\n",
    "    \n",
    "    # purpose: break apart the doc mappings and calculate a partial similarity for each pair\n",
    "    def mapper_pair_sim(self, _, line):\n",
    "        line = line.strip()\n",
    "        index, posting = line.split(\"\\t\")\n",
    "        posting = json.loads(posting)\n",
    "        \n",
    "        '''\n",
    "        @input: lines (postings) from inverted index\n",
    "         \"blue\" [[\"DocA\", 4], [\"DocC\", 4], [\"DocE\", 3]]\n",
    "        '''\n",
    "        \n",
    "        # build out all of the document pairs for the line\n",
    "        for subset in itertools.combinations(posting, 2):\n",
    "            # output the values necessary for jaccard and similarity calculations\n",
    "            doc1 = subset[0][0]\n",
    "            doc2 = subset[1][0]\n",
    "            # for jaccard\n",
    "            inter_cnt = 1\n",
    "            doc1_len = subset[0][1]\n",
    "            doc2_len = subset[1][1]\n",
    "            # for cosine\n",
    "            product = (1 / math.sqrt(doc1_len)) * (1 / math.sqrt(doc2_len))\n",
    "\n",
    "            yield (doc1, doc2), (inter_cnt, doc1_len, doc2_len, product)\n",
    "\n",
    "\n",
    "    # purpose: sum the partial similarities\n",
    "    def reducer_pair_sim(self, key, value):\n",
    "        \n",
    "        inter_cnt = 0\n",
    "        cosine = 0\n",
    "        d = {}\n",
    "        \n",
    "        # sum for final dist values\n",
    "        final_key = key[0] + ' - ' + key[1]\n",
    "        for i in value:\n",
    "            inter_cnt += i[0]\n",
    "            doc1_len = i[1]\n",
    "            doc2_len = i[2]\n",
    "            cosine += i[3]\n",
    "        jaccard = inter_cnt / (doc1_len + doc2_len - inter_cnt)\n",
    "        # overlap - size of the intersection divided by the smaller of the size of the two sets  \n",
    "        overlap = inter_cnt / min(doc1_len, doc2_len)\n",
    "        # dice - 2 times the intersection divided by the sum of the two set sizes\n",
    "        dice = (2 * inter_cnt) / (doc1_len + doc2_len)\n",
    "        \n",
    "        # similarity value results\n",
    "        d['cosine'] = cosine\n",
    "        d['jaccard'] = jaccard\n",
    "        d['overlap'] = overlap\n",
    "        d['dice'] = dice\n",
    "        \n",
    "        # similarity average\n",
    "        avg = np.mean(d.values())\n",
    "\n",
    "        yield avg, (final_key, d)\n",
    "    \n",
    "    # purpose: sort the final output by the avg or other dist value\n",
    "    def reducer_sort(self, key, value):\n",
    "        for v in value:\n",
    "            yield key, v\n",
    "\n",
    "  #END SUDENT CODE531_SIMILARITY\n",
    "  \n",
    "if __name__ == '__main__':\n",
    "    MRsimilarity.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "ignoring partitioner keyword arg (requires real Hadoop): 'org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner'\n",
      "Creating temp directory /tmp/similarity.jenncasper.20171004.175316.885969\n",
      "Running step 1 of 2...\n",
      "Running step 2 of 2...\n",
      "Streaming final output from /tmp/similarity.jenncasper.20171004.175316.885969/output...\n",
      "0.346721681\t[\"DocB - DocC\",{\"cosine\":0.3535533906,\"dice\":0.3333333333,\"overlap\":0.5,\"jaccard\":0.2}]\n",
      "0.5538613768\t[\"DocA - DocC\",{\"cosine\":0.5773502692,\"dice\":0.5714285714,\"overlap\":0.6666666667,\"jaccard\":0.4}]\n",
      "0.8207908119\t[\"DocA - DocB\",{\"cosine\":0.816496581,\"dice\":0.8,\"overlap\":1.0,\"jaccard\":0.6666666667}]\n",
      "Removing temp directory /tmp/similarity.jenncasper.20171004.175316.885969...\n"
     ]
    }
   ],
   "source": [
    "!python similarity.py -r local systems_test_index.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW5.3.1   Run Systems tests locally on small datasets (PHASE1)\n",
    "\n",
    "Complete 5.3 and systems test using the below test datasets. Phase 2 will focus on the entire Ngram dataset.\n",
    "\n",
    "To help you through these tasks please verify that your code gives the results below (for stripes, inverted index, and pairwise similarities).\n",
    "\n",
    "Test datasets:\n",
    "\n",
    "* googlebooks-eng-all-5gram-20090715-0-filtered.txt [see below]\n",
    "* atlas-boon-test [see below]\n",
    "* stripe-docs-test [see below]\n",
    "\n",
    "\n",
    "A large subset of the Google n-grams dataset\n",
    "\n",
    "https://aws.amazon.com/datasets/google-books-ngrams/\n",
    "\n",
    "which we have placed in a bucket/folder on Dropbox and on s3:\n",
    "\n",
    "https://www.dropbox.com/sh/tmqpc4o0xswhkvz/AACUifrl6wrMrlK6a3X3lZ9Ea?dl=0 \n",
    "\n",
    "s3://filtered-5grams/\n",
    "\n",
    "In particular, this bucket contains (~200) files (10Meg each) in the format:\n",
    "\n",
    "\t(ngram) \\t (count) \\t (pages_count) \\t (books_count)\n",
    "\n",
    "The next cell shows the first 10 lines of the googlebooks-eng-all-5gram-20090715-0-filtered.txt file.\n",
    "\n",
    "\n",
    "__DISCLAIMER__: Each record is already a 5-gram. In real life, we would calculate the stripes cooccurrence data from the raw text by windowing over the raw text and not from the 5-gram preprocessed data (as we are doing here).  Calculatating pairs on this 5-gram is a little corrupt as we will be double counting cooccurences. Having said that this exercise can still pull out some simialr terms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1: unit/systems first-10-lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting googlebooks-eng-all-5gram-20090715-0-filtered-first-10-lines.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile googlebooks-eng-all-5gram-20090715-0-filtered-first-10-lines.txt\n",
    "A BILL FOR ESTABLISHING RELIGIOUS\t59\t59\t54\n",
    "A Biography of General George\t92\t90\t74\n",
    "A Case Study in Government\t102\t102\t78\n",
    "A Case Study of Female\t447\t447\t327\n",
    "A Case Study of Limited\t55\t55\t43\n",
    "A Child's Christmas in Wales\t1099\t1061\t866\n",
    "A Circumstantial Narrative of the\t62\t62\t50\n",
    "A City by the Sea\t62\t60\t49\n",
    "A Collection of Fairy Tales\t123\t117\t80\n",
    "A Collection of Forms of\t116\t103\t82"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2: unit/systems atlas-boon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting atlas-boon-systems-test.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile atlas-boon-systems-test.txt\n",
    "atlas boon\t50\t50\t50\n",
    "boon cava dipped\t10\t10\t10\n",
    "atlas dipped\t15\t15\t15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3: unit/systems stripe-docs-test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three terms, A,B,C and their corresponding stripe-docs of co-occurring terms\n",
    "\n",
    "- DocA {X:20, Y:30, Z:5}\n",
    "- DocB {X:100, Y:20}\n",
    "- DocC {M:5, N:20, Z:5}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) build stripes for all the test data sets - run the commands and insure that your output matches the output below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "ignoring partitioner keyword arg (requires real Hadoop): 'org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner'\n",
      "Creating temp directory /tmp/buildStripes.jenncasper.20171004.162650.079176\n",
      "Running step 1 of 1...\n",
      "Streaming final output from /tmp/buildStripes.jenncasper.20171004.162650.079176/output...\n",
      "Removing temp directory /tmp/buildStripes.jenncasper.20171004.162650.079176...\n"
     ]
    }
   ],
   "source": [
    "###########################################################################\n",
    "# Make Stripes from ngrams for systems test 1\n",
    "###########################################################################\n",
    "\n",
    "#!hdfs dfs rm --recursive systems_test_stripes_1\n",
    "!python buildStripes.py -r local googlebooks-eng-all-5gram-20090715-0-filtered-first-10-lines.txt > systems_test_stripes_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"a\"\t{\"limited\":55,\"bill\":59,\"female\":447,\"study\":604,\"child's\":1099,\"collection\":239,\"general\":92,\"sea\":62,\"in\":1201,\"establishing\":59,\"religious\":59,\"george\":92,\"biography\":92,\"case\":604,\"city\":62,\"circumstantial\":62,\"fairy\":123,\"for\":59,\"of\":1011,\"tales\":123,\"government\":102,\"by\":62,\"forms\":116,\"narrative\":62,\"wales\":1099,\"the\":124,\"christmas\":1099}\r\n",
      "\"bill\"\t{\"a\":59,\"religious\":59,\"for\":59,\"establishing\":59}\r\n",
      "\"biography\"\t{\"a\":92,\"of\":92,\"george\":92,\"general\":92}\r\n",
      "\"by\"\t{\"a\":62,\"city\":62,\"the\":62,\"sea\":62}\r\n",
      "\"case\"\t{\"a\":604,\"limited\":55,\"female\":447,\"government\":102,\"of\":502,\"study\":604,\"in\":102}\r\n",
      "\"child's\"\t{\"a\":1099,\"wales\":1099,\"christmas\":1099,\"in\":1099}\r\n",
      "\"christmas\"\t{\"a\":1099,\"wales\":1099,\"child's\":1099,\"in\":1099}\r\n",
      "\"circumstantial\"\t{\"a\":62,\"of\":62,\"the\":62,\"narrative\":62}\r\n",
      "\"city\"\t{\"a\":62,\"the\":62,\"by\":62,\"sea\":62}\r\n",
      "\"collection\"\t{\"a\":239,\"forms\":116,\"fairy\":123,\"tales\":123,\"of\":355}\r\n",
      "\"establishing\"\t{\"a\":59,\"bill\":59,\"religious\":59,\"for\":59}\r\n",
      "\"fairy\"\t{\"a\":123,\"of\":123,\"tales\":123,\"collection\":123}\r\n",
      "\"female\"\t{\"a\":447,\"case\":447,\"study\":447,\"of\":447}\r\n",
      "\"for\"\t{\"a\":59,\"bill\":59,\"religious\":59,\"establishing\":59}\r\n",
      "\"forms\"\t{\"a\":116,\"of\":232,\"collection\":116}\r\n",
      "\"general\"\t{\"a\":92,\"of\":92,\"george\":92,\"biography\":92}\r\n",
      "\"george\"\t{\"a\":92,\"of\":92,\"biography\":92,\"general\":92}\r\n",
      "\"government\"\t{\"a\":102,\"case\":102,\"study\":102,\"in\":102}\r\n",
      "\"in\"\t{\"a\":1201,\"case\":102,\"government\":102,\"wales\":1099,\"study\":102,\"child's\":1099,\"christmas\":1099}\r\n",
      "\"limited\"\t{\"a\":55,\"case\":55,\"study\":55,\"of\":55}\r\n",
      "\"narrative\"\t{\"a\":62,\"of\":62,\"the\":62,\"circumstantial\":62}\r\n",
      "\"of\"\t{\"a\":1011,\"case\":502,\"circumstantial\":62,\"fairy\":123,\"limited\":55,\"tales\":123,\"collection\":355,\"general\":92,\"forms\":232,\"female\":447,\"narrative\":62,\"study\":502,\"the\":62,\"george\":92,\"biography\":92}\r\n",
      "\"religious\"\t{\"a\":59,\"bill\":59,\"for\":59,\"establishing\":59}\r\n",
      "\"sea\"\t{\"a\":62,\"city\":62,\"the\":62,\"by\":62}\r\n",
      "\"study\"\t{\"a\":604,\"case\":604,\"in\":102,\"female\":447,\"limited\":55,\"of\":502,\"government\":102}\r\n",
      "\"tales\"\t{\"a\":123,\"of\":123,\"fairy\":123,\"collection\":123}\r\n",
      "\"the\"\t{\"a\":124,\"city\":62,\"circumstantial\":62,\"sea\":62,\"narrative\":62,\"of\":62,\"by\":62}\r\n",
      "\"wales\"\t{\"a\":1099,\"child's\":1099,\"christmas\":1099,\"in\":1099}\r\n"
     ]
    }
   ],
   "source": [
    "!cat systems_test_stripes_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "\"a\"\t{\"limited\": 55, \"sea\": 62, \"general\": 92, \"female\": 447, \"in\": 1201, \"religious\": 59, \"george\": 92, \"biography\": 92, \"city\": 62, \"for\": 59, \"tales\": 123, \"child's\": 1099, \"forms\": 116, \"wales\": 1099, \"christmas\": 1099, \"government\": 102, \"collection\": 239, \"by\": 62, \"case\": 604, \"circumstantial\": 62, \"fairy\": 123, \"of\": 1011, \"study\": 604, \"bill\": 59, \"establishing\": 59, \"narrative\": 62, \"the\": 124}\n",
    "\"bill\"\t{\"a\": 59, \"religious\": 59, \"for\": 59, \"establishing\": 59}\n",
    "\"biography\"\t{\"a\": 92, \"of\": 92, \"george\": 92, \"general\": 92}\n",
    "\"by\"\t{\"a\": 62, \"city\": 62, \"the\": 62, \"sea\": 62}\n",
    "\"case\"\t{\"a\": 604, \"limited\": 55, \"government\": 102, \"of\": 502, \"study\": 604, \"female\": 447, \"in\": 102}\n",
    "\"child's\"\t{\"a\": 1099, \"wales\": 1099, \"christmas\": 1099, \"in\": 1099}\n",
    "\"christmas\"\t{\"a\": 1099, \"wales\": 1099, \"in\": 1099, \"child's\": 1099}\n",
    "\"circumstantial\"\t{\"a\": 62, \"of\": 62, \"the\": 62, \"narrative\": 62}\n",
    "\"city\"\t{\"a\": 62, \"the\": 62, \"by\": 62, \"sea\": 62}\n",
    "\"collection\"\t{\"a\": 239, \"of\": 355, \"fairy\": 123, \"tales\": 123, \"forms\": 116}\n",
    "\"establishing\"\t{\"a\": 59, \"bill\": 59, \"religious\": 59, \"for\": 59}\n",
    "\"fairy\"\t{\"a\": 123, \"of\": 123, \"tales\": 123, \"collection\": 123}\n",
    "\"female\"\t{\"a\": 447, \"case\": 447, \"study\": 447, \"of\": 447}\n",
    "\"for\"\t{\"a\": 59, \"bill\": 59, \"religious\": 59, \"establishing\": 59}\n",
    "\"forms\"\t{\"a\": 116, \"of\": 232, \"collection\": 116}\n",
    "\"general\"\t{\"a\": 92, \"of\": 92, \"george\": 92, \"biography\": 92}\n",
    "\"george\"\t{\"a\": 92, \"of\": 92, \"biography\": 92, \"general\": 92}\n",
    "\"government\"\t{\"a\": 102, \"case\": 102, \"study\": 102, \"in\": 102}\n",
    "\"in\"\t{\"a\": 1201, \"case\": 102, \"government\": 102, \"study\": 102, \"child's\": 1099, \"wales\": 1099, \"christmas\": 1099}\n",
    "\"limited\"\t{\"a\": 55, \"case\": 55, \"study\": 55, \"of\": 55}\n",
    "\"narrative\"\t{\"a\": 62, \"of\": 62, \"the\": 62, \"circumstantial\": 62}\n",
    "\"of\"\t{\"a\": 1127, \"case\": 502, \"circumstantial\": 62, \"george\": 92, \"limited\": 55, \"tales\": 123, \"collection\": 471, \"general\": 92, \"forms\": 348, \"female\": 447, \"narrative\": 62, \"study\": 502, \"fairy\": 123, \"the\": 62, \"biography\": 92}\n",
    "\"religious\"\t{\"a\": 59, \"bill\": 59, \"for\": 59, \"establishing\": 59}\n",
    "\"sea\"\t{\"a\": 62, \"city\": 62, \"the\": 62, \"by\": 62}\n",
    "\"study\"\t{\"a\": 604, \"case\": 604, \"limited\": 55, \"government\": 102, \"of\": 502, \"female\": 447, \"in\": 102}\n",
    "\"tales\"\t{\"a\": 123, \"of\": 123, \"fairy\": 123, \"collection\": 123}\n",
    "\"the\"\t{\"a\": 124, \"city\": 62, \"circumstantial\": 62, \"of\": 62, \"sea\": 62, \"narrative\": 62, \"by\": 62}\n",
    "\"wales\"\t{\"a\": 1099, \"in\": 1099, \"christmas\": 1099, \"child's\": 1099}\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "ignoring partitioner keyword arg (requires real Hadoop): 'org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner'\n",
      "Creating temp directory /tmp/buildStripes.jenncasper.20171004.162727.405623\n",
      "Running step 1 of 1...\n",
      "Streaming final output from /tmp/buildStripes.jenncasper.20171004.162727.405623/output...\n",
      "Removing temp directory /tmp/buildStripes.jenncasper.20171004.162727.405623...\n"
     ]
    }
   ],
   "source": [
    "###########################################################################\n",
    "# Make Stripes from ngrams for systems test 2\n",
    "###########################################################################\n",
    "\n",
    "#!hdfs dfs rm --recursive systems_test_stripes_2\n",
    "!python buildStripes.py -r local atlas-boon-systems-test.txt > systems_test_stripes_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"atlas\"\t{\"dipped\":15,\"boon\":50}\r\n",
      "\"boon\"\t{\"atlas\":50,\"dipped\":10,\"cava\":10}\r\n",
      "\"cava\"\t{\"dipped\":10,\"boon\":10}\r\n",
      "\"dipped\"\t{\"atlas\":15,\"boon\":10,\"cava\":10}\r\n"
     ]
    }
   ],
   "source": [
    "!cat systems_test_stripes_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<pre>\n",
    "\"atlas\"   {\"dipped\": 15, \"boon\": 50}   \n",
    "\"boon\"    {\"atlas\": 50, \"dipped\": 10, \"cava\": 10}   \n",
    "\"cava\"    {\"dipped\": 10, \"boon\": 10} \n",
    "\"dipped\"  {\"atlas\": 15, \"boon\": 10, \"cava\": 10}\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"DocA\"\t{\"X\":20, \"Y\":30, \"Z\":5}\r\n",
      "\"DocB\"\t{\"X\":100, \"Y\":20}\r\n",
      "\"DocC\"\t{\"M\":5, \"N\":20, \"Z\":5, \"Y\":1}\r\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "# Stripes for systems test 3 (given, no need to build stripes)\n",
    "########################################################################\n",
    "\n",
    "with open(\"systems_test_stripes_3\", \"w\") as f:\n",
    "    f.writelines([\n",
    "        '\"DocA\"\\t{\"X\":20, \"Y\":30, \"Z\":5}\\n',\n",
    "        '\"DocB\"\\t{\"X\":100, \"Y\":20}\\n',  \n",
    "        '\"DocC\"\\t{\"M\":5, \"N\":20, \"Z\":5, \"Y\":1}\\n'\n",
    "    ])\n",
    "!cat systems_test_stripes_3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Build Inverted Index - run the commands and insure that your output matches the output below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "ignoring partitioner keyword arg (requires real Hadoop): 'org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner'\n",
      "Creating temp directory /tmp/invertedIndex.jenncasper.20171004.162757.547847\n",
      "Running step 1 of 1...\n",
      "Streaming final output from /tmp/invertedIndex.jenncasper.20171004.162757.547847/output...\n",
      "Removing temp directory /tmp/invertedIndex.jenncasper.20171004.162757.547847...\n"
     ]
    }
   ],
   "source": [
    "!python invertedIndex.py -r local systems_test_stripes_1 > systems_test_index_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "ignoring partitioner keyword arg (requires real Hadoop): 'org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner'\n",
      "Creating temp directory /tmp/invertedIndex.jenncasper.20171004.162800.739973\n",
      "Running step 1 of 1...\n",
      "Streaming final output from /tmp/invertedIndex.jenncasper.20171004.162800.739973/output...\n",
      "Removing temp directory /tmp/invertedIndex.jenncasper.20171004.162800.739973...\n"
     ]
    }
   ],
   "source": [
    "!python invertedIndex.py -r local systems_test_stripes_2 > systems_test_index_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "ignoring partitioner keyword arg (requires real Hadoop): 'org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner'\n",
      "Creating temp directory /tmp/invertedIndex.jenncasper.20171004.162803.980040\n",
      "Running step 1 of 1...\n",
      "Streaming final output from /tmp/invertedIndex.jenncasper.20171004.162803.980040/output...\n",
      "Removing temp directory /tmp/invertedIndex.jenncasper.20171004.162803.980040...\n"
     ]
    }
   ],
   "source": [
    "!python invertedIndex.py -r local systems_test_stripes_3 > systems_test_index_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Systems test  1  - Inverted Index\n",
      "\n",
      "             \"a\" |          bill 4 |     biography 4 |            by 4\n",
      "          \"bill\" |            a 27 |  establishing 4 |           for 4\n",
      "     \"biography\" |            a 27 |       general 4 |        george 4\n",
      "            \"by\" |            a 27 |          city 4 |           sea 4\n",
      "          \"case\" |            a 27 |        female 4 |    government 4\n",
      "       \"child's\" |            a 27 |     christmas 4 |            in 7\n",
      "     \"christmas\" |            a 27 |       child's 4 |            in 7\n",
      "\"circumstantial\" |            a 27 |     narrative 4 |           of 15\n",
      "          \"city\" |            a 27 |            by 4 |           sea 4\n",
      "    \"collection\" |            a 27 |         fairy 4 |         forms 3\n",
      "  \"establishing\" |            a 27 |          bill 4 |           for 4\n",
      "         \"fairy\" |            a 27 |    collection 5 |           of 15\n",
      "        \"female\" |            a 27 |          case 7 |           of 15\n",
      "           \"for\" |            a 27 |          bill 4 |  establishing 4\n",
      "         \"forms\" |            a 27 |    collection 5 |           of 15\n",
      "       \"general\" |            a 27 |     biography 4 |        george 4\n",
      "        \"george\" |            a 27 |     biography 4 |       general 4\n",
      "    \"government\" |            a 27 |          case 7 |            in 7\n",
      "            \"in\" |            a 27 |          case 7 |       child's 4\n",
      "       \"limited\" |            a 27 |          case 7 |           of 15\n",
      "     \"narrative\" |            a 27 |circumstantial 4 |           of 15\n",
      "            \"of\" |            a 27 |     biography 4 |          case 7\n",
      "     \"religious\" |            a 27 |          bill 4 |  establishing 4\n",
      "           \"sea\" |            a 27 |            by 4 |          city 4\n",
      "         \"study\" |            a 27 |          case 7 |        female 4\n",
      "         \"tales\" |            a 27 |    collection 5 |         fairy 4\n",
      "           \"the\" |            a 27 |            by 4 |circumstantial 4\n",
      "         \"wales\" |            a 27 |       child's 4 |     christmas 4\n",
      "\n",
      "Systems test  2  - Inverted Index\n",
      "\n",
      "         \"atlas\" |          boon 3 |        dipped 3 |                \n",
      "          \"boon\" |         atlas 2 |          cava 2 |        dipped 3\n",
      "          \"cava\" |          boon 3 |        dipped 3 |                \n",
      "        \"dipped\" |         atlas 2 |          boon 3 |          cava 2\n",
      "\n",
      "Systems test  3  - Inverted Index\n",
      "\n",
      "             \"M\" |          DocC 4 |                 |                \n",
      "             \"N\" |          DocC 4 |                 |                \n",
      "             \"X\" |          DocA 3 |          DocB 2 |                \n",
      "             \"Y\" |          DocA 3 |          DocB 2 |          DocC 4\n",
      "             \"Z\" |          DocA 3 |          DocC 4 |                \n"
     ]
    }
   ],
   "source": [
    "##########################################################\n",
    "# Pretty print systems tests for generating Inverted Index\n",
    "##########################################################\n",
    "\n",
    "import json\n",
    "\n",
    "for i in range(1,4):\n",
    "    print \"\"*90\n",
    "    print \"Systems test \",i,\" - Inverted Index\"\n",
    "    print \"\"*90  \n",
    "    with open(\"systems_test_index_\"+str(i),\"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            word,stripe = line.split(\"\\t\")\n",
    "            stripe = json.loads(stripe)\n",
    "            stripe.extend([[\"\",\"\"] for _ in xrange(3 - len(stripe))])\n",
    "            print \"{0:>16} |{1:>16} |{2:>16} |{3:>16}\".format((word), \n",
    "                                                              stripe[0][0]+\" \"+str(stripe[0][1]), \n",
    "                                                              stripe[1][0]+\" \"+str(stripe[1][1]), \n",
    "                                                              stripe[2][0]+\" \"+str(stripe[2][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverted Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "Systems test  1  - Inverted Index\n",
    "\n",
    "             \"a\" |          bill 4 |     biography 4 |            by 4\n",
    "          \"bill\" |            a 27 |  establishing 4 |           for 4\n",
    "     \"biography\" |            a 27 |       general 4 |        george 4\n",
    "            \"by\" |            a 27 |          city 4 |           sea 4\n",
    "          \"case\" |            a 27 |        female 4 |    government 4\n",
    "       \"child's\" |            a 27 |     christmas 4 |            in 7\n",
    "     \"christmas\" |            a 27 |       child's 4 |            in 7\n",
    "\"circumstantial\" |            a 27 |     narrative 4 |           of 15\n",
    "          \"city\" |            a 27 |            by 4 |           sea 4\n",
    "    \"collection\" |            a 27 |         fairy 4 |         forms 3\n",
    "  \"establishing\" |            a 27 |          bill 4 |           for 4\n",
    "         \"fairy\" |            a 27 |    collection 5 |           of 15\n",
    "        \"female\" |            a 27 |          case 7 |           of 15\n",
    "           \"for\" |            a 27 |          bill 4 |  establishing 4\n",
    "         \"forms\" |            a 27 |    collection 5 |           of 15\n",
    "       \"general\" |            a 27 |     biography 4 |        george 4\n",
    "        \"george\" |            a 27 |     biography 4 |       general 4\n",
    "    \"government\" |            a 27 |          case 7 |            in 7\n",
    "            \"in\" |            a 27 |          case 7 |       child's 4\n",
    "       \"limited\" |            a 27 |          case 7 |           of 15\n",
    "     \"narrative\" |            a 27 |circumstantial 4 |           of 15\n",
    "            \"of\" |            a 27 |     biography 4 |          case 7\n",
    "     \"religious\" |            a 27 |          bill 4 |  establishing 4\n",
    "           \"sea\" |            a 27 |            by 4 |          city 4\n",
    "         \"study\" |            a 27 |          case 7 |        female 4\n",
    "         \"tales\" |            a 27 |    collection 5 |         fairy 4\n",
    "           \"the\" |            a 27 |            by 4 |circumstantial 4\n",
    "         \"wales\" |            a 27 |       child's 4 |     christmas 4\n",
    "\n",
    "Systems test  2  - Inverted Index\n",
    "\n",
    "         \"atlas\" |          boon 3 |        dipped 3 |                \n",
    "          \"boon\" |         atlas 2 |          cava 2 |        dipped 3\n",
    "          \"cava\" |          boon 3 |        dipped 3 |                \n",
    "        \"dipped\" |         atlas 2 |          boon 3 |          cava 2\n",
    "\n",
    "Systems test  3  - Inverted Index\n",
    "\n",
    "             \"M\" |          DocC 4 |                 |                \n",
    "             \"N\" |          DocC 4 |                 |                \n",
    "             \"X\" |          DocA 3 |          DocB 2 |                \n",
    "             \"Y\" |          DocA 3 |          DocB 2 |          DocC 4\n",
    "             \"Z\" |          DocA 3 |          DocC 4 |                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Calculate similarities - run the commands and insure that your output matches the output below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: you must run in hadoop mode to generate sorted similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /tmp/similarity.jenncasper.20171004.175334.514813\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/jenncasper/tmp/mrjob/similarity.jenncasper.20171004.175334.514813/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob6354887940104187298.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1506640654827_0469\n",
      "  Submitted application application_1506640654827_0469\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1506640654827_0469/\n",
      "  Running job: job_1506640654827_0469\n",
      "  Job job_1506640654827_0469 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1506640654827_0469 completed successfully\n",
      "  Output directory: hdfs:///user/jenncasper/tmp/mrjob/similarity.jenncasper.20171004.175334.514813/step-output/0000\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=3330\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=50923\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=4794\n",
      "\t\tFILE: Number of bytes written=408213\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=3702\n",
      "\t\tHDFS: Number of bytes written=50923\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=17857536\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=8798720\n",
      "\t\tTotal time spent by all map tasks (ms)=11626\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=34878\n",
      "\t\tTotal time spent by all reduce tasks (ms)=3437\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=17185\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=11626\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=3437\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2840\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=224\n",
      "\t\tInput split bytes=372\n",
      "\t\tMap input records=28\n",
      "\t\tMap output bytes=31309\n",
      "\t\tMap output materialized bytes=6379\n",
      "\t\tMap output records=673\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1886109696\n",
      "\t\tReduce input groups=378\n",
      "\t\tReduce input records=673\n",
      "\t\tReduce output records=378\n",
      "\t\tReduce shuffle bytes=6379\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=1346\n",
      "\t\tTotal committed heap usage (bytes)=2197291008\n",
      "\t\tVirtual memory (bytes) snapshot=11407896576\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 2 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob1517881531520263092.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1506640654827_0470\n",
      "  Submitted application application_1506640654827_0470\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1506640654827_0470/\n",
      "  Running job: job_1506640654827_0470\n",
      "  Job job_1506640654827_0470 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1506640654827_0470 completed successfully\n",
      "  Output directory: hdfs:///user/jenncasper/tmp/mrjob/similarity.jenncasper.20171004.175334.514813/output\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=76385\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=50923\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=7112\n",
      "\t\tFILE: Number of bytes written=413358\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=76759\n",
      "\t\tHDFS: Number of bytes written=50923\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=16352256\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=8929280\n",
      "\t\tTotal time spent by all map tasks (ms)=10646\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=31938\n",
      "\t\tTotal time spent by all reduce tasks (ms)=3488\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=17440\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=10646\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=3488\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2810\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=239\n",
      "\t\tInput split bytes=374\n",
      "\t\tMap input records=378\n",
      "\t\tMap output bytes=51501\n",
      "\t\tMap output materialized bytes=8390\n",
      "\t\tMap output records=378\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1889079296\n",
      "\t\tReduce input groups=378\n",
      "\t\tReduce input records=378\n",
      "\t\tReduce output records=378\n",
      "\t\tReduce shuffle bytes=8390\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=756\n",
      "\t\tTotal committed heap usage (bytes)=2217738240\n",
      "\t\tVirtual memory (bytes) snapshot=11407601664\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Streaming final output from hdfs:///user/jenncasper/tmp/mrjob/similarity.jenncasper.20171004.175334.514813/output...\n",
      "Removing HDFS temp directory hdfs:///user/jenncasper/tmp/mrjob/similarity.jenncasper.20171004.175334.514813...\n",
      "Removing temp directory /tmp/similarity.jenncasper.20171004.175334.514813...\n"
     ]
    }
   ],
   "source": [
    "!python similarity.py -r hadoop systems_test_index_1 > systems_test_similarities_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /tmp/similarity.jenncasper.20171004.175458.265941\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/jenncasper/tmp/mrjob/similarity.jenncasper.20171004.175458.265941/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob2410471032634375421.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1506640654827_0471\n",
      "  Submitted application application_1506640654827_0471\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1506640654827_0471/\n",
      "  Running job: job_1506640654827_0471\n",
      "  Job job_1506640654827_0471 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1506640654827_0471 completed successfully\n",
      "  Output directory: hdfs:///user/jenncasper/tmp/mrjob/similarity.jenncasper.20171004.175458.265941/step-output/0000\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=236\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=763\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=178\n",
      "\t\tFILE: Number of bytes written=397503\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=608\n",
      "\t\tHDFS: Number of bytes written=763\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=9024000\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=7992320\n",
      "\t\tTotal time spent by all map tasks (ms)=5875\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=17625\n",
      "\t\tTotal time spent by all reduce tasks (ms)=3122\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=15610\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=5875\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=3122\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2510\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=231\n",
      "\t\tInput split bytes=372\n",
      "\t\tMap input records=4\n",
      "\t\tMap output bytes=404\n",
      "\t\tMap output materialized bytes=285\n",
      "\t\tMap output records=8\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1898979328\n",
      "\t\tReduce input groups=6\n",
      "\t\tReduce input records=8\n",
      "\t\tReduce output records=6\n",
      "\t\tReduce shuffle bytes=285\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=16\n",
      "\t\tTotal committed heap usage (bytes)=2350383104\n",
      "\t\tVirtual memory (bytes) snapshot=11412746240\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 2 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob4495081375774699418.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1506640654827_0472\n",
      "  Submitted application application_1506640654827_0472\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1506640654827_0472/\n",
      "  Running job: job_1506640654827_0472\n",
      "  Job job_1506640654827_0472 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1506640654827_0472 completed successfully\n",
      "  Output directory: hdfs:///user/jenncasper/tmp/mrjob/similarity.jenncasper.20171004.175458.265941/output\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=1145\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=763\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=303\n",
      "\t\tFILE: Number of bytes written=398573\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=1519\n",
      "\t\tHDFS: Number of bytes written=763\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=8867328\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=9625600\n",
      "\t\tTotal time spent by all map tasks (ms)=5773\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=17319\n",
      "\t\tTotal time spent by all reduce tasks (ms)=3760\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=18800\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=5773\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=3760\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2500\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=232\n",
      "\t\tInput split bytes=374\n",
      "\t\tMap input records=6\n",
      "\t\tMap output bytes=774\n",
      "\t\tMap output materialized bytes=414\n",
      "\t\tMap output records=6\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1894084608\n",
      "\t\tReduce input groups=6\n",
      "\t\tReduce input records=6\n",
      "\t\tReduce output records=6\n",
      "\t\tReduce shuffle bytes=414\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=12\n",
      "\t\tTotal committed heap usage (bytes)=2213543936\n",
      "\t\tVirtual memory (bytes) snapshot=11412815872\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Streaming final output from hdfs:///user/jenncasper/tmp/mrjob/similarity.jenncasper.20171004.175458.265941/output...\n",
      "Removing HDFS temp directory hdfs:///user/jenncasper/tmp/mrjob/similarity.jenncasper.20171004.175458.265941...\n",
      "Removing temp directory /tmp/similarity.jenncasper.20171004.175458.265941...\n"
     ]
    }
   ],
   "source": [
    "!python similarity.py -r hadoop systems_test_index_2 > systems_test_similarities_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /tmp/similarity.jenncasper.20171004.175622.237358\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/jenncasper/tmp/mrjob/similarity.jenncasper.20171004.175622.237358/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.output.key.comparator.class: mapreduce.job.output.key.comparator.class\n",
      "mapred.text.key.comparator.options: mapreduce.partition.keycomparator.options\n",
      "mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob3744284782311836774.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1506640654827_0473\n",
      "  Submitted application application_1506640654827_0473\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1506640654827_0473/\n",
      "  Running job: job_1506640654827_0473\n",
      "  Job job_1506640654827_0473 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1506640654827_0473 completed successfully\n",
      "  Output directory: hdfs:///user/jenncasper/tmp/mrjob/similarity.jenncasper.20171004.175622.237358/step-output/0000\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=194\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=453\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=138\n",
      "\t\tFILE: Number of bytes written=397374\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=566\n",
      "\t\tHDFS: Number of bytes written=453\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=15770112\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=15224320\n",
      "\t\tTotal time spent by all map tasks (ms)=10267\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=30801\n",
      "\t\tTotal time spent by all reduce tasks (ms)=5947\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=29735\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=10267\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=5947\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2640\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=174\n",
      "\t\tInput split bytes=372\n",
      "\t\tMap input records=5\n",
      "\t\tMap output bytes=245\n",
      "\t\tMap output materialized bytes=196\n",
      "\t\tMap output records=5\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1893195776\n",
      "\t\tReduce input groups=3\n",
      "\t\tReduce input records=5\n",
      "\t\tReduce output records=3\n",
      "\t\tReduce shuffle bytes=196\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=10\n",
      "\t\tTotal committed heap usage (bytes)=2192048128\n",
      "\t\tVirtual memory (bytes) snapshot=11413352448\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 2 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob5820741780800658178.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1506640654827_0474\n",
      "  Submitted application application_1506640654827_0474\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1506640654827_0474/\n",
      "  Running job: job_1506640654827_0474\n",
      "  Job job_1506640654827_0474 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1506640654827_0474 completed successfully\n",
      "  Output directory: hdfs:///user/jenncasper/tmp/mrjob/similarity.jenncasper.20171004.175622.237358/output\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=680\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=453\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=318\n",
      "\t\tFILE: Number of bytes written=398556\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=1054\n",
      "\t\tHDFS: Number of bytes written=453\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=9113088\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=8737280\n",
      "\t\tTotal time spent by all map tasks (ms)=5933\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=17799\n",
      "\t\tTotal time spent by all reduce tasks (ms)=3413\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=17065\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=5933\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=3413\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2600\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=238\n",
      "\t\tInput split bytes=374\n",
      "\t\tMap input records=3\n",
      "\t\tMap output bytes=459\n",
      "\t\tMap output materialized bytes=382\n",
      "\t\tMap output records=3\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1892220928\n",
      "\t\tReduce input groups=3\n",
      "\t\tReduce input records=3\n",
      "\t\tReduce output records=3\n",
      "\t\tReduce shuffle bytes=382\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=6\n",
      "\t\tTotal committed heap usage (bytes)=2215116800\n",
      "\t\tVirtual memory (bytes) snapshot=11409936384\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Streaming final output from hdfs:///user/jenncasper/tmp/mrjob/similarity.jenncasper.20171004.175622.237358/output...\n",
      "Removing HDFS temp directory hdfs:///user/jenncasper/tmp/mrjob/similarity.jenncasper.20171004.175622.237358...\n",
      "Removing temp directory /tmp/similarity.jenncasper.20171004.175622.237358...\n"
     ]
    }
   ],
   "source": [
    "!python similarity.py -r hadoop systems_test_index_3 > systems_test_similarities_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Systems test  1  - Similarity measures\n",
      "\n",
      "   average |                pair |         cosine |        jaccard |        overlap |           dice\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "  1.000000 |    female - limited |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "  0.868292 |       fairy - forms |       0.866025 |       0.750000 |       1.000000 |       0.857143\n",
      "  0.868292 |       forms - tales |       0.866025 |       0.750000 |       1.000000 |       0.857143\n",
      "  0.830357 |        case - study |       0.857143 |       0.750000 |       0.857143 |       0.857143\n",
      "  0.712500 |          bill - for |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "  0.712500 |   christmas - wales |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "  0.712500 |            by - sea |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "  0.712500 |circumstantial - narrative |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "  0.712500 |           by - city |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "  0.712500 |     child's - wales |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "  0.712500 |  biography - george |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "  0.712500 | biography - general |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "  0.712500 | child's - christmas |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "  0.712500 |    bill - religious |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "  0.712500 | bill - establishing |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "  0.712500 |government - limited |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "  0.712500 |  establishing - for |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "  0.712500 |establishing - religious |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "  0.712500 |          city - sea |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "  0.712500 |       fairy - tales |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "  0.712500 | female - government |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "  0.712500 |     for - religious |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "  0.712500 |    general - george |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "  0.698916 |              a - of |       0.695666 |       0.500000 |       0.933333 |       0.666667\n",
      "  0.646872 |  collection - fairy |       0.670820 |       0.500000 |       0.750000 |       0.666667\n",
      "  0.646872 |  collection - tales |       0.670820 |       0.500000 |       0.750000 |       0.666667\n",
      "  0.559350 |          city - the |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "  0.559350 |  government - study |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "  0.559350 |     narrative - the |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "  0.559350 |         female - in |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "  0.559350 |     limited - study |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "  0.559350 |      female - study |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "  0.559350 |          in - wales |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "  0.559350 |     government - in |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "  0.559350 |           sea - the |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "  0.559350 |        in - limited |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "  0.559350 |   case - government |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "  0.559350 |       case - female |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "  0.559350 |        child's - in |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "  0.559350 |            by - the |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "  0.559350 |      case - limited |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "  0.559350 |      christmas - in |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "  0.559350 |circumstantial - the |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "  0.553861 |   biography - forms |       0.577350 |       0.400000 |       0.666667 |       0.571429\n",
      "  0.553861 |circumstantial - forms |       0.577350 |       0.400000 |       0.666667 |       0.571429\n",
      "  0.553861 |     forms - general |       0.577350 |       0.400000 |       0.666667 |       0.571429\n",
      "  0.553861 |      forms - george |       0.577350 |       0.400000 |       0.666667 |       0.571429\n",
      "  0.553861 |     forms - limited |       0.577350 |       0.400000 |       0.666667 |       0.571429\n",
      "  0.553861 |   forms - narrative |       0.577350 |       0.400000 |       0.666667 |       0.571429\n",
      "  0.553861 |      female - forms |       0.577350 |       0.400000 |       0.666667 |       0.571429\n",
      "  0.504099 |  collection - forms |       0.516398 |       0.333333 |       0.666667 |       0.500000\n",
      "  0.477970 |     collection - of |       0.461880 |       0.250000 |       0.800000 |       0.400000\n",
      "  0.465201 |           a - study |       0.436436 |       0.214286 |       0.857143 |       0.352941\n",
      "  0.465201 |            a - case |       0.436436 |       0.214286 |       0.857143 |       0.352941\n",
      "  0.465201 |             a - the |       0.436436 |       0.214286 |       0.857143 |       0.352941\n",
      "  0.465201 |              a - in |       0.436436 |       0.214286 |       0.857143 |       0.352941\n",
      "  0.458333 |circumstantial - city |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |circumstantial - fairy |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |biography - circumstantial |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |   biography - fairy |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |  biography - female |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |circumstantial - female |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |christmas - government |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |circumstantial - general |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |circumstantial - george |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 | biography - limited |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |biography - narrative |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |   biography - tales |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 | by - circumstantial |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |circumstantial - limited |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |      by - narrative |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |circumstantial - sea |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |child's - government |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |circumstantial - tales |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |   narrative - tales |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |     female - george |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |     narrative - sea |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 | general - narrative |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |  george - narrative |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |  female - narrative |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |     limited - tales |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |     fairy - general |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |      female - tales |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |     general - tales |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 | limited - narrative |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |      george - tales |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |    george - limited |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |      fairy - female |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |      fairy - george |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |    city - narrative |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |     fairy - limited |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |   fairy - narrative |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |   general - limited |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |    female - general |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |  government - wales |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.438276 |       forms - study |       0.436436 |       0.250000 |       0.666667 |       0.400000\n",
      "  0.438276 |         forms - the |       0.436436 |       0.250000 |       0.666667 |       0.400000\n",
      "  0.438276 |        case - forms |       0.436436 |       0.250000 |       0.666667 |       0.400000\n",
      "  0.419343 |circumstantial - collection |       0.447214 |       0.285714 |       0.500000 |       0.444444\n",
      "  0.419343 |biography - collection |       0.447214 |       0.285714 |       0.500000 |       0.444444\n",
      "  0.419343 |collection - limited |       0.447214 |       0.285714 |       0.500000 |       0.444444\n",
      "  0.419343 | collection - george |       0.447214 |       0.285714 |       0.500000 |       0.444444\n",
      "  0.419343 |collection - general |       0.447214 |       0.285714 |       0.500000 |       0.444444\n",
      "  0.419343 | collection - female |       0.447214 |       0.285714 |       0.500000 |       0.444444\n",
      "  0.419343 |collection - narrative |       0.447214 |       0.285714 |       0.500000 |       0.444444\n",
      "  0.410147 |     government - of |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "  0.410147 |        general - of |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "  0.410147 |         george - of |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "  0.410147 |          fairy - of |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "  0.410147 |      narrative - of |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "  0.410147 |         female - of |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "  0.410147 |        limited - of |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "  0.410147 |          of - tales |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "  0.410147 |      biography - of |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "  0.410147 | circumstantial - of |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "  0.389610 |           case - in |       0.428571 |       0.272727 |       0.428571 |       0.428571\n",
      "  0.389610 |          in - study |       0.428571 |       0.272727 |       0.428571 |       0.428571\n",
      "  0.386912 |          of - study |       0.390360 |       0.222222 |       0.571429 |       0.363636\n",
      "  0.386912 |           case - of |       0.390360 |       0.222222 |       0.571429 |       0.363636\n",
      "  0.384281 |      a - collection |       0.344265 |       0.142857 |       0.800000 |       0.250000\n",
      "  0.365956 |    case - narrative |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "  0.365956 |     child's - study |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "  0.365956 |   christmas - study |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "  0.365956 |      case - child's |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "  0.365956 |    case - christmas |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "  0.365956 |case - circumstantial |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "  0.365956 |        case - wales |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "  0.365956 |        case - fairy |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "  0.365956 |circumstantial - study |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "  0.365956 |      case - general |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "  0.365956 |       case - george |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "  0.365956 |        case - tales |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "  0.365956 |   biography - study |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "  0.365956 |     biography - the |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "  0.365956 |    biography - case |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "  0.365956 |        george - the |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "  0.365956 |       general - the |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "  0.365956 |     general - study |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "  0.365956 |       study - tales |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "  0.365956 |         tales - the |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "  0.365956 |        female - the |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "  0.365956 |      george - study |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "  0.365956 |       limited - the |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "  0.365956 |   narrative - study |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "  0.365956 |         fairy - the |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "  0.365956 |       fairy - study |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "  0.365956 |       study - wales |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "  0.334842 |            a - bill |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "  0.334842 |           a - wales |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "  0.334842 |           a - tales |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "  0.334842 |             a - sea |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "  0.334842 |       a - religious |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "  0.334842 |       a - narrative |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "  0.334842 |         a - limited |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "  0.334842 |      a - government |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "  0.334842 |          a - george |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "  0.334842 |         a - general |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "  0.334842 |             a - for |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "  0.334842 |          a - female |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "  0.334842 |           a - fairy |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "  0.334842 |    a - establishing |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "  0.334842 |            a - city |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "  0.334842 |  a - circumstantial |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "  0.334842 |       a - christmas |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "  0.334842 |         a - child's |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "  0.334842 |              a - by |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "  0.334842 |       a - biography |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "  0.328008 |          forms - of |       0.298142 |       0.125000 |       0.666667 |       0.222222\n",
      "  0.317849 |  collection - study |       0.338062 |       0.200000 |       0.400000 |       0.333333\n",
      "  0.317849 |    collection - the |       0.338062 |       0.200000 |       0.400000 |       0.333333\n",
      "  0.317849 |   case - collection |       0.338062 |       0.200000 |       0.400000 |       0.333333\n",
      "  0.287991 |            of - the |       0.292770 |       0.157895 |       0.428571 |       0.272727\n",
      "  0.287991 |             in - of |       0.292770 |       0.157895 |       0.428571 |       0.272727\n",
      "  0.273413 |           a - forms |       0.222222 |       0.071429 |       0.666667 |       0.133333\n",
      "  0.271593 |             by - of |       0.258199 |       0.117647 |       0.500000 |       0.210526\n",
      "  0.271593 |           city - of |       0.258199 |       0.117647 |       0.500000 |       0.210526\n",
      "  0.271593 |            of - sea |       0.258199 |       0.117647 |       0.500000 |       0.210526\n",
      "  0.268597 |       forms - wales |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "  0.268597 |        city - forms |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "  0.268597 |   forms - religious |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "  0.268597 |         for - forms |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "  0.268597 |         forms - sea |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "  0.268597 |establishing - forms |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "  0.268597 |  forms - government |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "  0.268597 |   christmas - forms |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "  0.268597 |     child's - forms |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "  0.268597 |        bill - forms |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "  0.268597 |          by - forms |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "  0.255952 |          case - the |       0.285714 |       0.166667 |       0.285714 |       0.285714\n",
      "  0.255952 |         study - the |       0.285714 |       0.166667 |       0.285714 |       0.285714\n",
      "  0.223214 |         sea - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |         sea - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |     general - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |         for - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |         for - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |        city - fairy |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |           for - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 | george - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |      city - general |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |     for - narrative |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |       for - limited |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |   religious - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |    for - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |        for - george |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |       for - general |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |      female - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 | limited - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |       limited - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |        female - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |       tales - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |     limited - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |government - narrative |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |narrative - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |   narrative - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |          city - for |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |        female - for |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |       fairy - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |   city - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |         fairy - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |   fairy - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |      george - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |  george - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |      city - limited |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |  female - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |  fairy - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |    city - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |        george - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |         fairy - for |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |        city - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |establishing - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |     religious - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |establishing - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |       city - female |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |  establishing - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |        city - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |       city - george |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |establishing - narrative |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |establishing - limited |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |establishing - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |establishing - george |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |establishing - general |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |establishing - female |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |establishing - fairy |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 | general - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |       general - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |government - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |    government - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |   religious - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |general - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |  government - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |biography - establishing |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |     by - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |         by - george |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |child's - circumstantial |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |      child's - city |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |child's - establishing |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |     child's - fairy |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |    child's - female |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |       child's - for |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |        by - general |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |   child's - general |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |    child's - george |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |            by - for |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |         by - female |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |          by - fairy |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |   by - establishing |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |          by - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |christmas - circumstantial |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |      by - christmas |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |        by - child's |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |          by - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |   biography - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |    christmas - city |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |christmas - establishing |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |     biography - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |biography - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |   christmas - fairy |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |  christmas - female |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |     christmas - for |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |       child's - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |biography - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 | christmas - general |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |  christmas - george |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |     biography - for |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 | christmas - limited |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |christmas - narrative |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |   child's - limited |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |    biography - city |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |christmas - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |biography - christmas |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 | biography - child's |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |     christmas - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |      biography - by |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |        bill - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 | child's - narrative |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |        bill - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |      by - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |          bill - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |   christmas - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |    bill - narrative |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |      bill - limited |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |   bill - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |       bill - george |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |      bill - general |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |     child's - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |       bill - female |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |        bill - fairy |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |circumstantial - establishing |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |         bill - city |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |bill - circumstantial |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |    bill - christmas |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |      bill - child's |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |        by - limited |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |           bill - by |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |    bill - biography |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |circumstantial - for |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |circumstantial - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |circumstantial - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 | city - establishing |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |circumstantial - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 | child's - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.215666 |          forms - in |       0.218218 |       0.111111 |       0.333333 |       0.200000\n",
      "  0.205207 |  collection - wales |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "  0.205207 |collection - religious |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "  0.205207 |    collection - for |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "  0.205207 |collection - establishing |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "  0.205207 |    collection - sea |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "  0.205207 |collection - government |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "  0.205207 |christmas - collection |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "  0.205207 |child's - collection |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "  0.205207 |   bill - collection |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "  0.205207 |   city - collection |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "  0.205207 |     by - collection |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "  0.180200 |          bill - the |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |          by - study |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |             by - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |       child's - the |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |           by - case |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |      biography - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |        bill - study |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |           bill - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |     christmas - the |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |         bill - case |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 | circumstantial - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |          case - sea |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |    case - religious |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |          case - for |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 | case - establishing |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |         case - city |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |         the - wales |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |         sea - study |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |     religious - the |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |   religious - study |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |          in - tales |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |            in - sea |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |      in - religious |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |      in - narrative |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |    government - the |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |         george - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |        general - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |           for - the |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |            for - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |          fairy - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |  establishing - the |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |establishing - study |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |   establishing - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |        city - study |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |           city - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |         for - study |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.156652 |     collection - in |       0.169031 |       0.090909 |       0.200000 |       0.166667\n",
      "  0.134980 |   establishing - of |       0.129099 |       0.055556 |       0.250000 |       0.105263\n",
      "  0.134980 |            for - of |       0.129099 |       0.055556 |       0.250000 |       0.105263\n",
      "  0.134980 |      of - religious |       0.129099 |       0.055556 |       0.250000 |       0.105263\n",
      "  0.134980 |          of - wales |       0.129099 |       0.055556 |       0.250000 |       0.105263\n",
      "  0.134980 |        child's - of |       0.129099 |       0.055556 |       0.250000 |       0.105263\n",
      "  0.134980 |      christmas - of |       0.129099 |       0.055556 |       0.250000 |       0.105263\n",
      "  0.134980 |           bill - of |       0.129099 |       0.055556 |       0.250000 |       0.105263\n",
      "  0.126374 |            in - the |       0.142857 |       0.076923 |       0.142857 |       0.142857\n",
      "\n",
      "Systems test  2  - Similarity measures\n",
      "\n",
      "   average |                pair |         cosine |        jaccard |        overlap |           dice\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "  1.000000 |        atlas - cava |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "  0.625000 |       boon - dipped |       0.666667 |       0.500000 |       0.666667 |       0.666667\n",
      "  0.389562 |       cava - dipped |       0.408248 |       0.250000 |       0.500000 |       0.400000\n",
      "  0.389562 |         boon - cava |       0.408248 |       0.250000 |       0.500000 |       0.400000\n",
      "  0.389562 |      atlas - dipped |       0.408248 |       0.250000 |       0.500000 |       0.400000\n",
      "  0.389562 |        atlas - boon |       0.408248 |       0.250000 |       0.500000 |       0.400000\n",
      "\n",
      "Systems test  3  - Similarity measures\n",
      "\n",
      "   average |                pair |         cosine |        jaccard |        overlap |           dice\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "  0.820791 |         DocA - DocB |       0.816497 |       0.666667 |       1.000000 |       0.800000\n",
      "  0.553861 |         DocA - DocC |       0.577350 |       0.400000 |       0.666667 |       0.571429\n",
      "  0.346722 |         DocB - DocC |       0.353553 |       0.200000 |       0.500000 |       0.333333\n"
     ]
    }
   ],
   "source": [
    "############################################\n",
    "# Pretty print systems tests\n",
    "############################################\n",
    "\n",
    "import json, ast\n",
    "\n",
    "for i in range(1,4):\n",
    "    print ''*110\n",
    "    print \"Systems test \",i,\" - Similarity measures\"\n",
    "    print ''*110\n",
    "    print \"{0:>10} |{1:>20} |{2:>15} |{3:>15} |{4:>15} |{5:>15}\".format(\n",
    "          \"average\", \"pair\", \"cosine\", \"jaccard\", \"overlap\", \"dice\")\n",
    "    print '-'*110\n",
    "\n",
    "    with open(\"systems_test_similarities_\"+str(i),\"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            avg, stripe = line.split(\"\\t\")\n",
    "            pair, dist_dict = json.loads(stripe)\n",
    "            \n",
    "            print \"{0:>10f} |{1:>20} |{2:>15f} |{3:>15f} |{4:>15f} |{5:>15f}\".format(\n",
    "                float(avg), pair, float(dist_dict['cosine']), float(dist_dict['jaccard']), \n",
    "                float(dist_dict['overlap']), float(dist_dict['dice']))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairwise Similairity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "Systems test  1  - Similarity measures\n",
    "\n",
    "   average |                pair |         cosine |        jaccard |        overlap |           dice\n",
    "--------------------------------------------------------------------------------------------------------------\n",
    "  1.000000 |    female - limited |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
    "  0.868292 |       fairy - forms |       0.866025 |       0.750000 |       1.000000 |       0.857143\n",
    "  0.868292 |       forms - tales |       0.866025 |       0.750000 |       1.000000 |       0.857143\n",
    "  0.830357 |        case - study |       0.857143 |       0.750000 |       0.857143 |       0.857143\n",
    "  0.712500 | bill - establishing |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
    "  0.712500 |   christmas - wales |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
    "  0.712500 |circumstantial - narrative |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
    "  0.712500 |            by - sea |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
    "  0.712500 |           by - city |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
    "  0.712500 |     child's - wales |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
    "  0.712500 |  biography - george |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
    "  0.712500 | child's - christmas |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
    "  ...\n",
    "  \n",
    "\n",
    "Systems test  2  - Similarity measures\n",
    "\n",
    "   average |                pair |         cosine |        jaccard |        overlap |           dice\n",
    "--------------------------------------------------------------------------------------------------------------\n",
    "  1.000000 |        atlas - cava |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
    "  0.625000 |       boon - dipped |       0.666667 |       0.500000 |       0.666667 |       0.666667\n",
    "  0.389562 |       cava - dipped |       0.408248 |       0.250000 |       0.500000 |       0.400000\n",
    "  0.389562 |         boon - cava |       0.408248 |       0.250000 |       0.500000 |       0.400000\n",
    "  0.389562 |      atlas - dipped |       0.408248 |       0.250000 |       0.500000 |       0.400000\n",
    "  0.389562 |        atlas - boon |       0.408248 |       0.250000 |       0.500000 |       0.400000\n",
    "\n",
    "Systems test  3  - Similarity measures\n",
    "\n",
    "   average |                pair |         cosine |        jaccard |        overlap |           dice\n",
    "--------------------------------------------------------------------------------------------------------------\n",
    "  0.820791 |         DocA - DocB |       0.816497 |       0.666667 |       1.000000 |       0.800000\n",
    "  0.553861 |         DocA - DocC |       0.577350 |       0.400000 |       0.666667 |       0.571429\n",
    "  0.346722 |         DocB - DocC |       0.353553 |       0.200000 |       0.500000 |       0.333333\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# === END OF PHASE 1 ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "nav_menu": {
    "height": "512px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": true,
   "toc_position": {
    "height": "644px",
    "left": "0px",
    "right": "995.765625px",
    "top": "110px",
    "width": "387px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
