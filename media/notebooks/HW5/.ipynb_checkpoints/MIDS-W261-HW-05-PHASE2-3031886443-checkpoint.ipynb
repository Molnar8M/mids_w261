{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIDS - w261 Machine Learning At Scale\n",
    "__Course Lead:__ Dr James G. Shanahan (__email__ Jimi via  James.Shanahan _AT_ gmail.com)\n",
    "\n",
    "## Assignment - HW5\n",
    "\n",
    "\n",
    "---\n",
    "__Name:__  *Jennifer Casper*   \n",
    "__Class:__ MIDS w261 (Section Fall 2017 Group 2)     \n",
    "__Email:__  jenncasper@berkeley.edu     \n",
    "__Week:__   5\n",
    "\n",
    "__Due Time:__ 2 Phases. \n",
    "\n",
    "* __HW5 Phase 1__ \n",
    "This can be done on a local machine (with a unit test on the cloud such as AltaScale's PaaS or on AWS) and is due Tuesday, Week 6 by 8AM (West coast time). It will primarily focus on building a unit/systems and for pairwise similarity calculations pipeline (for stripe documents)\n",
    "\n",
    "* __HW5 Phase 2__ \n",
    "This will require the AltaScale cluster and will be due Tuesday, Week 7 by 8AM (West coast time). \n",
    "The focus of  HW5 Phase 2  will be to scale up the unit/systems tests to the Google 5 gram corpus. This will be a group exercise \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents <a name=\"TOC\"></a> \n",
    "\n",
    "1.  [HW Instructions](#1)   \n",
    "2.  [HW References](#2)\n",
    "3.  [HW Problems](#3)   \n",
    "       \n",
    "    5.4.  [HW5.4](#5.4)    \n",
    "    5.5.  [HW5.5](#5.5)    \n",
    "    5.6.  [HW5.6](#5.6)    \n",
    "    5.7.  [HW5.7](#5.7)    \n",
    "    5.8.  [HW5.8](#5.8)    \n",
    "    5.9.  [HW5.9](#5.9)    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"1\"></a>\n",
    "# 1 Instructions\n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "MIDS UC Berkeley, Machine Learning at Scale   \n",
    "DATSCIW261 ASSIGNMENT #5\n",
    "\n",
    "Version 2017-9-2 \n",
    "\n",
    "\n",
    "### IMPORTANT\n",
    "\n",
    "This homework must be completed in the cloud \n",
    "\n",
    "### === INSTRUCTIONS for SUBMISSIONS ===   \n",
    "Follow the instructions for submissions carefully.\n",
    "\n",
    "Each student has a `HW-<user>` repository for all assignments.   \n",
    "\n",
    "Click this link to enable you to create a github repo within the MIDS261 Classroom:   \n",
    "https://classroom.github.com/assignment-invitations/3b1d6c8e58351209f9dd865537111ff8   \n",
    "and follow the instructions to create a HW repo.\n",
    "\n",
    "Push the following to your HW github repo into the master branch:\n",
    "* Your local HW5 directory. Your repo file structure should look like this:\n",
    "\n",
    "```\n",
    "HW-<user>\n",
    "    --HW3\n",
    "       |__MIDS-W261-HW-03-<Student_id>.ipynb\n",
    "       |__MIDS-W261-HW-03-<Student_id>.pdf\n",
    "       |__some other hw3 file\n",
    "    --HW4\n",
    "       |__MIDS-W261-HW-04-<Student_id>.ipynb\n",
    "       |__MIDS-W261-HW-04-<Student_id>.pdf\n",
    "       |__some other hw4 file\n",
    "    etc..\n",
    "```    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2\">\n",
    "# 2 Useful References\n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "* See async and live lectures for this week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"3\">\n",
    "# 3 HW Problems\n",
    "[Back to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"5.4\"></a> \n",
    "# PHASE 2 (~90hrs total)\n",
    "----------\n",
    "\n",
    "# HW 5.4   \n",
    "## Full-scale experiment on Google N-gram data on the CLOUD\n",
    "__ Once you are happy with your test results __ proceed to generating  your results on the Google n-grams dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  HW5.4.0  <a name=\"5.4.0\"></a> Run systems tests on the CLOUD  (PHASE 2) (~10hrs)\n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "Repeat HW5.3.0 (using the same small data sources that were used in HW5.3.0) on ** the cloud** (e.g., AltaScale / AWS/ SoftLayer/ Azure). Make sure all tests give correct results! Good luck out there!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rework buildStripes.py for -r hadoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting buildStripes.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile buildStripes.py\n",
    "#!~/anaconda2/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import division\n",
    "import re\n",
    "import mrjob\n",
    "import json\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import sys, itertools\n",
    "#from collections import Counter\n",
    "from collections import defaultdict\n",
    "\n",
    "class MRbuildStripes(MRJob):\n",
    "  \n",
    "    MRJob.SORT_VALUES = True\n",
    "    \n",
    "    # purpose: only need a mapper to coordinate ngram pairs with the count and reducer to combine   \n",
    "    def steps(self):\n",
    "        JOBCONF_STEP = {\n",
    "            'mapreduce.job.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "            'mapreduce.partition.keycomparator.options':'-k1,1',\n",
    "        }\n",
    "        return [\n",
    "            MRStep(jobconf = JOBCONF_STEP,\n",
    "                   mapper=self.mapper,\n",
    "                   reducer=self.reducer,\n",
    "            )\n",
    "        ]\n",
    "    \n",
    "    # purpose: split out the word pair counts for the ngrams\n",
    "    # input: line from ngram input file - ngram \\t count \\t page count \\t book count\n",
    "    # output: key(word in ngram), value(dict of remaining ngram words with counts)\n",
    "    def mapper(self, _, line):\n",
    "        line = line.strip().split('\\t')\n",
    "        # capture the n-gram words\n",
    "        words = line[0].lower().split()        \n",
    "        # capture the count, pages_count, books_count values; only keep the count for use\n",
    "        count = int(line[1:][0])\n",
    "        # handle any ngrams with duplicate words\n",
    "        #total_inst = dict(Counter(words)) -> MRJob -r hadoop no likie Counter\n",
    "        total_inst = defaultdict(int)\n",
    "        for w in words:\n",
    "            total_inst[w] += 1\n",
    "        # init the dictionary for emitting\n",
    "        H = {}\n",
    "        \n",
    "        # note the set will remove duplicate words in the ngram list - how should this be handled?\n",
    "        for subset in itertools.combinations(sorted(set(words)), 2):\n",
    "            # check the first in the pair and only keep the count\n",
    "            if subset[0] not in H.keys():\n",
    "                H[subset[0]] = {}\n",
    "                H[subset[0]][subset[1]] = total_inst[subset[1]] * count\n",
    "            elif subset[1] not in H[subset[0]]:\n",
    "                H[subset[0]][subset[1]] = total_inst[subset[1]] * count\n",
    "            else:\n",
    "                H[subset[0]][subset[1]] += (total_inst[subset[1]] * count)\n",
    "                \n",
    "            # check the second in the pair to capture the symmetry relationship\n",
    "            if subset[1] not in H.keys():\n",
    "                H[subset[1]] = {}\n",
    "                H[subset[1]][subset[0]] = total_inst[subset[1]] * count\n",
    "            elif subset[0] not in H[subset[1]]:\n",
    "                H[subset[1]][subset[0]] = total_inst[subset[1]] * count\n",
    "            else:\n",
    "                H[subset[1]][subset[0]] += (total_inst[subset[1]] * count)\n",
    " \n",
    "        for key in H.keys():\n",
    "            yield key, (H[key])\n",
    "    \n",
    "    # purpose: combine the sorted-by-key mapper outputs into stripes\n",
    "    # input: key(word in ngram), value(dict of remaining ngram words with counts)\n",
    "    # output: key(word in ngram), value(dict of remaining ngram words with total counts)\n",
    "    def reducer(self, key, value):\n",
    "        #d = Counter() -> MRJob with -r hadoop hates Counter\n",
    "        d = defaultdict(int)\n",
    "        for item in value:\n",
    "            #item = {k:int(v) for k, v in item.iteritems()}\n",
    "            #d = d + Counter(item)\n",
    "            for k, v in item.iteritems():\n",
    "                d[k] += int(v)\n",
    "        yield key, dict(d)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRbuildStripes.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "ignoring partitioner keyword arg (requires real Hadoop): 'org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner'\n",
      "Creating temp directory /tmp/buildStripes.jenncasper.20171011.235433.668538\n",
      "Running step 1 of 1...\n",
      "Streaming final output from /tmp/buildStripes.jenncasper.20171011.235433.668538/output...\n",
      "\"a\"\t{\"limited\":55,\"bill\":59,\"sea\":62,\"study\":604,\"child's\":1099,\"the\":124,\"collection\":239,\"general\":92,\"female\":447,\"in\":1201,\"establishing\":59,\"religious\":59,\"george\":92,\"biography\":92,\"case\":604,\"city\":62,\"circumstantial\":62,\"for\":59,\"of\":1011,\"tales\":123,\"government\":102,\"by\":62,\"forms\":116,\"narrative\":62,\"wales\":1099,\"fairy\":123,\"christmas\":1099}\n",
      "\"bill\"\t{\"a\":59,\"religious\":59,\"for\":59,\"establishing\":59}\n",
      "\"biography\"\t{\"a\":92,\"of\":92,\"george\":92,\"general\":92}\n",
      "\"by\"\t{\"a\":62,\"city\":62,\"the\":62,\"sea\":62}\n",
      "\"case\"\t{\"a\":604,\"limited\":55,\"female\":447,\"government\":102,\"of\":502,\"study\":604,\"in\":102}\n",
      "\"child's\"\t{\"a\":1099,\"wales\":1099,\"christmas\":1099,\"in\":1099}\n",
      "\"christmas\"\t{\"a\":1099,\"wales\":1099,\"child's\":1099,\"in\":1099}\n",
      "\"circumstantial\"\t{\"a\":62,\"of\":62,\"the\":62,\"narrative\":62}\n",
      "\"city\"\t{\"a\":62,\"the\":62,\"by\":62,\"sea\":62}\n",
      "\"collection\"\t{\"a\":239,\"forms\":116,\"fairy\":123,\"tales\":123,\"of\":355}\n",
      "\"establishing\"\t{\"a\":59,\"bill\":59,\"religious\":59,\"for\":59}\n",
      "\"fairy\"\t{\"a\":123,\"of\":123,\"tales\":123,\"collection\":123}\n",
      "\"female\"\t{\"a\":447,\"case\":447,\"study\":447,\"of\":447}\n",
      "\"for\"\t{\"a\":59,\"bill\":59,\"religious\":59,\"establishing\":59}\n",
      "\"forms\"\t{\"a\":116,\"of\":232,\"collection\":116}\n",
      "\"general\"\t{\"a\":92,\"of\":92,\"george\":92,\"biography\":92}\n",
      "\"george\"\t{\"a\":92,\"of\":92,\"biography\":92,\"general\":92}\n",
      "\"government\"\t{\"a\":102,\"case\":102,\"study\":102,\"in\":102}\n",
      "\"in\"\t{\"a\":1201,\"case\":102,\"government\":102,\"wales\":1099,\"study\":102,\"child's\":1099,\"christmas\":1099}\n",
      "\"limited\"\t{\"a\":55,\"case\":55,\"study\":55,\"of\":55}\n",
      "\"narrative\"\t{\"a\":62,\"of\":62,\"the\":62,\"circumstantial\":62}\n",
      "\"of\"\t{\"a\":1011,\"case\":502,\"circumstantial\":62,\"fairy\":123,\"limited\":55,\"tales\":123,\"collection\":355,\"general\":92,\"forms\":232,\"female\":447,\"narrative\":62,\"study\":502,\"the\":62,\"george\":92,\"biography\":92}\n",
      "\"religious\"\t{\"a\":59,\"bill\":59,\"for\":59,\"establishing\":59}\n",
      "\"sea\"\t{\"a\":62,\"city\":62,\"the\":62,\"by\":62}\n",
      "\"study\"\t{\"a\":604,\"case\":604,\"in\":102,\"female\":447,\"limited\":55,\"of\":502,\"government\":102}\n",
      "\"tales\"\t{\"a\":123,\"of\":123,\"fairy\":123,\"collection\":123}\n",
      "\"the\"\t{\"a\":124,\"city\":62,\"circumstantial\":62,\"sea\":62,\"narrative\":62,\"of\":62,\"by\":62}\n",
      "\"wales\"\t{\"a\":1099,\"child's\":1099,\"christmas\":1099,\"in\":1099}\n",
      "Removing temp directory /tmp/buildStripes.jenncasper.20171011.235433.668538...\n"
     ]
    }
   ],
   "source": [
    "# test buildStripes.py locally after making the changes needed for -r hadoop\n",
    "!python buildStripes.py -r local googlebooks-eng-all-5gram-20090715-0-filtered-first-10-lines.txt #> test_stripes.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare invertedIndex.py for -r hadoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting invertedIndex.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile invertedIndex.py\n",
    "#!~/anaconda2/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import division\n",
    "import collections\n",
    "import re\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import itertools\n",
    "import mrjob\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import sys, ast\n",
    "\n",
    "class MRinvertedIndex(MRJob):\n",
    "    \n",
    "    MRJob.SORT_VALUES = True\n",
    "    \n",
    "    def steps(self):\n",
    "        JOBCONF_STEP = {\n",
    "            'mapreduce.job.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "            'mapreduce.partition.keycomparator.options':'-k1,1',\n",
    "        }\n",
    "        return [\n",
    "            MRStep(jobconf = JOBCONF_STEP,\n",
    "                   mapper = self.mapper,\n",
    "                   reducer = self.reducer,\n",
    "            )\n",
    "        ]  \n",
    "\n",
    "    # purpose: split out the word pair counts for the ngrams\n",
    "    # input: line from stripes file\n",
    "    # output: key(word in ngram), value(doc and doc lengths)\n",
    "    def mapper(self, _, line):\n",
    "        # splice out the input from the stripes file      \n",
    "        items = line.strip().split('\\t')\n",
    "        doc = items[0].replace(\"\\\"\",\"\")\n",
    "        stripe = ast.literal_eval(items[1])\n",
    "        # determine the ngram length and output\n",
    "        length = len(stripe.keys())\n",
    "        for word, cnt in sorted(stripe.iteritems()):\n",
    "            yield word, (doc, length)\n",
    "    \n",
    "    # purpose: take the sorted input and prep for output\n",
    "    # input: key(word in ngram), value(doc and doc lengths)\n",
    "    # output: key(word in ngram), value(list of doc and doc lengths)\n",
    "    def reducer(self, word, doc_len_list):\n",
    "        doc_lens = [i for i in doc_len_list]\n",
    "        yield word, doc_lens    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRinvertedIndex.run() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "ignoring partitioner keyword arg (requires real Hadoop): 'org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner'\n",
      "Creating temp directory /tmp/invertedIndex.jenncasper.20171009.170026.003995\n",
      "Running step 1 of 1...\n",
      "Streaming final output from /tmp/invertedIndex.jenncasper.20171009.170026.003995/output...\n",
      "\"a\"\t[[\"bill\",4],[\"biography\",4],[\"by\",4],[\"case\",7],[\"child's\",4],[\"christmas\",4],[\"circumstantial\",4],[\"city\",4],[\"collection\",5],[\"establishing\",4],[\"fairy\",4],[\"female\",4],[\"for\",4],[\"forms\",3],[\"general\",4],[\"george\",4],[\"government\",4],[\"in\",7],[\"limited\",4],[\"narrative\",4],[\"of\",15],[\"religious\",4],[\"sea\",4],[\"study\",7],[\"tales\",4],[\"the\",7],[\"wales\",4]]\n",
      "\"bill\"\t[[\"a\",27],[\"establishing\",4],[\"for\",4],[\"religious\",4]]\n",
      "\"biography\"\t[[\"a\",27],[\"general\",4],[\"george\",4],[\"of\",15]]\n",
      "\"by\"\t[[\"a\",27],[\"city\",4],[\"sea\",4],[\"the\",7]]\n",
      "\"case\"\t[[\"a\",27],[\"female\",4],[\"government\",4],[\"in\",7],[\"limited\",4],[\"of\",15],[\"study\",7]]\n",
      "\"child's\"\t[[\"a\",27],[\"christmas\",4],[\"in\",7],[\"wales\",4]]\n",
      "\"christmas\"\t[[\"a\",27],[\"child's\",4],[\"in\",7],[\"wales\",4]]\n",
      "\"circumstantial\"\t[[\"a\",27],[\"narrative\",4],[\"of\",15],[\"the\",7]]\n",
      "\"city\"\t[[\"a\",27],[\"by\",4],[\"sea\",4],[\"the\",7]]\n",
      "\"collection\"\t[[\"a\",27],[\"fairy\",4],[\"forms\",3],[\"of\",15],[\"tales\",4]]\n",
      "\"establishing\"\t[[\"a\",27],[\"bill\",4],[\"for\",4],[\"religious\",4]]\n",
      "\"fairy\"\t[[\"a\",27],[\"collection\",5],[\"of\",15],[\"tales\",4]]\n",
      "\"female\"\t[[\"a\",27],[\"case\",7],[\"of\",15],[\"study\",7]]\n",
      "\"for\"\t[[\"a\",27],[\"bill\",4],[\"establishing\",4],[\"religious\",4]]\n",
      "\"forms\"\t[[\"a\",27],[\"collection\",5],[\"of\",15]]\n",
      "\"general\"\t[[\"a\",27],[\"biography\",4],[\"george\",4],[\"of\",15]]\n",
      "\"george\"\t[[\"a\",27],[\"biography\",4],[\"general\",4],[\"of\",15]]\n",
      "\"government\"\t[[\"a\",27],[\"case\",7],[\"in\",7],[\"study\",7]]\n",
      "\"in\"\t[[\"a\",27],[\"case\",7],[\"child's\",4],[\"christmas\",4],[\"government\",4],[\"study\",7],[\"wales\",4]]\n",
      "\"limited\"\t[[\"a\",27],[\"case\",7],[\"of\",15],[\"study\",7]]\n",
      "\"narrative\"\t[[\"a\",27],[\"circumstantial\",4],[\"of\",15],[\"the\",7]]\n",
      "\"of\"\t[[\"a\",27],[\"biography\",4],[\"case\",7],[\"circumstantial\",4],[\"collection\",5],[\"fairy\",4],[\"female\",4],[\"forms\",3],[\"general\",4],[\"george\",4],[\"limited\",4],[\"narrative\",4],[\"study\",7],[\"tales\",4],[\"the\",7]]\n",
      "\"religious\"\t[[\"a\",27],[\"bill\",4],[\"establishing\",4],[\"for\",4]]\n",
      "\"sea\"\t[[\"a\",27],[\"by\",4],[\"city\",4],[\"the\",7]]\n",
      "\"study\"\t[[\"a\",27],[\"case\",7],[\"female\",4],[\"government\",4],[\"in\",7],[\"limited\",4],[\"of\",15]]\n",
      "\"tales\"\t[[\"a\",27],[\"collection\",5],[\"fairy\",4],[\"of\",15]]\n",
      "\"the\"\t[[\"a\",27],[\"by\",4],[\"circumstantial\",4],[\"city\",4],[\"narrative\",4],[\"of\",15],[\"sea\",4]]\n",
      "\"wales\"\t[[\"a\",27],[\"child's\",4],[\"christmas\",4],[\"in\",7]]\n",
      "Removing temp directory /tmp/invertedIndex.jenncasper.20171009.170026.003995...\n"
     ]
    }
   ],
   "source": [
    "# test invertedIndex.py locally after making the changes needed for -r hadoop\n",
    "!python invertedIndex.py -r local test_stripes.txt #> test_index.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up similarity.py to test on the small samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting similarity.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile similarity.py\n",
    "#!~/anaconda2/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import division\n",
    "import collections\n",
    "import re\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import itertools\n",
    "import mrjob\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "\n",
    "class MRsimilarity(MRJob):\n",
    "\n",
    "    MRJob.SORT_VALUES = True \n",
    "    \n",
    "    def steps(self):\n",
    "        JOBCONF_STEP1 = {\n",
    "            'mapreduce.job.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "            'mapreduce.partition.keycomparator.options':'-k1,1',\n",
    "        }\n",
    "        JOBCONF_STEP2 = { \n",
    "            'mapreduce.job.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "            'mapreduce.partition.keycomparator.options':'-k1,1nr',\n",
    "        }\n",
    "        return [MRStep(jobconf = JOBCONF_STEP1,\n",
    "                    mapper = self.mapper_pair_sim,\n",
    "                    reducer = self.reducer_pair_sim,\n",
    "                ),\n",
    "                MRStep(jobconf = JOBCONF_STEP2,\n",
    "                    mapper = None,   \n",
    "                    reducer = self.reducer_sort,\n",
    "                )\n",
    "        ]\n",
    "    \n",
    "    # purpose: break apart the doc mappings and calculate a partial similarity for each pair\n",
    "    def mapper_pair_sim(self, _, line):\n",
    "        line = line.strip()\n",
    "        index, posting = line.split(\"\\t\")\n",
    "        posting = json.loads(posting)\n",
    "        \n",
    "        # build out all of the document pairs for the line\n",
    "        for subset in itertools.combinations(posting, 2):\n",
    "            # output the values necessary for jaccard and similarity calculations\n",
    "            doc1 = subset[0][0]\n",
    "            doc2 = subset[1][0]\n",
    "            # for jaccard\n",
    "            inter_cnt = 1\n",
    "            doc1_len = subset[0][1]\n",
    "            doc2_len = subset[1][1]\n",
    "            # for cosine\n",
    "            product = (1 / math.sqrt(doc1_len)) * (1 / math.sqrt(doc2_len))\n",
    "\n",
    "            yield sorted([doc1, doc2]), (inter_cnt, doc1_len, doc2_len, product)\n",
    "\n",
    "    # purpose: sum the partial similarities\n",
    "    def reducer_pair_sim(self, key, value):\n",
    "        \n",
    "        inter_cnt = 0\n",
    "        cosine = 0\n",
    "        d = {}\n",
    "        \n",
    "        # sum for final dist values\n",
    "        final_key = key[0] + ' - ' + key[1]\n",
    "        for i in value:\n",
    "            inter_cnt += i[0]\n",
    "            doc1_len = i[1]\n",
    "            doc2_len = i[2]\n",
    "            cosine += i[3]\n",
    "        jaccard = inter_cnt / (doc1_len + doc2_len - inter_cnt)\n",
    "        # overlap - size of the intersection divided by the smaller of the size of the two sets  \n",
    "        overlap = inter_cnt / min(doc1_len, doc2_len)\n",
    "        # dice - 2 times the intersection divided by the sum of the two set sizes\n",
    "        dice = (2 * inter_cnt) / (doc1_len + doc2_len)\n",
    "        \n",
    "        # similarity value results\n",
    "        d['cosine'] = cosine\n",
    "        d['jaccard'] = jaccard\n",
    "        d['overlap'] = overlap\n",
    "        d['dice'] = dice\n",
    "        \n",
    "        # similarity average\n",
    "        avg = np.mean(d.values())\n",
    "\n",
    "        yield avg, (final_key, d)\n",
    "    \n",
    "    # purpose: sort the final output by the avg or other dist value\n",
    "    def reducer_sort(self, key, value):\n",
    "        for v in value:\n",
    "            yield key, v\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRsimilarity.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "ignoring partitioner keyword arg (requires real Hadoop): 'org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner'\n",
      "Creating temp directory /tmp/similarity.jenncasper.20171011.235010.572998\n",
      "Running step 1 of 2...\n",
      "Running step 2 of 2...\n",
      "Streaming final output from /tmp/similarity.jenncasper.20171011.235010.572998/output...\n",
      "Removing temp directory /tmp/similarity.jenncasper.20171011.235010.572998...\n",
      "1.0\t[\"female - limited\",{\"cosine\":1.0,\"dice\":1.0,\"overlap\":1.0,\"jaccard\":1.0}]\n",
      "0.8682920652\t[\"fairy - forms\",{\"cosine\":0.8660254038,\"dice\":0.8571428571,\"overlap\":1.0,\"jaccard\":0.75}]\n",
      "0.8682920652\t[\"forms - tales\",{\"cosine\":0.8660254038,\"dice\":0.8571428571,\"overlap\":1.0,\"jaccard\":0.75}]\n",
      "0.8303571429\t[\"case - study\",{\"cosine\":0.8571428574,\"dice\":0.8571428571,\"overlap\":0.8571428571,\"jaccard\":0.75}]\n",
      "0.7125\t[\"bill - establishing\",{\"cosine\":0.75,\"dice\":0.75,\"overlap\":0.75,\"jaccard\":0.6}]\n",
      "0.7125\t[\"bill - for\",{\"cosine\":0.75,\"dice\":0.75,\"overlap\":0.75,\"jaccard\":0.6}]\n",
      "0.7125\t[\"bill - religious\",{\"cosine\":0.75,\"dice\":0.75,\"overlap\":0.75,\"jaccard\":0.6}]\n",
      "0.7125\t[\"biography - general\",{\"cosine\":0.75,\"dice\":0.75,\"overlap\":0.75,\"jaccard\":0.6}]\n",
      "0.7125\t[\"biography - george\",{\"cosine\":0.75,\"dice\":0.75,\"overlap\":0.75,\"jaccard\":0.6}]\n",
      "0.7125\t[\"by - city\",{\"cosine\":0.75,\"dice\":0.75,\"overlap\":0.75,\"jaccard\":0.6}]\n",
      "0.7125\t[\"by - sea\",{\"cosine\":0.75,\"dice\":0.75,\"overlap\":0.75,\"jaccard\":0.6}]\n",
      "0.7125\t[\"child's - christmas\",{\"cosine\":0.75,\"dice\":0.75,\"overlap\":0.75,\"jaccard\":0.6}]\n",
      "0.7125\t[\"child's - wales\",{\"cosine\":0.75,\"dice\":0.75,\"overlap\":0.75,\"jaccard\":0.6}]\n",
      "0.7125\t[\"christmas - wales\",{\"cosine\":0.75,\"dice\":0.75,\"overlap\":0.75,\"jaccard\":0.6}]\n",
      "0.7125\t[\"circumstantial - narrative\",{\"cosine\":0.75,\"dice\":0.75,\"overlap\":0.75,\"jaccard\":0.6}]\n",
      "0.7125\t[\"city - sea\",{\"cosine\":0.75,\"dice\":0.75,\"overlap\":0.75,\"jaccard\":0.6}]\n",
      "0.7125\t[\"establishing - for\",{\"cosine\":0.75,\"dice\":0.75,\"overlap\":0.75,\"jaccard\":0.6}]\n",
      "0.7125\t[\"establishing - religious\",{\"cosine\":0.75,\"dice\":0.75,\"overlap\":0.75,\"jaccard\":0.6}]\n",
      "0.7125\t[\"fairy - tales\",{\"cosine\":0.75,\"dice\":0.75,\"overlap\":0.75,\"jaccard\":0.6}]\n",
      "0.7125\t[\"female - government\",{\"cosine\":0.75,\"dice\":0.75,\"overlap\":0.75,\"jaccard\":0.6}]\n",
      "0.7125\t[\"for - religious\",{\"cosine\":0.75,\"dice\":0.75,\"overlap\":0.75,\"jaccard\":0.6}]\n",
      "0.7125\t[\"general - george\",{\"cosine\":0.75,\"dice\":0.75,\"overlap\":0.75,\"jaccard\":0.6}]\n",
      "0.7125\t[\"government - limited\",{\"cosine\":0.75,\"dice\":0.75,\"overlap\":0.75,\"jaccard\":0.6}]\n",
      "0.6989163982\t[\"a - of\",{\"cosine\":0.695665593,\"dice\":0.6666666667,\"overlap\":0.9333333333,\"jaccard\":0.5}]\n",
      "0.6468717649\t[\"collection - fairy\",{\"cosine\":0.6708203931,\"dice\":0.6666666667,\"overlap\":0.75,\"jaccard\":0.5}]\n",
      "0.6468717649\t[\"collection - tales\",{\"cosine\":0.6708203931,\"dice\":0.6666666667,\"overlap\":0.75,\"jaccard\":0.5}]\n",
      "0.5593503137\t[\"by - the\",{\"cosine\":0.5669467095,\"dice\":0.5454545455,\"overlap\":0.75,\"jaccard\":0.375}]\n",
      "0.5593503137\t[\"case - female\",{\"cosine\":0.5669467095,\"dice\":0.5454545455,\"overlap\":0.75,\"jaccard\":0.375}]\n",
      "0.5593503137\t[\"case - government\",{\"cosine\":0.5669467095,\"dice\":0.5454545455,\"overlap\":0.75,\"jaccard\":0.375}]\n",
      "0.5593503137\t[\"case - limited\",{\"cosine\":0.5669467095,\"dice\":0.5454545455,\"overlap\":0.75,\"jaccard\":0.375}]\n",
      "0.5593503137\t[\"child's - in\",{\"cosine\":0.5669467095,\"dice\":0.5454545455,\"overlap\":0.75,\"jaccard\":0.375}]\n",
      "0.5593503137\t[\"christmas - in\",{\"cosine\":0.5669467095,\"dice\":0.5454545455,\"overlap\":0.75,\"jaccard\":0.375}]\n",
      "0.5593503137\t[\"circumstantial - the\",{\"cosine\":0.5669467095,\"dice\":0.5454545455,\"overlap\":0.75,\"jaccard\":0.375}]\n",
      "0.5593503137\t[\"city - the\",{\"cosine\":0.5669467095,\"dice\":0.5454545455,\"overlap\":0.75,\"jaccard\":0.375}]\n",
      "0.5593503137\t[\"female - in\",{\"cosine\":0.5669467095,\"dice\":0.5454545455,\"overlap\":0.75,\"jaccard\":0.375}]\n",
      "0.5593503137\t[\"female - study\",{\"cosine\":0.5669467095,\"dice\":0.5454545455,\"overlap\":0.75,\"jaccard\":0.375}]\n",
      "0.5593503137\t[\"government - in\",{\"cosine\":0.5669467095,\"dice\":0.5454545455,\"overlap\":0.75,\"jaccard\":0.375}]\n",
      "0.5593503137\t[\"government - study\",{\"cosine\":0.5669467095,\"dice\":0.5454545455,\"overlap\":0.75,\"jaccard\":0.375}]\n",
      "0.5593503137\t[\"in - limited\",{\"cosine\":0.5669467095,\"dice\":0.5454545455,\"overlap\":0.75,\"jaccard\":0.375}]\n",
      "0.5593503137\t[\"in - wales\",{\"cosine\":0.5669467095,\"dice\":0.5454545455,\"overlap\":0.75,\"jaccard\":0.375}]\n",
      "0.5593503137\t[\"limited - study\",{\"cosine\":0.5669467095,\"dice\":0.5454545455,\"overlap\":0.75,\"jaccard\":0.375}]\n",
      "0.5593503137\t[\"narrative - the\",{\"cosine\":0.5669467095,\"dice\":0.5454545455,\"overlap\":0.75,\"jaccard\":0.375}]\n",
      "0.5593503137\t[\"sea - the\",{\"cosine\":0.5669467095,\"dice\":0.5454545455,\"overlap\":0.75,\"jaccard\":0.375}]\n",
      "0.5538613768\t[\"biography - forms\",{\"cosine\":0.5773502692,\"dice\":0.5714285714,\"overlap\":0.6666666667,\"jaccard\":0.4}]\n",
      "0.5538613768\t[\"circumstantial - forms\",{\"cosine\":0.5773502692,\"dice\":0.5714285714,\"overlap\":0.6666666667,\"jaccard\":0.4}]\n",
      "0.5538613768\t[\"female - forms\",{\"cosine\":0.5773502692,\"dice\":0.5714285714,\"overlap\":0.6666666667,\"jaccard\":0.4}]\n",
      "0.5538613768\t[\"forms - general\",{\"cosine\":0.5773502692,\"dice\":0.5714285714,\"overlap\":0.6666666667,\"jaccard\":0.4}]\n",
      "0.5538613768\t[\"forms - george\",{\"cosine\":0.5773502692,\"dice\":0.5714285714,\"overlap\":0.6666666667,\"jaccard\":0.4}]\n",
      "0.5538613768\t[\"forms - limited\",{\"cosine\":0.5773502692,\"dice\":0.5714285714,\"overlap\":0.6666666667,\"jaccard\":0.4}]\n",
      "0.5538613768\t[\"forms - narrative\",{\"cosine\":0.5773502692,\"dice\":0.5714285714,\"overlap\":0.6666666667,\"jaccard\":0.4}]\n",
      "0.5040994448\t[\"collection - forms\",{\"cosine\":0.5163977794,\"dice\":0.5,\"overlap\":0.6666666667,\"jaccard\":0.3333333333}]\n",
      "0.4779700538\t[\"collection - of\",{\"cosine\":0.4618802152,\"dice\":0.4,\"overlap\":0.8,\"jaccard\":0.25}]\n",
      "0.465201382\t[\"a - case\",{\"cosine\":0.4364357802,\"dice\":0.3529411765,\"overlap\":0.8571428571,\"jaccard\":0.2142857143}]\n",
      "0.465201382\t[\"a - in\",{\"cosine\":0.4364357802,\"dice\":0.3529411765,\"overlap\":0.8571428571,\"jaccard\":0.2142857143}]\n",
      "0.465201382\t[\"a - study\",{\"cosine\":0.4364357802,\"dice\":0.3529411765,\"overlap\":0.8571428571,\"jaccard\":0.2142857143}]\n",
      "0.465201382\t[\"a - the\",{\"cosine\":0.4364357802,\"dice\":0.3529411765,\"overlap\":0.8571428571,\"jaccard\":0.2142857143}]\n",
      "0.4583333333\t[\"biography - circumstantial\",{\"cosine\":0.5,\"dice\":0.5,\"overlap\":0.5,\"jaccard\":0.3333333333}]\n",
      "0.4583333333\t[\"biography - fairy\",{\"cosine\":0.5,\"dice\":0.5,\"overlap\":0.5,\"jaccard\":0.3333333333}]\n",
      "0.4583333333\t[\"biography - female\",{\"cosine\":0.5,\"dice\":0.5,\"overlap\":0.5,\"jaccard\":0.3333333333}]\n",
      "0.4583333333\t[\"biography - limited\",{\"cosine\":0.5,\"dice\":0.5,\"overlap\":0.5,\"jaccard\":0.3333333333}]\n",
      "0.4583333333\t[\"biography - narrative\",{\"cosine\":0.5,\"dice\":0.5,\"overlap\":0.5,\"jaccard\":0.3333333333}]\n",
      "0.4583333333\t[\"biography - tales\",{\"cosine\":0.5,\"dice\":0.5,\"overlap\":0.5,\"jaccard\":0.3333333333}]\n",
      "0.4583333333\t[\"by - circumstantial\",{\"cosine\":0.5,\"dice\":0.5,\"overlap\":0.5,\"jaccard\":0.3333333333}]\n",
      "0.4583333333\t[\"by - narrative\",{\"cosine\":0.5,\"dice\":0.5,\"overlap\":0.5,\"jaccard\":0.3333333333}]\n",
      "0.4583333333\t[\"child's - government\",{\"cosine\":0.5,\"dice\":0.5,\"overlap\":0.5,\"jaccard\":0.3333333333}]\n",
      "0.4583333333\t[\"christmas - government\",{\"cosine\":0.5,\"dice\":0.5,\"overlap\":0.5,\"jaccard\":0.3333333333}]\n",
      "0.4583333333\t[\"circumstantial - city\",{\"cosine\":0.5,\"dice\":0.5,\"overlap\":0.5,\"jaccard\":0.3333333333}]\n",
      "0.4583333333\t[\"circumstantial - fairy\",{\"cosine\":0.5,\"dice\":0.5,\"overlap\":0.5,\"jaccard\":0.3333333333}]\n",
      "0.4583333333\t[\"circumstantial - female\",{\"cosine\":0.5,\"dice\":0.5,\"overlap\":0.5,\"jaccard\":0.3333333333}]\n",
      "0.4583333333\t[\"circumstantial - general\",{\"cosine\":0.5,\"dice\":0.5,\"overlap\":0.5,\"jaccard\":0.3333333333}]\n",
      "0.4583333333\t[\"circumstantial - george\",{\"cosine\":0.5,\"dice\":0.5,\"overlap\":0.5,\"jaccard\":0.3333333333}]\n",
      "0.4583333333\t[\"circumstantial - limited\",{\"cosine\":0.5,\"dice\":0.5,\"overlap\":0.5,\"jaccard\":0.3333333333}]\n",
      "0.4583333333\t[\"circumstantial - sea\",{\"cosine\":0.5,\"dice\":0.5,\"overlap\":0.5,\"jaccard\":0.3333333333}]\n",
      "0.4583333333\t[\"circumstantial - tales\",{\"cosine\":0.5,\"dice\":0.5,\"overlap\":0.5,\"jaccard\":0.3333333333}]\n",
      "0.4583333333\t[\"city - narrative\",{\"cosine\":0.5,\"dice\":0.5,\"overlap\":0.5,\"jaccard\":0.3333333333}]\n",
      "0.4583333333\t[\"fairy - female\",{\"cosine\":0.5,\"dice\":0.5,\"overlap\":0.5,\"jaccard\":0.3333333333}]\n",
      "0.4583333333\t[\"fairy - general\",{\"cosine\":0.5,\"dice\":0.5,\"overlap\":0.5,\"jaccard\":0.3333333333}]\n",
      "0.4583333333\t[\"fairy - george\",{\"cosine\":0.5,\"dice\":0.5,\"overlap\":0.5,\"jaccard\":0.3333333333}]\n",
      "0.4583333333\t[\"fairy - limited\",{\"cosine\":0.5,\"dice\":0.5,\"overlap\":0.5,\"jaccard\":0.3333333333}]\n",
      "0.4583333333\t[\"fairy - narrative\",{\"cosine\":0.5,\"dice\":0.5,\"overlap\":0.5,\"jaccard\":0.3333333333}]\n",
      "0.4583333333\t[\"female - general\",{\"cosine\":0.5,\"dice\":0.5,\"overlap\":0.5,\"jaccard\":0.3333333333}]\n",
      "0.4583333333\t[\"female - george\",{\"cosine\":0.5,\"dice\":0.5,\"overlap\":0.5,\"jaccard\":0.3333333333}]\n",
      "0.4583333333\t[\"female - narrative\",{\"cosine\":0.5,\"dice\":0.5,\"overlap\":0.5,\"jaccard\":0.3333333333}]\n",
      "0.4583333333\t[\"female - tales\",{\"cosine\":0.5,\"dice\":0.5,\"overlap\":0.5,\"jaccard\":0.3333333333}]\n",
      "0.4583333333\t[\"general - limited\",{\"cosine\":0.5,\"dice\":0.5,\"overlap\":0.5,\"jaccard\":0.3333333333}]\n",
      "0.4583333333\t[\"general - narrative\",{\"cosine\":0.5,\"dice\":0.5,\"overlap\":0.5,\"jaccard\":0.3333333333}]\n",
      "0.4583333333\t[\"general - tales\",{\"cosine\":0.5,\"dice\":0.5,\"overlap\":0.5,\"jaccard\":0.3333333333}]\n",
      "0.4583333333\t[\"george - limited\",{\"cosine\":0.5,\"dice\":0.5,\"overlap\":0.5,\"jaccard\":0.3333333333}]\n",
      "0.4583333333\t[\"george - narrative\",{\"cosine\":0.5,\"dice\":0.5,\"overlap\":0.5,\"jaccard\":0.3333333333}]\n",
      "0.4583333333\t[\"george - tales\",{\"cosine\":0.5,\"dice\":0.5,\"overlap\":0.5,\"jaccard\":0.3333333333}]\n",
      "0.4583333333\t[\"government - wales\",{\"cosine\":0.5,\"dice\":0.5,\"overlap\":0.5,\"jaccard\":0.3333333333}]\n",
      "0.4583333333\t[\"limited - narrative\",{\"cosine\":0.5,\"dice\":0.5,\"overlap\":0.5,\"jaccard\":0.3333333333}]\n",
      "0.4583333333\t[\"limited - tales\",{\"cosine\":0.5,\"dice\":0.5,\"overlap\":0.5,\"jaccard\":0.3333333333}]\n",
      "0.4583333333\t[\"narrative - sea\",{\"cosine\":0.5,\"dice\":0.5,\"overlap\":0.5,\"jaccard\":0.3333333333}]\n",
      "0.4583333333\t[\"narrative - tales\",{\"cosine\":0.5,\"dice\":0.5,\"overlap\":0.5,\"jaccard\":0.3333333333}]\n",
      "0.4382756118\t[\"case - forms\",{\"cosine\":0.4364357804,\"dice\":0.4,\"overlap\":0.6666666667,\"jaccard\":0.25}]\n",
      "0.4382756118\t[\"forms - study\",{\"cosine\":0.4364357804,\"dice\":0.4,\"overlap\":0.6666666667,\"jaccard\":0.25}]\n",
      "0.4382756118\t[\"forms - the\",{\"cosine\":0.4364357804,\"dice\":0.4,\"overlap\":0.6666666667,\"jaccard\":0.25}]\n",
      "0.4193430814\t[\"biography - collection\",{\"cosine\":0.4472135954,\"dice\":0.4444444444,\"overlap\":0.5,\"jaccard\":0.2857142857}]\n",
      "0.4193430814\t[\"circumstantial - collection\",{\"cosine\":0.4472135954,\"dice\":0.4444444444,\"overlap\":0.5,\"jaccard\":0.2857142857}]\n",
      "0.4193430814\t[\"collection - female\",{\"cosine\":0.4472135954,\"dice\":0.4444444444,\"overlap\":0.5,\"jaccard\":0.2857142857}]\n",
      "0.4193430814\t[\"collection - general\",{\"cosine\":0.4472135954,\"dice\":0.4444444444,\"overlap\":0.5,\"jaccard\":0.2857142857}]\n",
      "0.4193430814\t[\"collection - george\",{\"cosine\":0.4472135954,\"dice\":0.4444444444,\"overlap\":0.5,\"jaccard\":0.2857142857}]\n",
      "0.4193430814\t[\"collection - limited\",{\"cosine\":0.4472135954,\"dice\":0.4444444444,\"overlap\":0.5,\"jaccard\":0.2857142857}]\n",
      "0.4193430814\t[\"collection - narrative\",{\"cosine\":0.4472135954,\"dice\":0.4444444444,\"overlap\":0.5,\"jaccard\":0.2857142857}]\n",
      "0.4101469521\t[\"biography - of\",{\"cosine\":0.3872983347,\"dice\":0.3157894737,\"overlap\":0.75,\"jaccard\":0.1875}]\n",
      "0.4101469521\t[\"circumstantial - of\",{\"cosine\":0.3872983347,\"dice\":0.3157894737,\"overlap\":0.75,\"jaccard\":0.1875}]\n",
      "0.4101469521\t[\"fairy - of\",{\"cosine\":0.3872983347,\"dice\":0.3157894737,\"overlap\":0.75,\"jaccard\":0.1875}]\n",
      "0.4101469521\t[\"female - of\",{\"cosine\":0.3872983347,\"dice\":0.3157894737,\"overlap\":0.75,\"jaccard\":0.1875}]\n",
      "0.4101469521\t[\"general - of\",{\"cosine\":0.3872983347,\"dice\":0.3157894737,\"overlap\":0.75,\"jaccard\":0.1875}]\n",
      "0.4101469521\t[\"george - of\",{\"cosine\":0.3872983347,\"dice\":0.3157894737,\"overlap\":0.75,\"jaccard\":0.1875}]\n",
      "0.4101469521\t[\"government - of\",{\"cosine\":0.3872983347,\"dice\":0.3157894737,\"overlap\":0.75,\"jaccard\":0.1875}]\n",
      "0.4101469521\t[\"limited - of\",{\"cosine\":0.3872983347,\"dice\":0.3157894737,\"overlap\":0.75,\"jaccard\":0.1875}]\n",
      "0.4101469521\t[\"narrative - of\",{\"cosine\":0.3872983347,\"dice\":0.3157894737,\"overlap\":0.75,\"jaccard\":0.1875}]\n",
      "0.4101469521\t[\"of - tales\",{\"cosine\":0.3872983347,\"dice\":0.3157894737,\"overlap\":0.75,\"jaccard\":0.1875}]\n",
      "0.3896103896\t[\"case - in\",{\"cosine\":0.4285714287,\"dice\":0.4285714286,\"overlap\":0.4285714286,\"jaccard\":0.2727272727}]\n",
      "0.3896103896\t[\"in - study\",{\"cosine\":0.4285714287,\"dice\":0.4285714286,\"overlap\":0.4285714286,\"jaccard\":0.2727272727}]\n",
      "0.3869117966\t[\"case - of\",{\"cosine\":0.3903600292,\"dice\":0.3636363636,\"overlap\":0.5714285714,\"jaccard\":0.2222222222}]\n",
      "0.3869117966\t[\"of - study\",{\"cosine\":0.3903600292,\"dice\":0.3636363636,\"overlap\":0.5714285714,\"jaccard\":0.2222222222}]\n",
      "0.3842805823\t[\"a - collection\",{\"cosine\":0.3442651864,\"dice\":0.25,\"overlap\":0.8,\"jaccard\":0.1428571429}]\n",
      "0.3659557647\t[\"biography - case\",{\"cosine\":0.377964473,\"dice\":0.3636363636,\"overlap\":0.5,\"jaccard\":0.2222222222}]\n",
      "0.3659557647\t[\"biography - study\",{\"cosine\":0.377964473,\"dice\":0.3636363636,\"overlap\":0.5,\"jaccard\":0.2222222222}]\n",
      "0.3659557647\t[\"biography - the\",{\"cosine\":0.377964473,\"dice\":0.3636363636,\"overlap\":0.5,\"jaccard\":0.2222222222}]\n",
      "0.3659557647\t[\"case - child's\",{\"cosine\":0.377964473,\"dice\":0.3636363636,\"overlap\":0.5,\"jaccard\":0.2222222222}]\n",
      "0.3659557647\t[\"case - christmas\",{\"cosine\":0.377964473,\"dice\":0.3636363636,\"overlap\":0.5,\"jaccard\":0.2222222222}]\n",
      "0.3659557647\t[\"case - circumstantial\",{\"cosine\":0.377964473,\"dice\":0.3636363636,\"overlap\":0.5,\"jaccard\":0.2222222222}]\n",
      "0.3659557647\t[\"case - fairy\",{\"cosine\":0.377964473,\"dice\":0.3636363636,\"overlap\":0.5,\"jaccard\":0.2222222222}]\n",
      "0.3659557647\t[\"case - general\",{\"cosine\":0.377964473,\"dice\":0.3636363636,\"overlap\":0.5,\"jaccard\":0.2222222222}]\n",
      "0.3659557647\t[\"case - george\",{\"cosine\":0.377964473,\"dice\":0.3636363636,\"overlap\":0.5,\"jaccard\":0.2222222222}]\n",
      "0.3659557647\t[\"case - narrative\",{\"cosine\":0.377964473,\"dice\":0.3636363636,\"overlap\":0.5,\"jaccard\":0.2222222222}]\n",
      "0.3659557647\t[\"case - tales\",{\"cosine\":0.377964473,\"dice\":0.3636363636,\"overlap\":0.5,\"jaccard\":0.2222222222}]\n",
      "0.3659557647\t[\"case - wales\",{\"cosine\":0.377964473,\"dice\":0.3636363636,\"overlap\":0.5,\"jaccard\":0.2222222222}]\n",
      "0.3659557647\t[\"child's - study\",{\"cosine\":0.377964473,\"dice\":0.3636363636,\"overlap\":0.5,\"jaccard\":0.2222222222}]\n",
      "0.3659557647\t[\"christmas - study\",{\"cosine\":0.377964473,\"dice\":0.3636363636,\"overlap\":0.5,\"jaccard\":0.2222222222}]\n",
      "0.3659557647\t[\"circumstantial - study\",{\"cosine\":0.377964473,\"dice\":0.3636363636,\"overlap\":0.5,\"jaccard\":0.2222222222}]\n",
      "0.3659557647\t[\"fairy - study\",{\"cosine\":0.377964473,\"dice\":0.3636363636,\"overlap\":0.5,\"jaccard\":0.2222222222}]\n",
      "0.3659557647\t[\"fairy - the\",{\"cosine\":0.377964473,\"dice\":0.3636363636,\"overlap\":0.5,\"jaccard\":0.2222222222}]\n",
      "0.3659557647\t[\"female - the\",{\"cosine\":0.377964473,\"dice\":0.3636363636,\"overlap\":0.5,\"jaccard\":0.2222222222}]\n",
      "0.3659557647\t[\"general - study\",{\"cosine\":0.377964473,\"dice\":0.3636363636,\"overlap\":0.5,\"jaccard\":0.2222222222}]\n",
      "0.3659557647\t[\"general - the\",{\"cosine\":0.377964473,\"dice\":0.3636363636,\"overlap\":0.5,\"jaccard\":0.2222222222}]\n",
      "0.3659557647\t[\"george - study\",{\"cosine\":0.377964473,\"dice\":0.3636363636,\"overlap\":0.5,\"jaccard\":0.2222222222}]\n",
      "0.3659557647\t[\"george - the\",{\"cosine\":0.377964473,\"dice\":0.3636363636,\"overlap\":0.5,\"jaccard\":0.2222222222}]\n",
      "0.3659557647\t[\"limited - the\",{\"cosine\":0.377964473,\"dice\":0.3636363636,\"overlap\":0.5,\"jaccard\":0.2222222222}]\n",
      "0.3659557647\t[\"narrative - study\",{\"cosine\":0.377964473,\"dice\":0.3636363636,\"overlap\":0.5,\"jaccard\":0.2222222222}]\n",
      "0.3659557647\t[\"study - tales\",{\"cosine\":0.377964473,\"dice\":0.3636363636,\"overlap\":0.5,\"jaccard\":0.2222222222}]\n",
      "0.3659557647\t[\"study - wales\",{\"cosine\":0.377964473,\"dice\":0.3636363636,\"overlap\":0.5,\"jaccard\":0.2222222222}]\n",
      "0.3659557647\t[\"tales - the\",{\"cosine\":0.377964473,\"dice\":0.3636363636,\"overlap\":0.5,\"jaccard\":0.2222222222}]\n",
      "0.3348415947\t[\"a - bill\",{\"cosine\":0.2886751347,\"dice\":0.1935483871,\"overlap\":0.75,\"jaccard\":0.1071428571}]\n",
      "0.3348415947\t[\"a - biography\",{\"cosine\":0.2886751347,\"dice\":0.1935483871,\"overlap\":0.75,\"jaccard\":0.1071428571}]\n",
      "0.3348415947\t[\"a - by\",{\"cosine\":0.2886751347,\"dice\":0.1935483871,\"overlap\":0.75,\"jaccard\":0.1071428571}]\n",
      "0.3348415947\t[\"a - child's\",{\"cosine\":0.2886751347,\"dice\":0.1935483871,\"overlap\":0.75,\"jaccard\":0.1071428571}]\n",
      "0.3348415947\t[\"a - christmas\",{\"cosine\":0.2886751347,\"dice\":0.1935483871,\"overlap\":0.75,\"jaccard\":0.1071428571}]\n",
      "0.3348415947\t[\"a - circumstantial\",{\"cosine\":0.2886751347,\"dice\":0.1935483871,\"overlap\":0.75,\"jaccard\":0.1071428571}]\n",
      "0.3348415947\t[\"a - city\",{\"cosine\":0.2886751347,\"dice\":0.1935483871,\"overlap\":0.75,\"jaccard\":0.1071428571}]\n",
      "0.3348415947\t[\"a - establishing\",{\"cosine\":0.2886751347,\"dice\":0.1935483871,\"overlap\":0.75,\"jaccard\":0.1071428571}]\n",
      "0.3348415947\t[\"a - fairy\",{\"cosine\":0.2886751347,\"dice\":0.1935483871,\"overlap\":0.75,\"jaccard\":0.1071428571}]\n",
      "0.3348415947\t[\"a - female\",{\"cosine\":0.2886751347,\"dice\":0.1935483871,\"overlap\":0.75,\"jaccard\":0.1071428571}]\n",
      "0.3348415947\t[\"a - for\",{\"cosine\":0.2886751347,\"dice\":0.1935483871,\"overlap\":0.75,\"jaccard\":0.1071428571}]\n",
      "0.3348415947\t[\"a - general\",{\"cosine\":0.2886751347,\"dice\":0.1935483871,\"overlap\":0.75,\"jaccard\":0.1071428571}]\n",
      "0.3348415947\t[\"a - george\",{\"cosine\":0.2886751347,\"dice\":0.1935483871,\"overlap\":0.75,\"jaccard\":0.1071428571}]\n",
      "0.3348415947\t[\"a - government\",{\"cosine\":0.2886751347,\"dice\":0.1935483871,\"overlap\":0.75,\"jaccard\":0.1071428571}]\n",
      "0.3348415947\t[\"a - limited\",{\"cosine\":0.2886751347,\"dice\":0.1935483871,\"overlap\":0.75,\"jaccard\":0.1071428571}]\n",
      "0.3348415947\t[\"a - narrative\",{\"cosine\":0.2886751347,\"dice\":0.1935483871,\"overlap\":0.75,\"jaccard\":0.1071428571}]\n",
      "0.3348415947\t[\"a - religious\",{\"cosine\":0.2886751347,\"dice\":0.1935483871,\"overlap\":0.75,\"jaccard\":0.1071428571}]\n",
      "0.3348415947\t[\"a - sea\",{\"cosine\":0.2886751347,\"dice\":0.1935483871,\"overlap\":0.75,\"jaccard\":0.1071428571}]\n",
      "0.3348415947\t[\"a - tales\",{\"cosine\":0.2886751347,\"dice\":0.1935483871,\"overlap\":0.75,\"jaccard\":0.1071428571}]\n",
      "0.3348415947\t[\"a - wales\",{\"cosine\":0.2886751347,\"dice\":0.1935483871,\"overlap\":0.75,\"jaccard\":0.1071428571}]\n",
      "0.3280078215\t[\"forms - of\",{\"cosine\":0.298142397,\"dice\":0.2222222222,\"overlap\":0.6666666667,\"jaccard\":0.125}]\n",
      "0.3178487588\t[\"case - collection\",{\"cosine\":0.3380617018,\"dice\":0.3333333333,\"overlap\":0.4,\"jaccard\":0.2}]\n",
      "0.3178487588\t[\"collection - study\",{\"cosine\":0.3380617018,\"dice\":0.3333333333,\"overlap\":0.4,\"jaccard\":0.2}]\n",
      "0.3178487588\t[\"collection - the\",{\"cosine\":0.3380617018,\"dice\":0.3333333333,\"overlap\":0.4,\"jaccard\":0.2}]\n",
      "0.287990865\t[\"in - of\",{\"cosine\":0.2927700219,\"dice\":0.2727272727,\"overlap\":0.4285714286,\"jaccard\":0.1578947368}]\n",
      "0.287990865\t[\"of - the\",{\"cosine\":0.2927700219,\"dice\":0.2727272727,\"overlap\":0.4285714286,\"jaccard\":0.1578947368}]\n",
      "0.2734126984\t[\"a - forms\",{\"cosine\":0.2222222222,\"dice\":0.1333333333,\"overlap\":0.6666666667,\"jaccard\":0.0714285714}]\n",
      "0.2715930661\t[\"by - of\",{\"cosine\":0.2581988898,\"dice\":0.2105263158,\"overlap\":0.5,\"jaccard\":0.1176470588}]\n",
      "0.2715930661\t[\"city - of\",{\"cosine\":0.2581988898,\"dice\":0.2105263158,\"overlap\":0.5,\"jaccard\":0.1176470588}]\n",
      "0.2715930661\t[\"of - sea\",{\"cosine\":0.2581988898,\"dice\":0.2105263158,\"overlap\":0.5,\"jaccard\":0.1176470588}]\n",
      "0.2685973551\t[\"bill - forms\",{\"cosine\":0.2886751346,\"dice\":0.2857142857,\"overlap\":0.3333333333,\"jaccard\":0.1666666667}]\n",
      "0.2685973551\t[\"by - forms\",{\"cosine\":0.2886751346,\"dice\":0.2857142857,\"overlap\":0.3333333333,\"jaccard\":0.1666666667}]\n",
      "0.2685973551\t[\"child's - forms\",{\"cosine\":0.2886751346,\"dice\":0.2857142857,\"overlap\":0.3333333333,\"jaccard\":0.1666666667}]\n",
      "0.2685973551\t[\"christmas - forms\",{\"cosine\":0.2886751346,\"dice\":0.2857142857,\"overlap\":0.3333333333,\"jaccard\":0.1666666667}]\n",
      "0.2685973551\t[\"city - forms\",{\"cosine\":0.2886751346,\"dice\":0.2857142857,\"overlap\":0.3333333333,\"jaccard\":0.1666666667}]\n",
      "0.2685973551\t[\"establishing - forms\",{\"cosine\":0.2886751346,\"dice\":0.2857142857,\"overlap\":0.3333333333,\"jaccard\":0.1666666667}]\n",
      "0.2685973551\t[\"for - forms\",{\"cosine\":0.2886751346,\"dice\":0.2857142857,\"overlap\":0.3333333333,\"jaccard\":0.1666666667}]\n",
      "0.2685973551\t[\"forms - government\",{\"cosine\":0.2886751346,\"dice\":0.2857142857,\"overlap\":0.3333333333,\"jaccard\":0.1666666667}]\n",
      "0.2685973551\t[\"forms - religious\",{\"cosine\":0.2886751346,\"dice\":0.2857142857,\"overlap\":0.3333333333,\"jaccard\":0.1666666667}]\n",
      "0.2685973551\t[\"forms - sea\",{\"cosine\":0.2886751346,\"dice\":0.2857142857,\"overlap\":0.3333333333,\"jaccard\":0.1666666667}]\n",
      "0.2685973551\t[\"forms - wales\",{\"cosine\":0.2886751346,\"dice\":0.2857142857,\"overlap\":0.3333333333,\"jaccard\":0.1666666667}]\n",
      "0.255952381\t[\"case - the\",{\"cosine\":0.2857142858,\"dice\":0.2857142857,\"overlap\":0.2857142857,\"jaccard\":0.1666666667}]\n",
      "0.255952381\t[\"study - the\",{\"cosine\":0.2857142858,\"dice\":0.2857142857,\"overlap\":0.2857142857,\"jaccard\":0.1666666667}]\n",
      "0.2232142857\t[\"bill - biography\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"bill - by\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"bill - child's\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"bill - christmas\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"bill - circumstantial\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"bill - city\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"bill - fairy\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"bill - female\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"bill - general\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"bill - george\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"bill - government\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"bill - limited\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"bill - narrative\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"bill - sea\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"bill - tales\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"bill - wales\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"biography - by\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"biography - child's\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"biography - christmas\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"biography - city\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"biography - establishing\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"biography - for\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"biography - government\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"biography - religious\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"biography - sea\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"biography - wales\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"by - child's\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"by - christmas\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"by - establishing\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"by - fairy\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"by - female\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"by - for\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"by - general\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"by - george\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"by - government\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"by - limited\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"by - religious\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"by - tales\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"by - wales\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"child's - circumstantial\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"child's - city\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"child's - establishing\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"child's - fairy\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"child's - female\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"child's - for\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"child's - general\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"child's - george\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"child's - limited\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"child's - narrative\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"child's - religious\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"child's - sea\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"child's - tales\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"christmas - circumstantial\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"christmas - city\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"christmas - establishing\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"christmas - fairy\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"christmas - female\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"christmas - for\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"christmas - general\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"christmas - george\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"christmas - limited\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"christmas - narrative\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"christmas - religious\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"christmas - sea\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"christmas - tales\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"circumstantial - establishing\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"circumstantial - for\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"circumstantial - government\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"circumstantial - religious\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"circumstantial - wales\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"city - establishing\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"city - fairy\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"city - female\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"city - for\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"city - general\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"city - george\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"city - government\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"city - limited\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"city - religious\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"city - tales\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"city - wales\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"establishing - fairy\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"establishing - female\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"establishing - general\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"establishing - george\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"establishing - government\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"establishing - limited\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"establishing - narrative\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"establishing - sea\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"establishing - tales\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"establishing - wales\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"fairy - for\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"fairy - government\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"fairy - religious\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"fairy - sea\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"fairy - wales\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"female - for\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"female - religious\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"female - sea\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"female - wales\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"for - general\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"for - george\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"for - government\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"for - limited\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"for - narrative\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"for - sea\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"for - tales\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"for - wales\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"general - government\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"general - religious\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"general - sea\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"general - wales\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"george - government\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"george - religious\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"george - sea\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"george - wales\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"government - narrative\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"government - religious\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"government - sea\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"government - tales\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"limited - religious\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"limited - sea\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"limited - wales\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"narrative - religious\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"narrative - wales\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"religious - sea\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"religious - tales\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"religious - wales\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"sea - tales\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"sea - wales\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2232142857\t[\"tales - wales\",{\"cosine\":0.25,\"dice\":0.25,\"overlap\":0.25,\"jaccard\":0.1428571429}]\n",
      "0.2156655837\t[\"forms - in\",{\"cosine\":0.2182178902,\"dice\":0.2,\"overlap\":0.3333333333,\"jaccard\":0.1111111111}]\n",
      "0.205207255\t[\"bill - collection\",{\"cosine\":0.2236067977,\"dice\":0.2222222222,\"overlap\":0.25,\"jaccard\":0.125}]\n",
      "0.205207255\t[\"by - collection\",{\"cosine\":0.2236067977,\"dice\":0.2222222222,\"overlap\":0.25,\"jaccard\":0.125}]\n",
      "0.205207255\t[\"child's - collection\",{\"cosine\":0.2236067977,\"dice\":0.2222222222,\"overlap\":0.25,\"jaccard\":0.125}]\n",
      "0.205207255\t[\"christmas - collection\",{\"cosine\":0.2236067977,\"dice\":0.2222222222,\"overlap\":0.25,\"jaccard\":0.125}]\n",
      "0.205207255\t[\"city - collection\",{\"cosine\":0.2236067977,\"dice\":0.2222222222,\"overlap\":0.25,\"jaccard\":0.125}]\n",
      "0.205207255\t[\"collection - establishing\",{\"cosine\":0.2236067977,\"dice\":0.2222222222,\"overlap\":0.25,\"jaccard\":0.125}]\n",
      "0.205207255\t[\"collection - for\",{\"cosine\":0.2236067977,\"dice\":0.2222222222,\"overlap\":0.25,\"jaccard\":0.125}]\n",
      "0.205207255\t[\"collection - government\",{\"cosine\":0.2236067977,\"dice\":0.2222222222,\"overlap\":0.25,\"jaccard\":0.125}]\n",
      "0.205207255\t[\"collection - religious\",{\"cosine\":0.2236067977,\"dice\":0.2222222222,\"overlap\":0.25,\"jaccard\":0.125}]\n",
      "0.205207255\t[\"collection - sea\",{\"cosine\":0.2236067977,\"dice\":0.2222222222,\"overlap\":0.25,\"jaccard\":0.125}]\n",
      "0.205207255\t[\"collection - wales\",{\"cosine\":0.2236067977,\"dice\":0.2222222222,\"overlap\":0.25,\"jaccard\":0.125}]\n",
      "0.1802001046\t[\"bill - case\",{\"cosine\":0.1889822365,\"dice\":0.1818181818,\"overlap\":0.25,\"jaccard\":0.1}]\n",
      "0.1802001046\t[\"bill - in\",{\"cosine\":0.1889822365,\"dice\":0.1818181818,\"overlap\":0.25,\"jaccard\":0.1}]\n",
      "0.1802001046\t[\"bill - study\",{\"cosine\":0.1889822365,\"dice\":0.1818181818,\"overlap\":0.25,\"jaccard\":0.1}]\n",
      "0.1802001046\t[\"bill - the\",{\"cosine\":0.1889822365,\"dice\":0.1818181818,\"overlap\":0.25,\"jaccard\":0.1}]\n",
      "0.1802001046\t[\"biography - in\",{\"cosine\":0.1889822365,\"dice\":0.1818181818,\"overlap\":0.25,\"jaccard\":0.1}]\n",
      "0.1802001046\t[\"by - case\",{\"cosine\":0.1889822365,\"dice\":0.1818181818,\"overlap\":0.25,\"jaccard\":0.1}]\n",
      "0.1802001046\t[\"by - in\",{\"cosine\":0.1889822365,\"dice\":0.1818181818,\"overlap\":0.25,\"jaccard\":0.1}]\n",
      "0.1802001046\t[\"by - study\",{\"cosine\":0.1889822365,\"dice\":0.1818181818,\"overlap\":0.25,\"jaccard\":0.1}]\n",
      "0.1802001046\t[\"case - city\",{\"cosine\":0.1889822365,\"dice\":0.1818181818,\"overlap\":0.25,\"jaccard\":0.1}]\n",
      "0.1802001046\t[\"case - establishing\",{\"cosine\":0.1889822365,\"dice\":0.1818181818,\"overlap\":0.25,\"jaccard\":0.1}]\n",
      "0.1802001046\t[\"case - for\",{\"cosine\":0.1889822365,\"dice\":0.1818181818,\"overlap\":0.25,\"jaccard\":0.1}]\n",
      "0.1802001046\t[\"case - religious\",{\"cosine\":0.1889822365,\"dice\":0.1818181818,\"overlap\":0.25,\"jaccard\":0.1}]\n",
      "0.1802001046\t[\"case - sea\",{\"cosine\":0.1889822365,\"dice\":0.1818181818,\"overlap\":0.25,\"jaccard\":0.1}]\n",
      "0.1802001046\t[\"child's - the\",{\"cosine\":0.1889822365,\"dice\":0.1818181818,\"overlap\":0.25,\"jaccard\":0.1}]\n",
      "0.1802001046\t[\"christmas - the\",{\"cosine\":0.1889822365,\"dice\":0.1818181818,\"overlap\":0.25,\"jaccard\":0.1}]\n",
      "0.1802001046\t[\"circumstantial - in\",{\"cosine\":0.1889822365,\"dice\":0.1818181818,\"overlap\":0.25,\"jaccard\":0.1}]\n",
      "0.1802001046\t[\"city - in\",{\"cosine\":0.1889822365,\"dice\":0.1818181818,\"overlap\":0.25,\"jaccard\":0.1}]\n",
      "0.1802001046\t[\"city - study\",{\"cosine\":0.1889822365,\"dice\":0.1818181818,\"overlap\":0.25,\"jaccard\":0.1}]\n",
      "0.1802001046\t[\"establishing - in\",{\"cosine\":0.1889822365,\"dice\":0.1818181818,\"overlap\":0.25,\"jaccard\":0.1}]\n",
      "0.1802001046\t[\"establishing - study\",{\"cosine\":0.1889822365,\"dice\":0.1818181818,\"overlap\":0.25,\"jaccard\":0.1}]\n",
      "0.1802001046\t[\"establishing - the\",{\"cosine\":0.1889822365,\"dice\":0.1818181818,\"overlap\":0.25,\"jaccard\":0.1}]\n",
      "0.1802001046\t[\"fairy - in\",{\"cosine\":0.1889822365,\"dice\":0.1818181818,\"overlap\":0.25,\"jaccard\":0.1}]\n",
      "0.1802001046\t[\"for - in\",{\"cosine\":0.1889822365,\"dice\":0.1818181818,\"overlap\":0.25,\"jaccard\":0.1}]\n",
      "0.1802001046\t[\"for - study\",{\"cosine\":0.1889822365,\"dice\":0.1818181818,\"overlap\":0.25,\"jaccard\":0.1}]\n",
      "0.1802001046\t[\"for - the\",{\"cosine\":0.1889822365,\"dice\":0.1818181818,\"overlap\":0.25,\"jaccard\":0.1}]\n",
      "0.1802001046\t[\"general - in\",{\"cosine\":0.1889822365,\"dice\":0.1818181818,\"overlap\":0.25,\"jaccard\":0.1}]\n",
      "0.1802001046\t[\"george - in\",{\"cosine\":0.1889822365,\"dice\":0.1818181818,\"overlap\":0.25,\"jaccard\":0.1}]\n",
      "0.1802001046\t[\"government - the\",{\"cosine\":0.1889822365,\"dice\":0.1818181818,\"overlap\":0.25,\"jaccard\":0.1}]\n",
      "0.1802001046\t[\"in - narrative\",{\"cosine\":0.1889822365,\"dice\":0.1818181818,\"overlap\":0.25,\"jaccard\":0.1}]\n",
      "0.1802001046\t[\"in - religious\",{\"cosine\":0.1889822365,\"dice\":0.1818181818,\"overlap\":0.25,\"jaccard\":0.1}]\n",
      "0.1802001046\t[\"in - sea\",{\"cosine\":0.1889822365,\"dice\":0.1818181818,\"overlap\":0.25,\"jaccard\":0.1}]\n",
      "0.1802001046\t[\"in - tales\",{\"cosine\":0.1889822365,\"dice\":0.1818181818,\"overlap\":0.25,\"jaccard\":0.1}]\n",
      "0.1802001046\t[\"religious - study\",{\"cosine\":0.1889822365,\"dice\":0.1818181818,\"overlap\":0.25,\"jaccard\":0.1}]\n",
      "0.1802001046\t[\"religious - the\",{\"cosine\":0.1889822365,\"dice\":0.1818181818,\"overlap\":0.25,\"jaccard\":0.1}]\n",
      "0.1802001046\t[\"sea - study\",{\"cosine\":0.1889822365,\"dice\":0.1818181818,\"overlap\":0.25,\"jaccard\":0.1}]\n",
      "0.1802001046\t[\"the - wales\",{\"cosine\":0.1889822365,\"dice\":0.1818181818,\"overlap\":0.25,\"jaccard\":0.1}]\n",
      "0.1566516521\t[\"collection - in\",{\"cosine\":0.1690308509,\"dice\":0.1666666667,\"overlap\":0.2,\"jaccard\":0.0909090909}]\n",
      "0.1349795396\t[\"bill - of\",{\"cosine\":0.1290994449,\"dice\":0.1052631579,\"overlap\":0.25,\"jaccard\":0.0555555556}]\n",
      "0.1349795396\t[\"child's - of\",{\"cosine\":0.1290994449,\"dice\":0.1052631579,\"overlap\":0.25,\"jaccard\":0.0555555556}]\n",
      "0.1349795396\t[\"christmas - of\",{\"cosine\":0.1290994449,\"dice\":0.1052631579,\"overlap\":0.25,\"jaccard\":0.0555555556}]\n",
      "0.1349795396\t[\"establishing - of\",{\"cosine\":0.1290994449,\"dice\":0.1052631579,\"overlap\":0.25,\"jaccard\":0.0555555556}]\n",
      "0.1349795396\t[\"for - of\",{\"cosine\":0.1290994449,\"dice\":0.1052631579,\"overlap\":0.25,\"jaccard\":0.0555555556}]\n",
      "0.1349795396\t[\"of - religious\",{\"cosine\":0.1290994449,\"dice\":0.1052631579,\"overlap\":0.25,\"jaccard\":0.0555555556}]\n",
      "0.1349795396\t[\"of - wales\",{\"cosine\":0.1290994449,\"dice\":0.1052631579,\"overlap\":0.25,\"jaccard\":0.0555555556}]\n",
      "0.1263736264\t[\"in - the\",{\"cosine\":0.1428571429,\"dice\":0.1428571429,\"overlap\":0.1428571429,\"jaccard\":0.0769230769}]\n"
     ]
    }
   ],
   "source": [
    "# test similarity.py locally after making the changes needed for -r hadoop\n",
    "!python similarity.py -r local test_index.txt | sort -k1,1nr #> test_similarity.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1: unit/systems test first-10-lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing googlebooks-eng-all-5gram-20090715-0-filtered-first-10-lines.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile googlebooks-eng-all-5gram-20090715-0-filtered-first-10-lines.txt\n",
    "A BILL FOR ESTABLISHING RELIGIOUS\t59\t59\t54\n",
    "A Biography of General George\t92\t90\t74\n",
    "A Case Study in Government\t102\t102\t78\n",
    "A Case Study of Female\t447\t447\t327\n",
    "A Case Study of Limited\t55\t55\t43\n",
    "A Child's Christmas in Wales\t1099\t1061\t866\n",
    "A Circumstantial Narrative of the\t62\t62\t50\n",
    "A City by the Sea\t62\t60\t49\n",
    "A Collection of Fairy Tales\t123\t117\t80\n",
    "A Collection of Forms of\t116\t103\t82"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2: unit/systems test atlas-boon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting atlas-boon-systems-test.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile atlas-boon-systems-test.txt\n",
    "atlas boon\t50\t50\t50\n",
    "boon cava dipped\t10\t10\t10\n",
    "atlas dipped\t15\t15\t15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3: systems test stripes-docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"DocA\"\t{\"X\":20, \"Y\":30, \"Z\":5}\r\n",
      "\"DocB\"\t{\"X\":100, \"Y\":20}\r\n",
      "\"DocC\"\t{\"M\":5, \"N\":20, \"Z\":5, \"Y\":1}\r\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "# Stripes for systems test 3 (given, no need to build stripes)\n",
    "########################################################################\n",
    "\n",
    "with open(\"systems_test_stripes_3\", \"w\") as f:\n",
    "    f.writelines([\n",
    "        '\"DocA\"\\t{\"X\":20, \"Y\":30, \"Z\":5}\\n',\n",
    "        '\"DocB\"\\t{\"X\":100, \"Y\":20}\\n',  \n",
    "        '\"DocC\"\\t{\"M\":5, \"N\":20, \"Z\":5, \"Y\":1}\\n'\n",
    "    ])\n",
    "!cat systems_test_stripes_3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Build the stripes for the 3 tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup the HDFS variables and pathes per James' example\n",
    "import os\n",
    "USER = !whoami\n",
    "USER = USER[0]\n",
    "OUTPUT_PATH_BASE = '/user/{USER}'.format(USER=USER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 items\r\n",
      "drwx------   - jenncasper users          0 2017-10-13 00:55 /user/jenncasper/.Trash\r\n",
      "drwx------   - jenncasper users          0 2017-10-12 06:26 /user/jenncasper/.staging\r\n",
      "drwxr-xr-x   - jenncasper users          0 2017-09-27 20:17 /user/jenncasper/apps\r\n",
      "drwxr-xr-x   - jenncasper users          0 2017-10-11 22:56 /user/jenncasper/hw540_outputs\r\n",
      "drwxr-xr-x   - jenncasper users          0 2017-10-11 14:24 /user/jenncasper/hw541_outputs\r\n",
      "drwxr-xr-x   - jenncasper users          0 2017-10-13 00:55 /user/jenncasper/hw550_outputs\r\n",
      "drwxr-xr-x   - jenncasper users          0 2017-10-09 01:06 /user/jenncasper/tests\r\n",
      "drwxr-xr-x   - jenncasper users          0 2017-10-04 16:14 /user/jenncasper/tmp\r\n"
     ]
    }
   ],
   "source": [
    "# list the output directories\n",
    "!hadoop fs -ls /user/jenncasper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/10/11 22:25:01 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 5760 minutes, Emptier interval = 360 minutes.\n",
      "Moved: 'hdfs://nn-ia.s3s.altiscale.com:8020/user/jenncasper/hw540_outputs/systems_test_stripes_1' to trash at: hdfs://nn-ia.s3s.altiscale.com:8020/user/jenncasper/.Trash/Current\n",
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /tmp/buildStripes.jenncasper.20171011.222503.547584\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/jenncasper/tmp/mrjob/buildStripes.jenncasper.20171011.222503.547584/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 1...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob2244085720357779387.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1506640654827_2705\n",
      "  Submitted application application_1506640654827_2705\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1506640654827_2705/\n",
      "  Running job: job_1506640654827_2705\n",
      "  Job job_1506640654827_2705 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1506640654827_2705 completed successfully\n",
      "  Output directory: hdfs:///user/jenncasper/hw540_outputs/systems_test_stripes_1\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=563\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=2408\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=1072\n",
      "\t\tFILE: Number of bytes written=400388\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=1027\n",
      "\t\tHDFS: Number of bytes written=2408\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=16114176\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=14169600\n",
      "\t\tTotal time spent by all map tasks (ms)=10491\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=31473\n",
      "\t\tTotal time spent by all reduce tasks (ms)=5535\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=27675\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=10491\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=5535\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2420\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=272\n",
      "\t\tInput split bytes=464\n",
      "\t\tMap input records=10\n",
      "\t\tMap output bytes=2975\n",
      "\t\tMap output materialized bytes=1088\n",
      "\t\tMap output records=49\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1892081664\n",
      "\t\tReduce input groups=49\n",
      "\t\tReduce input records=49\n",
      "\t\tReduce output records=28\n",
      "\t\tReduce shuffle bytes=1088\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=98\n",
      "\t\tTotal committed heap usage (bytes)=2246049792\n",
      "\t\tVirtual memory (bytes) snapshot=11409936384\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Removing HDFS temp directory hdfs:///user/jenncasper/tmp/mrjob/buildStripes.jenncasper.20171011.222503.547584...\n",
      "Removing temp directory /tmp/buildStripes.jenncasper.20171011.222503.547584...\n"
     ]
    }
   ],
   "source": [
    "# buildStripes for systems_test_stripes_1\n",
    "!hadoop fs -rm -r hw540_outputs/systems_test_stripes_1\n",
    "OUTPUT_PATH = os.path.join(OUTPUT_PATH_BASE,'hw540_outputs/systems_test_stripes_1')\n",
    "!python buildStripes.py \\\n",
    "    -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered-first-10-lines.txt \\\n",
    "    --output-dir={OUTPUT_PATH} \\\n",
    "    --no-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "-rw-r--r--   3 jenncasper users          0 2017-10-11 22:26 /user/jenncasper/hw540_outputs/systems_test_stripes_1/_SUCCESS\n",
      "-rw-r--r--   3 jenncasper users       2408 2017-10-11 22:26 /user/jenncasper/hw540_outputs/systems_test_stripes_1/part-00000\n",
      "\"a\"\t{\"limited\": 55, \"bill\": 59, \"sea\": 62, \"study\": 604, \"government\": 102, \"collection\": 239, \"general\": 92, \"female\": 447, \"in\": 1201, \"establishing\": 59, \"religious\": 59, \"george\": 92, \"biography\": 92, \"case\": 604, \"city\": 62, \"circumstantial\": 62, \"fairy\": 123, \"for\": 59, \"of\": 1011, \"tales\": 123, \"child's\": 1099, \"by\": 62, \"forms\": 116, \"narrative\": 62, \"wales\": 1099, \"the\": 124, \"christmas\": 1099}\n",
      "\"bill\"\t{\"a\": 59, \"religious\": 59, \"for\": 59, \"establishing\": 59}\n",
      "\"biography\"\t{\"a\": 92, \"of\": 92, \"george\": 92, \"general\": 92}\n",
      "\"by\"\t{\"a\": 62, \"city\": 62, \"the\": 62, \"sea\": 62}\n",
      "\"case\"\t{\"a\": 604, \"limited\": 55, \"female\": 447, \"government\": 102, \"of\": 502, \"study\": 604, \"in\": 102}\n",
      "\"child's\"\t{\"a\": 1099, \"wales\": 1099, \"christmas\": 1099, \"in\": 1099}\n",
      "\"christmas\"\t{\"a\": 1099, \"wales\": 1099, \"child's\": 1099, \"in\": 1099}\n",
      "\"circumstantial\"\t{\"a\": 62, \"of\": 62, \"the\": 62, \"narrative\": 62}\n",
      "\"city\"\t{\"a\": 62, \"the\": 62, \"by\": 62, \"sea\": 62}\n",
      "\"collection\"\t{\"a\": 239, \"of\": 355, \"fairy\": 123, \"tales\": 123, \"forms\": 116}\n",
      "\"establishing\"\t{\"a\": 59, \"bill\": 59, \"religious\": 59, \"for\": 59}\n",
      "\"fairy\"\t{\"a\": 123, \"of\": 123, \"tales\": 123, \"collection\": 123}\n",
      "\"female\"\t{\"a\": 447, \"case\": 447, \"study\": 447, \"of\": 447}\n",
      "\"for\"\t{\"a\": 59, \"bill\": 59, \"religious\": 59, \"establishing\": 59}\n",
      "\"forms\"\t{\"a\": 116, \"of\": 232, \"collection\": 116}\n",
      "\"general\"\t{\"a\": 92, \"of\": 92, \"george\": 92, \"biography\": 92}\n",
      "\"george\"\t{\"a\": 92, \"of\": 92, \"biography\": 92, \"general\": 92}\n",
      "\"government\"\t{\"a\": 102, \"case\": 102, \"study\": 102, \"in\": 102}\n",
      "\"in\"\t{\"a\": 1201, \"case\": 102, \"government\": 102, \"wales\": 1099, \"study\": 102, \"child's\": 1099, \"christmas\": 1099}\n",
      "\"limited\"\t{\"a\": 55, \"case\": 55, \"study\": 55, \"of\": 55}\n",
      "\"narrative\"\t{\"a\": 62, \"of\": 62, \"the\": 62, \"circumstantial\": 62}\n",
      "\"of\"\t{\"a\": 1011, \"case\": 502, \"circumstantial\": 62, \"limited\": 55, \"the\": 62, \"tales\": 123, \"collection\": 355, \"general\": 92, \"forms\": 232, \"female\": 447, \"narrative\": 62, \"study\": 502, \"fairy\": 123, \"george\": 92, \"biography\": 92}\n",
      "\"religious\"\t{\"a\": 59, \"bill\": 59, \"for\": 59, \"establishing\": 59}\n",
      "\"sea\"\t{\"a\": 62, \"city\": 62, \"the\": 62, \"by\": 62}\n",
      "\"study\"\t{\"a\": 604, \"case\": 604, \"in\": 102, \"female\": 447, \"limited\": 55, \"of\": 502, \"government\": 102}\n",
      "\"tales\"\t{\"a\": 123, \"of\": 123, \"fairy\": 123, \"collection\": 123}\n",
      "\"the\"\t{\"a\": 124, \"city\": 62, \"circumstantial\": 62, \"sea\": 62, \"narrative\": 62, \"of\": 62, \"by\": 62}\n",
      "\"wales\"\t{\"a\": 1099, \"child's\": 1099, \"christmas\": 1099, \"in\": 1099}\n"
     ]
    }
   ],
   "source": [
    "# check the output for systems_test_stripes_1\n",
    "!hadoop fs -ls {OUTPUT_PATH}/\n",
    "!hadoop fs -cat {OUTPUT_PATH}/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/10/11 22:29:24 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 5760 minutes, Emptier interval = 360 minutes.\n",
      "Moved: 'hdfs://nn-ia.s3s.altiscale.com:8020/user/jenncasper/hw540_outputs/systems_test_stripes_2' to trash at: hdfs://nn-ia.s3s.altiscale.com:8020/user/jenncasper/.Trash/Current\n",
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /tmp/buildStripes.jenncasper.20171011.222926.646931\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/jenncasper/tmp/mrjob/buildStripes.jenncasper.20171011.222926.646931/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 1...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob5408707189646071644.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1506640654827_2706\n",
      "  Submitted application application_1506640654827_2706\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1506640654827_2706/\n",
      "  Running job: job_1506640654827_2706\n",
      "  Job job_1506640654827_2706 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1506640654827_2706 completed successfully\n",
      "  Output directory: hdfs:///user/jenncasper/hw540_outputs/systems_test_stripes_2\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=101\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=163\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=135\n",
      "\t\tFILE: Number of bytes written=398417\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=491\n",
      "\t\tHDFS: Number of bytes written=163\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=15908352\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=22223360\n",
      "\t\tTotal time spent by all map tasks (ms)=10357\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=31071\n",
      "\t\tTotal time spent by all reduce tasks (ms)=8681\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=43405\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=10357\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=8681\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2660\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=330\n",
      "\t\tInput split bytes=390\n",
      "\t\tMap input records=3\n",
      "\t\tMap output bytes=197\n",
      "\t\tMap output materialized bytes=165\n",
      "\t\tMap output records=7\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1888186368\n",
      "\t\tReduce input groups=7\n",
      "\t\tReduce input records=7\n",
      "\t\tReduce output records=4\n",
      "\t\tReduce shuffle bytes=165\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=14\n",
      "\t\tTotal committed heap usage (bytes)=2263875584\n",
      "\t\tVirtual memory (bytes) snapshot=11410087936\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Removing HDFS temp directory hdfs:///user/jenncasper/tmp/mrjob/buildStripes.jenncasper.20171011.222926.646931...\n",
      "Removing temp directory /tmp/buildStripes.jenncasper.20171011.222926.646931...\n"
     ]
    }
   ],
   "source": [
    "# buildStripes for systems_test_stripes_2\n",
    "!hadoop fs -rm -r hw540_outputs/systems_test_stripes_2\n",
    "OUTPUT_PATH = os.path.join(OUTPUT_PATH_BASE,'hw540_outputs/systems_test_stripes_2')\n",
    "!python buildStripes.py \\\n",
    "    -r hadoop atlas-boon-systems-test.txt \\\n",
    "    --output-dir={OUTPUT_PATH} \\\n",
    "    --no-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "-rw-r--r--   3 jenncasper users          0 2017-10-11 22:30 /user/jenncasper/hw540_outputs/systems_test_stripes_2/_SUCCESS\n",
      "-rw-r--r--   3 jenncasper users        163 2017-10-11 22:30 /user/jenncasper/hw540_outputs/systems_test_stripes_2/part-00000\n",
      "\"atlas\"\t{\"dipped\": 15, \"boon\": 50}\n",
      "\"boon\"\t{\"atlas\": 50, \"dipped\": 10, \"cava\": 10}\n",
      "\"cava\"\t{\"dipped\": 10, \"boon\": 10}\n",
      "\"dipped\"\t{\"atlas\": 15, \"boon\": 10, \"cava\": 10}\n"
     ]
    }
   ],
   "source": [
    "# check the output for systems_test_stripes_2\n",
    "!hadoop fs -ls {OUTPUT_PATH}/\n",
    "!hadoop fs -cat {OUTPUT_PATH}/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stripes for systems_test_stripes_3 ready in the file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Build the inverted indexes for the 3 tests and pretty print the output kept in HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/10/11 22:31:40 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 5760 minutes, Emptier interval = 360 minutes.\n",
      "Moved: 'hdfs://nn-ia.s3s.altiscale.com:8020/user/jenncasper/hw540_outputs/systems_test_index_1' to trash at: hdfs://nn-ia.s3s.altiscale.com:8020/user/jenncasper/.Trash/Current\n",
      "No configs found; falling back on auto-configuration\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Creating temp directory /tmp/invertedIndex.jenncasper.20171011.223142.447836\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/jenncasper/tmp/mrjob/invertedIndex.jenncasper.20171011.223142.447836/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 1...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob9134337919392028332.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1506640654827_2708\n",
      "  Submitted application application_1506640654827_2708\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1506640654827_2708/\n",
      "  Running job: job_1506640654827_2708\n",
      "  Job job_1506640654827_2708 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1506640654827_2708 completed successfully\n",
      "  Output directory: hdfs:///user/jenncasper/hw540_outputs/systems_test_index_1\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=3612\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=2508\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=1333\n",
      "\t\tFILE: Number of bytes written=400873\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=3914\n",
      "\t\tHDFS: Number of bytes written=2508\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=24895488\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=8161280\n",
      "\t\tTotal time spent by all map tasks (ms)=16208\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=48624\n",
      "\t\tTotal time spent by all reduce tasks (ms)=3188\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=15940\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=16208\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=3188\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2530\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=244\n",
      "\t\tInput split bytes=302\n",
      "\t\tMap input records=28\n",
      "\t\tMap output bytes=3466\n",
      "\t\tMap output materialized bytes=1552\n",
      "\t\tMap output records=158\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1903767552\n",
      "\t\tReduce input groups=158\n",
      "\t\tReduce input records=158\n",
      "\t\tReduce output records=28\n",
      "\t\tReduce shuffle bytes=1552\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=316\n",
      "\t\tTotal committed heap usage (bytes)=2163212288\n",
      "\t\tVirtual memory (bytes) snapshot=11412033536\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Removing HDFS temp directory hdfs:///user/jenncasper/tmp/mrjob/invertedIndex.jenncasper.20171011.223142.447836...\n",
      "Removing temp directory /tmp/invertedIndex.jenncasper.20171011.223142.447836...\n"
     ]
    }
   ],
   "source": [
    "# invertedIndex for systems_test_index_1\n",
    "!hadoop fs -rm -r hw540_outputs/systems_test_index_1\n",
    "INPUT_PATH = os.path.join('hdfs:///', OUTPUT_PATH_BASE[1:],'hw540_outputs/systems_test_stripes_1')\n",
    "OUTPUT_PATH = os.path.join(OUTPUT_PATH_BASE, 'hw540_outputs/systems_test_index_1')\n",
    "!python invertedIndex.py \\\n",
    "    -r hadoop {INPUT_PATH} \\\n",
    "    --output-dir={OUTPUT_PATH} \\\n",
    "    --no-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "-rw-r--r--   3 jenncasper users          0 2017-10-11 22:33 /user/jenncasper/hw540_outputs/systems_test_index_1/_SUCCESS\n",
      "-rw-r--r--   3 jenncasper users       2508 2017-10-11 22:33 /user/jenncasper/hw540_outputs/systems_test_index_1/part-00000\n",
      "\"a\"\t[[\"of\", 15], [\"government\", 4], [\"in\", 7], [\"wales\", 4], [\"narrative\", 4], [\"general\", 4], [\"forms\", 3], [\"limited\", 4], [\"religious\", 4], [\"the\", 7], [\"george\", 4], [\"sea\", 4], [\"study\", 7], [\"tales\", 4], [\"by\", 4], [\"collection\", 5], [\"for\", 4], [\"case\", 7], [\"female\", 4], [\"biography\", 4], [\"child's\", 4], [\"bill\", 4], [\"fairy\", 4], [\"christmas\", 4], [\"circumstantial\", 4], [\"establishing\", 4], [\"city\", 4]]\n",
      "\"bill\"\t[[\"establishing\", 4], [\"for\", 4], [\"a\", 27], [\"religious\", 4]]\n",
      "\"biography\"\t[[\"of\", 15], [\"general\", 4], [\"george\", 4], [\"a\", 27]]\n",
      "\"by\"\t[[\"city\", 4], [\"a\", 27], [\"the\", 7], [\"sea\", 4]]\n",
      "\"case\"\t[[\"of\", 15], [\"study\", 7], [\"in\", 7], [\"government\", 4], [\"limited\", 4], [\"a\", 27], [\"female\", 4]]\n",
      "\"child's\"\t[[\"christmas\", 4], [\"a\", 27], [\"wales\", 4], [\"in\", 7]]\n",
      "\"christmas\"\t[[\"wales\", 4], [\"in\", 7], [\"a\", 27], [\"child's\", 4]]\n",
      "\"circumstantial\"\t[[\"a\", 27], [\"narrative\", 4], [\"the\", 7], [\"of\", 15]]\n",
      "\"city\"\t[[\"sea\", 4], [\"the\", 7], [\"by\", 4], [\"a\", 27]]\n",
      "\"collection\"\t[[\"fairy\", 4], [\"a\", 27], [\"tales\", 4], [\"forms\", 3], [\"of\", 15]]\n",
      "\"establishing\"\t[[\"religious\", 4], [\"for\", 4], [\"bill\", 4], [\"a\", 27]]\n",
      "\"fairy\"\t[[\"collection\", 5], [\"a\", 27], [\"of\", 15], [\"tales\", 4]]\n",
      "\"female\"\t[[\"of\", 15], [\"study\", 7], [\"a\", 27], [\"case\", 7]]\n",
      "\"for\"\t[[\"establishing\", 4], [\"a\", 27], [\"bill\", 4], [\"religious\", 4]]\n",
      "\"forms\"\t[[\"of\", 15], [\"collection\", 5], [\"a\", 27]]\n",
      "\"general\"\t[[\"a\", 27], [\"biography\", 4], [\"of\", 15], [\"george\", 4]]\n",
      "\"george\"\t[[\"general\", 4], [\"of\", 15], [\"biography\", 4], [\"a\", 27]]\n",
      "\"government\"\t[[\"case\", 7], [\"a\", 27], [\"study\", 7], [\"in\", 7]]\n",
      "\"in\"\t[[\"study\", 7], [\"wales\", 4], [\"government\", 4], [\"case\", 7], [\"christmas\", 4], [\"a\", 27], [\"child's\", 4]]\n",
      "\"limited\"\t[[\"a\", 27], [\"case\", 7], [\"of\", 15], [\"study\", 7]]\n",
      "\"narrative\"\t[[\"of\", 15], [\"the\", 7], [\"a\", 27], [\"circumstantial\", 4]]\n",
      "\"of\"\t[[\"biography\", 4], [\"case\", 7], [\"a\", 27], [\"circumstantial\", 4], [\"collection\", 5], [\"fairy\", 4], [\"female\", 4], [\"limited\", 4], [\"george\", 4], [\"narrative\", 4], [\"study\", 7], [\"tales\", 4], [\"general\", 4], [\"the\", 7], [\"forms\", 3]]\n",
      "\"religious\"\t[[\"a\", 27], [\"for\", 4], [\"bill\", 4], [\"establishing\", 4]]\n",
      "\"sea\"\t[[\"by\", 4], [\"city\", 4], [\"a\", 27], [\"the\", 7]]\n",
      "\"study\"\t[[\"of\", 15], [\"government\", 4], [\"in\", 7], [\"limited\", 4], [\"female\", 4], [\"case\", 7], [\"a\", 27]]\n",
      "\"tales\"\t[[\"fairy\", 4], [\"collection\", 5], [\"a\", 27], [\"of\", 15]]\n",
      "\"the\"\t[[\"narrative\", 4], [\"sea\", 4], [\"of\", 15], [\"city\", 4], [\"by\", 4], [\"a\", 27], [\"circumstantial\", 4]]\n",
      "\"wales\"\t[[\"christmas\", 4], [\"child's\", 4], [\"a\", 27], [\"in\", 7]]\n"
     ]
    }
   ],
   "source": [
    "# check the output for systems_test_index_1\n",
    "!hadoop fs -ls {OUTPUT_PATH}/\n",
    "!hadoop fs -cat {OUTPUT_PATH}/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/10/11 22:35:11 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 5760 minutes, Emptier interval = 360 minutes.\n",
      "Moved: 'hdfs://nn-ia.s3s.altiscale.com:8020/user/jenncasper/hw540_outputs/systems_test_index_2' to trash at: hdfs://nn-ia.s3s.altiscale.com:8020/user/jenncasper/.Trash/Current\n",
      "No configs found; falling back on auto-configuration\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Creating temp directory /tmp/invertedIndex.jenncasper.20171011.223512.374619\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/jenncasper/tmp/mrjob/invertedIndex.jenncasper.20171011.223512.374619/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 1...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob2343132119121872506.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1506640654827_2710\n",
      "  Submitted application application_1506640654827_2710\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1506640654827_2710/\n",
      "  Running job: job_1506640654827_2710\n",
      "  Job job_1506640654827_2710 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1506640654827_2710 completed successfully\n",
      "  Output directory: hdfs:///user/jenncasper/hw540_outputs/systems_test_index_2\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=245\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=173\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=145\n",
      "\t\tFILE: Number of bytes written=398323\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=547\n",
      "\t\tHDFS: Number of bytes written=173\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=15435264\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=7022080\n",
      "\t\tTotal time spent by all map tasks (ms)=10049\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=30147\n",
      "\t\tTotal time spent by all reduce tasks (ms)=2743\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=13715\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=10049\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=2743\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2290\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=200\n",
      "\t\tInput split bytes=302\n",
      "\t\tMap input records=4\n",
      "\t\tMap output bytes=216\n",
      "\t\tMap output materialized bytes=190\n",
      "\t\tMap output records=10\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1889005568\n",
      "\t\tReduce input groups=10\n",
      "\t\tReduce input records=10\n",
      "\t\tReduce output records=4\n",
      "\t\tReduce shuffle bytes=190\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=20\n",
      "\t\tTotal committed heap usage (bytes)=2220883968\n",
      "\t\tVirtual memory (bytes) snapshot=11406987264\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Removing HDFS temp directory hdfs:///user/jenncasper/tmp/mrjob/invertedIndex.jenncasper.20171011.223512.374619...\n",
      "Removing temp directory /tmp/invertedIndex.jenncasper.20171011.223512.374619...\n"
     ]
    }
   ],
   "source": [
    "# invertedIndex for systems_test_index_2\n",
    "!hadoop fs -rm -r hw540_outputs/systems_test_index_2\n",
    "INPUT_PATH = os.path.join('hdfs:///', OUTPUT_PATH_BASE[1:],'hw540_outputs/systems_test_stripes_2')\n",
    "OUTPUT_PATH = os.path.join(OUTPUT_PATH_BASE, 'hw540_outputs/systems_test_index_2')\n",
    "!python invertedIndex.py \\\n",
    "    -r hadoop {INPUT_PATH} \\\n",
    "    --output-dir={OUTPUT_PATH} \\\n",
    "    --no-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "-rw-r--r--   3 jenncasper users          0 2017-10-11 22:36 /user/jenncasper/hw540_outputs/systems_test_index_2/_SUCCESS\n",
      "-rw-r--r--   3 jenncasper users        173 2017-10-11 22:36 /user/jenncasper/hw540_outputs/systems_test_index_2/part-00000\n",
      "\"atlas\"\t[[\"boon\", 3], [\"dipped\", 3]]\n",
      "\"boon\"\t[[\"dipped\", 3], [\"cava\", 2], [\"atlas\", 2]]\n",
      "\"cava\"\t[[\"boon\", 3], [\"dipped\", 3]]\n",
      "\"dipped\"\t[[\"cava\", 2], [\"boon\", 3], [\"atlas\", 2]]\n"
     ]
    }
   ],
   "source": [
    "# check the output for systems_test_index_2\n",
    "!hadoop fs -ls {OUTPUT_PATH}/\n",
    "!hadoop fs -cat {OUTPUT_PATH}/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/10/11 22:40:09 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 5760 minutes, Emptier interval = 360 minutes.\n",
      "Moved: 'hdfs://nn-ia.s3s.altiscale.com:8020/user/jenncasper/hw540_outputs/systems_test_index_3' to trash at: hdfs://nn-ia.s3s.altiscale.com:8020/user/jenncasper/.Trash/Current\n",
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /tmp/invertedIndex.jenncasper.20171011.224010.362737\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/jenncasper/tmp/mrjob/invertedIndex.jenncasper.20171011.224010.362737/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 1...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob219257686767158106.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1506640654827_2712\n",
      "  Submitted application application_1506640654827_2712\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1506640654827_2712/\n",
      "  Running job: job_1506640654827_2712\n",
      "  Job job_1506640654827_2712 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1506640654827_2712 completed successfully\n",
      "  Output directory: hdfs:///user/jenncasper/hw540_outputs/systems_test_index_3\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=140\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=142\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=101\n",
      "\t\tFILE: Number of bytes written=398356\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=522\n",
      "\t\tHDFS: Number of bytes written=142\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=8573952\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=15843840\n",
      "\t\tTotal time spent by all map tasks (ms)=5582\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=16746\n",
      "\t\tTotal time spent by all reduce tasks (ms)=6189\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=30945\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=5582\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=6189\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2610\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=228\n",
      "\t\tInput split bytes=382\n",
      "\t\tMap input records=3\n",
      "\t\tMap output bytes=153\n",
      "\t\tMap output materialized bytes=120\n",
      "\t\tMap output records=9\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1908436992\n",
      "\t\tReduce input groups=9\n",
      "\t\tReduce input records=9\n",
      "\t\tReduce output records=5\n",
      "\t\tReduce shuffle bytes=120\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=18\n",
      "\t\tTotal committed heap usage (bytes)=2281701376\n",
      "\t\tVirtual memory (bytes) snapshot=11416125440\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Removing HDFS temp directory hdfs:///user/jenncasper/tmp/mrjob/invertedIndex.jenncasper.20171011.224010.362737...\n",
      "Removing temp directory /tmp/invertedIndex.jenncasper.20171011.224010.362737...\n"
     ]
    }
   ],
   "source": [
    "# invertedIndex for systems_test_index_3\n",
    "!hadoop fs -rm -r hw540_outputs/systems_test_index_3\n",
    "OUTPUT_PATH = os.path.join(OUTPUT_PATH_BASE, 'hw540_outputs/systems_test_index_3')\n",
    "!python invertedIndex.py \\\n",
    "    -r hadoop systems_test_stripes_3 \\\n",
    "    --output-dir={OUTPUT_PATH} \\\n",
    "    --no-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "-rw-r--r--   3 jenncasper users          0 2017-10-11 22:41 /user/jenncasper/hw540_outputs/systems_test_index_3/_SUCCESS\n",
      "-rw-r--r--   3 jenncasper users        142 2017-10-11 22:41 /user/jenncasper/hw540_outputs/systems_test_index_3/part-00000\n",
      "\"M\"\t[[\"DocC\", 4]]\n",
      "\"N\"\t[[\"DocC\", 4]]\n",
      "\"X\"\t[[\"DocB\", 2], [\"DocA\", 3]]\n",
      "\"Y\"\t[[\"DocB\", 2], [\"DocA\", 3], [\"DocC\", 4]]\n",
      "\"Z\"\t[[\"DocC\", 4], [\"DocA\", 3]]\n"
     ]
    }
   ],
   "source": [
    "# check the output for systems_test_index_3\n",
    "!hadoop fs -ls {OUTPUT_PATH}/\n",
    "!hadoop fs -cat {OUTPUT_PATH}/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Systems test  1  - Inverted Index\n",
      "\n",
      "             \"a\" |          bill 4 |     biography 4 |            by 4\n",
      "          \"bill\" |            a 27 |  establishing 4 |           for 4\n",
      "     \"biography\" |            a 27 |       general 4 |        george 4\n",
      "            \"by\" |            a 27 |          city 4 |           sea 4\n",
      "          \"case\" |            a 27 |        female 4 |    government 4\n",
      "       \"child's\" |            a 27 |     christmas 4 |            in 7\n",
      "     \"christmas\" |            a 27 |       child's 4 |            in 7\n",
      "\"circumstantial\" |            a 27 |     narrative 4 |           of 15\n",
      "          \"city\" |            a 27 |            by 4 |           sea 4\n",
      "    \"collection\" |            a 27 |         fairy 4 |         forms 3\n",
      "  \"establishing\" |            a 27 |          bill 4 |           for 4\n",
      "         \"fairy\" |            a 27 |    collection 5 |           of 15\n",
      "        \"female\" |            a 27 |          case 7 |           of 15\n",
      "           \"for\" |            a 27 |          bill 4 |  establishing 4\n",
      "         \"forms\" |            a 27 |    collection 5 |           of 15\n",
      "       \"general\" |            a 27 |     biography 4 |        george 4\n",
      "        \"george\" |            a 27 |     biography 4 |       general 4\n",
      "    \"government\" |            a 27 |          case 7 |            in 7\n",
      "            \"in\" |            a 27 |          case 7 |       child's 4\n",
      "       \"limited\" |            a 27 |          case 7 |           of 15\n",
      "     \"narrative\" |            a 27 |circumstantial 4 |           of 15\n",
      "            \"of\" |            a 27 |     biography 4 |          case 7\n",
      "     \"religious\" |            a 27 |          bill 4 |  establishing 4\n",
      "           \"sea\" |            a 27 |            by 4 |          city 4\n",
      "         \"study\" |            a 27 |          case 7 |        female 4\n",
      "         \"tales\" |            a 27 |    collection 5 |         fairy 4\n",
      "           \"the\" |            a 27 |            by 4 |circumstantial 4\n",
      "         \"wales\" |            a 27 |       child's 4 |     christmas 4\n",
      "\n",
      "Systems test  2  - Inverted Index\n",
      "\n",
      "         \"atlas\" |          boon 3 |        dipped 3 |                \n",
      "          \"boon\" |         atlas 2 |          cava 2 |        dipped 3\n",
      "          \"cava\" |          boon 3 |        dipped 3 |                \n",
      "        \"dipped\" |         atlas 2 |          boon 3 |          cava 2\n",
      "\n",
      "Systems test  3  - Inverted Index\n",
      "\n",
      "             \"M\" |          DocC 4 |                 |                \n",
      "             \"N\" |          DocC 4 |                 |                \n",
      "             \"X\" |          DocA 3 |          DocB 2 |                \n",
      "             \"Y\" |          DocA 3 |          DocB 2 |          DocC 4\n",
      "             \"Z\" |          DocA 3 |          DocC 4 |                \n"
     ]
    }
   ],
   "source": [
    "##########################################################\n",
    "# Pretty print systems tests for generating Inverted Index from HDFS\n",
    "##########################################################\n",
    "\n",
    "import json\n",
    "import subprocess\n",
    "\n",
    "for i in range(1,4):\n",
    "    print \"\"*90\n",
    "    print \"Systems test \",i,\" - Inverted Index\"\n",
    "    print \"\"*90  \n",
    "    \n",
    "    INDEX_PATH = os.path.join(OUTPUT_PATH_BASE, 'hw540_outputs/systems_test_index_'+str(i), '*')\n",
    "    cat = subprocess.Popen([\"hadoop\", \"fs\", \"-cat\", INDEX_PATH], stdout=subprocess.PIPE)\n",
    "    for line in cat.stdout:\n",
    "        line = line.strip()\n",
    "        word,stripe = line.split(\"\\t\")\n",
    "        stripe = sorted(json.loads(stripe))\n",
    "        stripe.extend([[\"\",\"\"] for _ in xrange(3 - len(stripe))])\n",
    "        print \"{0:>16} |{1:>16} |{2:>16} |{3:>16}\".format((word), \n",
    "                                                          stripe[0][0]+\" \"+str(stripe[0][1]), \n",
    "                                                          stripe[1][0]+\" \"+str(stripe[1][1]), \n",
    "                                                          stripe[2][0]+\" \"+str(stripe[2][1]))\n",
    "        cat.wait()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Calculate the similarities for the 3 tests and pretty print the output kept in HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/10/11 22:44:25 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 5760 minutes, Emptier interval = 360 minutes.\n",
      "Moved: 'hdfs://nn-ia.s3s.altiscale.com:8020/user/jenncasper/hw540_outputs/systems_test_similarities_1' to trash at: hdfs://nn-ia.s3s.altiscale.com:8020/user/jenncasper/.Trash/Current\n",
      "No configs found; falling back on auto-configuration\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Creating temp directory /tmp/similarity.jenncasper.20171011.224427.480024\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/jenncasper/tmp/mrjob/similarity.jenncasper.20171011.224427.480024/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob1590302298502348307.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1506640654827_2717\n",
      "  Submitted application application_1506640654827_2717\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1506640654827_2717/\n",
      "  Running job: job_1506640654827_2717\n",
      "  Job job_1506640654827_2717 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1506640654827_2717 completed successfully\n",
      "  Output directory: hdfs:///user/jenncasper/tmp/mrjob/similarity.jenncasper.20171011.224427.480024/step-output/0000\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=3762\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=50923\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=5291\n",
      "\t\tFILE: Number of bytes written=410098\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=4060\n",
      "\t\tHDFS: Number of bytes written=50923\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=16250880\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=14602240\n",
      "\t\tTotal time spent by all map tasks (ms)=10580\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=31740\n",
      "\t\tTotal time spent by all reduce tasks (ms)=5704\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=28520\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=10580\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=5704\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2950\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=198\n",
      "\t\tInput split bytes=298\n",
      "\t\tMap input records=28\n",
      "\t\tMap output bytes=31309\n",
      "\t\tMap output materialized bytes=6835\n",
      "\t\tMap output records=673\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1887653888\n",
      "\t\tReduce input groups=490\n",
      "\t\tReduce input records=673\n",
      "\t\tReduce output records=378\n",
      "\t\tReduce shuffle bytes=6835\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=1346\n",
      "\t\tTotal committed heap usage (bytes)=2319450112\n",
      "\t\tVirtual memory (bytes) snapshot=11411501056\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 2 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob1462097449245872257.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1506640654827_2718\n",
      "  Submitted application application_1506640654827_2718\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1506640654827_2718/\n",
      "  Running job: job_1506640654827_2718\n",
      "  Job job_1506640654827_2718 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1506640654827_2718 completed successfully\n",
      "  Output directory: hdfs:///user/jenncasper/hw540_outputs/systems_test_similarities_1\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=76385\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=50923\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=7112\n",
      "\t\tFILE: Number of bytes written=413298\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=76759\n",
      "\t\tHDFS: Number of bytes written=50923\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=15060480\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=7462400\n",
      "\t\tTotal time spent by all map tasks (ms)=9805\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=29415\n",
      "\t\tTotal time spent by all reduce tasks (ms)=2915\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=14575\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=9805\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=2915\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2550\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=232\n",
      "\t\tInput split bytes=374\n",
      "\t\tMap input records=378\n",
      "\t\tMap output bytes=51501\n",
      "\t\tMap output materialized bytes=8390\n",
      "\t\tMap output records=378\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1892749312\n",
      "\t\tReduce input groups=378\n",
      "\t\tReduce input records=378\n",
      "\t\tReduce output records=378\n",
      "\t\tReduce shuffle bytes=8390\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=756\n",
      "\t\tTotal committed heap usage (bytes)=2265972736\n",
      "\t\tVirtual memory (bytes) snapshot=11409190912\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Removing HDFS temp directory hdfs:///user/jenncasper/tmp/mrjob/similarity.jenncasper.20171011.224427.480024...\n",
      "Removing temp directory /tmp/similarity.jenncasper.20171011.224427.480024...\n"
     ]
    }
   ],
   "source": [
    "# similarities for systems_test_similarities_1\n",
    "!hadoop fs -rm -r hw540_outputs/systems_test_similarities_1\n",
    "INPUT_PATH = os.path.join('hdfs:///', OUTPUT_PATH_BASE[1:],'hw540_outputs/systems_test_index_1')\n",
    "OUTPUT_PATH = os.path.join(OUTPUT_PATH_BASE, 'hw540_outputs/systems_test_similarities_1')\n",
    "!python similarity.py \\\n",
    "    -r hadoop {INPUT_PATH} \\\n",
    "    --output-dir={OUTPUT_PATH} \\\n",
    "    --no-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "-rw-r--r--   3 jenncasper users          0 2017-10-11 22:46 /user/jenncasper/hw540_outputs/systems_test_similarities_1/_SUCCESS\n",
      "-rw-r--r--   3 jenncasper users      50923 2017-10-11 22:46 /user/jenncasper/hw540_outputs/systems_test_similarities_1/part-00000\n",
      "1.0\t[\"female - limited\", {\"cosine\": 1.0, \"dice\": 1.0, \"overlap\": 1.0, \"jaccard\": 1.0}]\n",
      "0.86829206523182401\t[\"fairy - forms\", {\"cosine\": 0.86602540378443882, \"dice\": 0.8571428571428571, \"overlap\": 1.0, \"jaccard\": 0.75}]\n",
      "0.86829206523182401\t[\"forms - tales\", {\"cosine\": 0.86602540378443882, \"dice\": 0.8571428571428571, \"overlap\": 1.0, \"jaccard\": 0.75}]\n",
      "0.83035714285714279\t[\"case - study\", {\"cosine\": 0.85714285714285687, \"dice\": 0.8571428571428571, \"overlap\": 0.8571428571428571, \"jaccard\": 0.75}]\n",
      "0.71250000000000002\t[\"bill - for\", {\"cosine\": 0.75, \"dice\": 0.75, \"overlap\": 0.75, \"jaccard\": 0.59999999999999998}]\n",
      "0.71250000000000002\t[\"christmas - wales\", {\"cosine\": 0.75, \"dice\": 0.75, \"overlap\": 0.75, \"jaccard\": 0.59999999999999998}]\n",
      "0.71250000000000002\t[\"by - sea\", {\"cosine\": 0.75, \"dice\": 0.75, \"overlap\": 0.75, \"jaccard\": 0.59999999999999998}]\n",
      "0.71250000000000002\t[\"circumstantial - narrative\", {\"cosine\": 0.75, \"dice\": 0.75, \"overlap\": 0.75, \"jaccard\": 0.59999999999999998}]\n",
      "0.71250000000000002\t[\"by - city\", {\"cosine\": 0.75, \"dice\": 0.75, \"overlap\": 0.75, \"jaccard\": 0.59999999999999998}]\n",
      "0.71250000000000002\t[\"child's - wales\", {\"cosine\": 0.75, \"dice\": 0.75, \"overlap\": 0.75, \"jaccard\": 0.59999999999999998}]\n",
      "0.71250000000000002\t[\"biography - george\", {\"cosine\": 0.75, \"dice\": 0.75, \"overlap\": 0.75, \"jaccard\": 0.59999999999999998}]\n",
      "0.71250000000000002\t[\"biography - general\", {\"cosine\": 0.75, \"dice\": 0.75, \"overlap\": 0.75, \"jaccard\": 0.59999999999999998}]\n",
      "0.71250000000000002\t[\"child's - christmas\", {\"cosine\": 0.75, \"dice\": 0.75, \"overlap\": 0.75, \"jaccard\": 0.59999999999999998}]\n",
      "0.71250000000000002\t[\"bill - religious\", {\"cosine\": 0.75, \"dice\": 0.75, \"overlap\": 0.75, \"jaccard\": 0.59999999999999998}]\n",
      "0.71250000000000002\t[\"bill - establishing\", {\"cosine\": 0.75, \"dice\": 0.75, \"overlap\": 0.75, \"jaccard\": 0.59999999999999998}]\n",
      "0.71250000000000002\t[\"government - limited\", {\"cosine\": 0.75, \"dice\": 0.75, \"overlap\": 0.75, \"jaccard\": 0.59999999999999998}]\n",
      "0.71250000000000002\t[\"establishing - for\", {\"cosine\": 0.75, \"dice\": 0.75, \"overlap\": 0.75, \"jaccard\": 0.59999999999999998}]\n",
      "0.71250000000000002\t[\"establishing - religious\", {\"cosine\": 0.75, \"dice\": 0.75, \"overlap\": 0.75, \"jaccard\": 0.59999999999999998}]\n",
      "0.71250000000000002\t[\"city - sea\", {\"cosine\": 0.75, \"dice\": 0.75, \"overlap\": 0.75, \"jaccard\": 0.59999999999999998}]\n",
      "0.71250000000000002\t[\"fairy - tales\", {\"cosine\": 0.75, \"dice\": 0.75, \"overlap\": 0.75, \"jaccard\": 0.59999999999999998}]\n",
      "0.71250000000000002\t[\"female - government\", {\"cosine\": 0.75, \"dice\": 0.75, \"overlap\": 0.75, \"jaccard\": 0.59999999999999998}]\n",
      "0.71250000000000002\t[\"for - religious\", {\"cosine\": 0.75, \"dice\": 0.75, \"overlap\": 0.75, \"jaccard\": 0.59999999999999998}]\n",
      "0.71250000000000002\t[\"general - george\", {\"cosine\": 0.75, \"dice\": 0.75, \"overlap\": 0.75, \"jaccard\": 0.59999999999999998}]\n",
      "0.69891639824998364\t[\"a - of\", {\"cosine\": 0.69566559299993458, \"dice\": 0.66666666666666663, \"overlap\": 0.93333333333333335, \"jaccard\": 0.5}]\n",
      "0.64687176497915089\t[\"collection - fairy\", {\"cosine\": 0.67082039324993692, \"dice\": 0.66666666666666663, \"overlap\": 0.75, \"jaccard\": 0.5}]\n",
      "0.64687176497915089\t[\"collection - tales\", {\"cosine\": 0.67082039324993692, \"dice\": 0.66666666666666663, \"overlap\": 0.75, \"jaccard\": 0.5}]\n",
      "0.55935031374209654\t[\"city - the\", {\"cosine\": 0.56694670951384074, \"dice\": 0.54545454545454541, \"overlap\": 0.75, \"jaccard\": 0.375}]\n",
      "0.55935031374209654\t[\"government - study\", {\"cosine\": 0.56694670951384074, \"dice\": 0.54545454545454541, \"overlap\": 0.75, \"jaccard\": 0.375}]\n",
      "0.55935031374209654\t[\"narrative - the\", {\"cosine\": 0.56694670951384074, \"dice\": 0.54545454545454541, \"overlap\": 0.75, \"jaccard\": 0.375}]\n",
      "0.55935031374209654\t[\"female - in\", {\"cosine\": 0.56694670951384074, \"dice\": 0.54545454545454541, \"overlap\": 0.75, \"jaccard\": 0.375}]\n",
      "0.55935031374209654\t[\"limited - study\", {\"cosine\": 0.56694670951384074, \"dice\": 0.54545454545454541, \"overlap\": 0.75, \"jaccard\": 0.375}]\n",
      "0.55935031374209654\t[\"female - study\", {\"cosine\": 0.56694670951384074, \"dice\": 0.54545454545454541, \"overlap\": 0.75, \"jaccard\": 0.375}]\n",
      "0.55935031374209654\t[\"in - wales\", {\"cosine\": 0.56694670951384074, \"dice\": 0.54545454545454541, \"overlap\": 0.75, \"jaccard\": 0.375}]\n",
      "0.55935031374209654\t[\"government - in\", {\"cosine\": 0.56694670951384074, \"dice\": 0.54545454545454541, \"overlap\": 0.75, \"jaccard\": 0.375}]\n",
      "0.55935031374209654\t[\"sea - the\", {\"cosine\": 0.56694670951384074, \"dice\": 0.54545454545454541, \"overlap\": 0.75, \"jaccard\": 0.375}]\n",
      "0.55935031374209654\t[\"in - limited\", {\"cosine\": 0.56694670951384074, \"dice\": 0.54545454545454541, \"overlap\": 0.75, \"jaccard\": 0.375}]\n",
      "0.55935031374209654\t[\"case - government\", {\"cosine\": 0.56694670951384074, \"dice\": 0.54545454545454541, \"overlap\": 0.75, \"jaccard\": 0.375}]\n",
      "0.55935031374209654\t[\"case - female\", {\"cosine\": 0.56694670951384074, \"dice\": 0.54545454545454541, \"overlap\": 0.75, \"jaccard\": 0.375}]\n",
      "0.55935031374209654\t[\"child's - in\", {\"cosine\": 0.56694670951384074, \"dice\": 0.54545454545454541, \"overlap\": 0.75, \"jaccard\": 0.375}]\n",
      "0.55935031374209654\t[\"by - the\", {\"cosine\": 0.56694670951384074, \"dice\": 0.54545454545454541, \"overlap\": 0.75, \"jaccard\": 0.375}]\n",
      "0.55935031374209654\t[\"case - limited\", {\"cosine\": 0.56694670951384074, \"dice\": 0.54545454545454541, \"overlap\": 0.75, \"jaccard\": 0.375}]\n",
      "0.55935031374209654\t[\"christmas - in\", {\"cosine\": 0.56694670951384074, \"dice\": 0.54545454545454541, \"overlap\": 0.75, \"jaccard\": 0.375}]\n",
      "0.55935031374209654\t[\"circumstantial - the\", {\"cosine\": 0.56694670951384074, \"dice\": 0.54545454545454541, \"overlap\": 0.75, \"jaccard\": 0.375}]\n",
      "0.55386137682121594\t[\"biography - forms\", {\"cosine\": 0.57735026918962584, \"dice\": 0.5714285714285714, \"overlap\": 0.66666666666666663, \"jaccard\": 0.40000000000000002}]\n",
      "0.55386137682121594\t[\"circumstantial - forms\", {\"cosine\": 0.57735026918962584, \"dice\": 0.5714285714285714, \"overlap\": 0.66666666666666663, \"jaccard\": 0.40000000000000002}]\n",
      "0.55386137682121594\t[\"forms - general\", {\"cosine\": 0.57735026918962584, \"dice\": 0.5714285714285714, \"overlap\": 0.66666666666666663, \"jaccard\": 0.40000000000000002}]\n",
      "0.55386137682121594\t[\"forms - george\", {\"cosine\": 0.57735026918962584, \"dice\": 0.5714285714285714, \"overlap\": 0.66666666666666663, \"jaccard\": 0.40000000000000002}]\n",
      "0.55386137682121594\t[\"forms - limited\", {\"cosine\": 0.57735026918962584, \"dice\": 0.5714285714285714, \"overlap\": 0.66666666666666663, \"jaccard\": 0.40000000000000002}]\n",
      "0.55386137682121594\t[\"forms - narrative\", {\"cosine\": 0.57735026918962584, \"dice\": 0.5714285714285714, \"overlap\": 0.66666666666666663, \"jaccard\": 0.40000000000000002}]\n",
      "0.55386137682121594\t[\"female - forms\", {\"cosine\": 0.57735026918962584, \"dice\": 0.5714285714285714, \"overlap\": 0.66666666666666663, \"jaccard\": 0.40000000000000002}]\n",
      "0.5040994448735806\t[\"collection - forms\", {\"cosine\": 0.51639777949432231, \"dice\": 0.5, \"overlap\": 0.66666666666666663, \"jaccard\": 0.33333333333333331}]\n",
      "0.47797005383792512\t[\"collection - of\", {\"cosine\": 0.46188021535170054, \"dice\": 0.40000000000000002, \"overlap\": 0.80000000000000004, \"jaccard\": 0.25}]\n",
      "0.46520138209278611\t[\"a - study\", {\"cosine\": 0.43643578047198478, \"dice\": 0.35294117647058826, \"overlap\": 0.8571428571428571, \"jaccard\": 0.21428571428571427}]\n",
      "0.46520138209278611\t[\"a - case\", {\"cosine\": 0.43643578047198478, \"dice\": 0.35294117647058826, \"overlap\": 0.8571428571428571, \"jaccard\": 0.21428571428571427}]\n",
      "0.46520138209278611\t[\"a - the\", {\"cosine\": 0.43643578047198478, \"dice\": 0.35294117647058826, \"overlap\": 0.8571428571428571, \"jaccard\": 0.21428571428571427}]\n",
      "0.46520138209278611\t[\"a - in\", {\"cosine\": 0.43643578047198478, \"dice\": 0.35294117647058826, \"overlap\": 0.8571428571428571, \"jaccard\": 0.21428571428571427}]\n",
      "0.45833333333333331\t[\"circumstantial - city\", {\"cosine\": 0.5, \"dice\": 0.5, \"overlap\": 0.5, \"jaccard\": 0.33333333333333331}]\n",
      "0.45833333333333331\t[\"circumstantial - fairy\", {\"cosine\": 0.5, \"dice\": 0.5, \"overlap\": 0.5, \"jaccard\": 0.33333333333333331}]\n",
      "0.45833333333333331\t[\"biography - circumstantial\", {\"cosine\": 0.5, \"dice\": 0.5, \"overlap\": 0.5, \"jaccard\": 0.33333333333333331}]\n",
      "0.45833333333333331\t[\"biography - fairy\", {\"cosine\": 0.5, \"dice\": 0.5, \"overlap\": 0.5, \"jaccard\": 0.33333333333333331}]\n",
      "0.45833333333333331\t[\"biography - female\", {\"cosine\": 0.5, \"dice\": 0.5, \"overlap\": 0.5, \"jaccard\": 0.33333333333333331}]\n",
      "0.45833333333333331\t[\"circumstantial - female\", {\"cosine\": 0.5, \"dice\": 0.5, \"overlap\": 0.5, \"jaccard\": 0.33333333333333331}]\n",
      "0.45833333333333331\t[\"christmas - government\", {\"cosine\": 0.5, \"dice\": 0.5, \"overlap\": 0.5, \"jaccard\": 0.33333333333333331}]\n",
      "0.45833333333333331\t[\"circumstantial - general\", {\"cosine\": 0.5, \"dice\": 0.5, \"overlap\": 0.5, \"jaccard\": 0.33333333333333331}]\n",
      "0.45833333333333331\t[\"circumstantial - george\", {\"cosine\": 0.5, \"dice\": 0.5, \"overlap\": 0.5, \"jaccard\": 0.33333333333333331}]\n",
      "0.45833333333333331\t[\"biography - limited\", {\"cosine\": 0.5, \"dice\": 0.5, \"overlap\": 0.5, \"jaccard\": 0.33333333333333331}]\n",
      "0.45833333333333331\t[\"biography - narrative\", {\"cosine\": 0.5, \"dice\": 0.5, \"overlap\": 0.5, \"jaccard\": 0.33333333333333331}]\n",
      "0.45833333333333331\t[\"biography - tales\", {\"cosine\": 0.5, \"dice\": 0.5, \"overlap\": 0.5, \"jaccard\": 0.33333333333333331}]\n",
      "0.45833333333333331\t[\"by - circumstantial\", {\"cosine\": 0.5, \"dice\": 0.5, \"overlap\": 0.5, \"jaccard\": 0.33333333333333331}]\n",
      "0.45833333333333331\t[\"circumstantial - limited\", {\"cosine\": 0.5, \"dice\": 0.5, \"overlap\": 0.5, \"jaccard\": 0.33333333333333331}]\n",
      "0.45833333333333331\t[\"by - narrative\", {\"cosine\": 0.5, \"dice\": 0.5, \"overlap\": 0.5, \"jaccard\": 0.33333333333333331}]\n",
      "0.45833333333333331\t[\"circumstantial - sea\", {\"cosine\": 0.5, \"dice\": 0.5, \"overlap\": 0.5, \"jaccard\": 0.33333333333333331}]\n",
      "0.45833333333333331\t[\"child's - government\", {\"cosine\": 0.5, \"dice\": 0.5, \"overlap\": 0.5, \"jaccard\": 0.33333333333333331}]\n",
      "0.45833333333333331\t[\"circumstantial - tales\", {\"cosine\": 0.5, \"dice\": 0.5, \"overlap\": 0.5, \"jaccard\": 0.33333333333333331}]\n",
      "0.45833333333333331\t[\"narrative - tales\", {\"cosine\": 0.5, \"dice\": 0.5, \"overlap\": 0.5, \"jaccard\": 0.33333333333333331}]\n",
      "0.45833333333333331\t[\"female - george\", {\"cosine\": 0.5, \"dice\": 0.5, \"overlap\": 0.5, \"jaccard\": 0.33333333333333331}]\n",
      "0.45833333333333331\t[\"narrative - sea\", {\"cosine\": 0.5, \"dice\": 0.5, \"overlap\": 0.5, \"jaccard\": 0.33333333333333331}]\n",
      "0.45833333333333331\t[\"general - narrative\", {\"cosine\": 0.5, \"dice\": 0.5, \"overlap\": 0.5, \"jaccard\": 0.33333333333333331}]\n",
      "0.45833333333333331\t[\"george - narrative\", {\"cosine\": 0.5, \"dice\": 0.5, \"overlap\": 0.5, \"jaccard\": 0.33333333333333331}]\n",
      "0.45833333333333331\t[\"female - narrative\", {\"cosine\": 0.5, \"dice\": 0.5, \"overlap\": 0.5, \"jaccard\": 0.33333333333333331}]\n",
      "0.45833333333333331\t[\"limited - tales\", {\"cosine\": 0.5, \"dice\": 0.5, \"overlap\": 0.5, \"jaccard\": 0.33333333333333331}]\n",
      "0.45833333333333331\t[\"fairy - general\", {\"cosine\": 0.5, \"dice\": 0.5, \"overlap\": 0.5, \"jaccard\": 0.33333333333333331}]\n",
      "0.45833333333333331\t[\"female - tales\", {\"cosine\": 0.5, \"dice\": 0.5, \"overlap\": 0.5, \"jaccard\": 0.33333333333333331}]\n",
      "0.45833333333333331\t[\"general - tales\", {\"cosine\": 0.5, \"dice\": 0.5, \"overlap\": 0.5, \"jaccard\": 0.33333333333333331}]\n",
      "0.45833333333333331\t[\"limited - narrative\", {\"cosine\": 0.5, \"dice\": 0.5, \"overlap\": 0.5, \"jaccard\": 0.33333333333333331}]\n",
      "0.45833333333333331\t[\"george - tales\", {\"cosine\": 0.5, \"dice\": 0.5, \"overlap\": 0.5, \"jaccard\": 0.33333333333333331}]\n",
      "0.45833333333333331\t[\"george - limited\", {\"cosine\": 0.5, \"dice\": 0.5, \"overlap\": 0.5, \"jaccard\": 0.33333333333333331}]\n",
      "0.45833333333333331\t[\"fairy - female\", {\"cosine\": 0.5, \"dice\": 0.5, \"overlap\": 0.5, \"jaccard\": 0.33333333333333331}]\n",
      "0.45833333333333331\t[\"fairy - george\", {\"cosine\": 0.5, \"dice\": 0.5, \"overlap\": 0.5, \"jaccard\": 0.33333333333333331}]\n",
      "0.45833333333333331\t[\"city - narrative\", {\"cosine\": 0.5, \"dice\": 0.5, \"overlap\": 0.5, \"jaccard\": 0.33333333333333331}]\n",
      "0.45833333333333331\t[\"fairy - limited\", {\"cosine\": 0.5, \"dice\": 0.5, \"overlap\": 0.5, \"jaccard\": 0.33333333333333331}]\n",
      "0.45833333333333331\t[\"fairy - narrative\", {\"cosine\": 0.5, \"dice\": 0.5, \"overlap\": 0.5, \"jaccard\": 0.33333333333333331}]\n",
      "0.45833333333333331\t[\"general - limited\", {\"cosine\": 0.5, \"dice\": 0.5, \"overlap\": 0.5, \"jaccard\": 0.33333333333333331}]\n",
      "0.45833333333333331\t[\"female - general\", {\"cosine\": 0.5, \"dice\": 0.5, \"overlap\": 0.5, \"jaccard\": 0.33333333333333331}]\n",
      "0.45833333333333331\t[\"government - wales\", {\"cosine\": 0.5, \"dice\": 0.5, \"overlap\": 0.5, \"jaccard\": 0.33333333333333331}]\n",
      "0.4382756117846629\t[\"forms - study\", {\"cosine\": 0.43643578047198478, \"dice\": 0.40000000000000002, \"overlap\": 0.66666666666666663, \"jaccard\": 0.25}]\n",
      "0.4382756117846629\t[\"forms - the\", {\"cosine\": 0.43643578047198478, \"dice\": 0.40000000000000002, \"overlap\": 0.66666666666666663, \"jaccard\": 0.25}]\n",
      "0.4382756117846629\t[\"case - forms\", {\"cosine\": 0.43643578047198478, \"dice\": 0.40000000000000002, \"overlap\": 0.66666666666666663, \"jaccard\": 0.25}]\n",
      "0.41934308141467203\t[\"circumstantial - collection\", {\"cosine\": 0.44721359549995793, \"dice\": 0.44444444444444442, \"overlap\": 0.5, \"jaccard\": 0.2857142857142857}]\n",
      "0.41934308141467203\t[\"biography - collection\", {\"cosine\": 0.44721359549995793, \"dice\": 0.44444444444444442, \"overlap\": 0.5, \"jaccard\": 0.2857142857142857}]\n",
      "0.41934308141467203\t[\"collection - limited\", {\"cosine\": 0.44721359549995793, \"dice\": 0.44444444444444442, \"overlap\": 0.5, \"jaccard\": 0.2857142857142857}]\n",
      "0.41934308141467203\t[\"collection - george\", {\"cosine\": 0.44721359549995793, \"dice\": 0.44444444444444442, \"overlap\": 0.5, \"jaccard\": 0.2857142857142857}]\n",
      "0.41934308141467203\t[\"collection - general\", {\"cosine\": 0.44721359549995793, \"dice\": 0.44444444444444442, \"overlap\": 0.5, \"jaccard\": 0.2857142857142857}]\n",
      "0.41934308141467203\t[\"collection - female\", {\"cosine\": 0.44721359549995793, \"dice\": 0.44444444444444442, \"overlap\": 0.5, \"jaccard\": 0.2857142857142857}]\n",
      "0.41934308141467203\t[\"collection - narrative\", {\"cosine\": 0.44721359549995793, \"dice\": 0.44444444444444442, \"overlap\": 0.5, \"jaccard\": 0.2857142857142857}]\n",
      "0.41014695207623802\t[\"government - of\", {\"cosine\": 0.38729833462074165, \"dice\": 0.31578947368421051, \"overlap\": 0.75, \"jaccard\": 0.1875}]\n",
      "0.41014695207623802\t[\"general - of\", {\"cosine\": 0.38729833462074165, \"dice\": 0.31578947368421051, \"overlap\": 0.75, \"jaccard\": 0.1875}]\n",
      "0.41014695207623802\t[\"george - of\", {\"cosine\": 0.38729833462074165, \"dice\": 0.31578947368421051, \"overlap\": 0.75, \"jaccard\": 0.1875}]\n",
      "0.41014695207623802\t[\"fairy - of\", {\"cosine\": 0.38729833462074165, \"dice\": 0.31578947368421051, \"overlap\": 0.75, \"jaccard\": 0.1875}]\n",
      "0.41014695207623802\t[\"narrative - of\", {\"cosine\": 0.38729833462074165, \"dice\": 0.31578947368421051, \"overlap\": 0.75, \"jaccard\": 0.1875}]\n",
      "0.41014695207623802\t[\"female - of\", {\"cosine\": 0.38729833462074165, \"dice\": 0.31578947368421051, \"overlap\": 0.75, \"jaccard\": 0.1875}]\n",
      "0.41014695207623802\t[\"limited - of\", {\"cosine\": 0.38729833462074165, \"dice\": 0.31578947368421051, \"overlap\": 0.75, \"jaccard\": 0.1875}]\n",
      "0.41014695207623802\t[\"of - tales\", {\"cosine\": 0.38729833462074165, \"dice\": 0.31578947368421051, \"overlap\": 0.75, \"jaccard\": 0.1875}]\n",
      "0.41014695207623802\t[\"biography - of\", {\"cosine\": 0.38729833462074165, \"dice\": 0.31578947368421051, \"overlap\": 0.75, \"jaccard\": 0.1875}]\n",
      "0.41014695207623802\t[\"circumstantial - of\", {\"cosine\": 0.38729833462074165, \"dice\": 0.31578947368421051, \"overlap\": 0.75, \"jaccard\": 0.1875}]\n",
      "0.38961038961038957\t[\"case - in\", {\"cosine\": 0.42857142857142849, \"dice\": 0.42857142857142855, \"overlap\": 0.42857142857142855, \"jaccard\": 0.27272727272727271}]\n",
      "0.38961038961038957\t[\"in - study\", {\"cosine\": 0.42857142857142849, \"dice\": 0.42857142857142855, \"overlap\": 0.42857142857142855, \"jaccard\": 0.27272727272727271}]\n",
      "0.38691179661664266\t[\"of - study\", {\"cosine\": 0.3903600291794132, \"dice\": 0.36363636363636365, \"overlap\": 0.5714285714285714, \"jaccard\": 0.22222222222222221}]\n",
      "0.38691179661664266\t[\"case - of\", {\"cosine\": 0.3903600291794132, \"dice\": 0.36363636363636365, \"overlap\": 0.5714285714285714, \"jaccard\": 0.22222222222222221}]\n",
      "0.38428058229667272\t[\"a - collection\", {\"cosine\": 0.34426518632954817, \"dice\": 0.25, \"overlap\": 0.80000000000000004, \"jaccard\": 0.14285714285714285}]\n",
      "0.36595576471695324\t[\"case - narrative\", {\"cosine\": 0.3779644730092272, \"dice\": 0.36363636363636365, \"overlap\": 0.5, \"jaccard\": 0.22222222222222221}]\n",
      "0.36595576471695324\t[\"child's - study\", {\"cosine\": 0.3779644730092272, \"dice\": 0.36363636363636365, \"overlap\": 0.5, \"jaccard\": 0.22222222222222221}]\n",
      "0.36595576471695324\t[\"christmas - study\", {\"cosine\": 0.3779644730092272, \"dice\": 0.36363636363636365, \"overlap\": 0.5, \"jaccard\": 0.22222222222222221}]\n",
      "0.36595576471695324\t[\"case - child's\", {\"cosine\": 0.3779644730092272, \"dice\": 0.36363636363636365, \"overlap\": 0.5, \"jaccard\": 0.22222222222222221}]\n",
      "0.36595576471695324\t[\"case - christmas\", {\"cosine\": 0.3779644730092272, \"dice\": 0.36363636363636365, \"overlap\": 0.5, \"jaccard\": 0.22222222222222221}]\n",
      "0.36595576471695324\t[\"case - circumstantial\", {\"cosine\": 0.3779644730092272, \"dice\": 0.36363636363636365, \"overlap\": 0.5, \"jaccard\": 0.22222222222222221}]\n",
      "0.36595576471695324\t[\"case - wales\", {\"cosine\": 0.3779644730092272, \"dice\": 0.36363636363636365, \"overlap\": 0.5, \"jaccard\": 0.22222222222222221}]\n",
      "0.36595576471695324\t[\"case - fairy\", {\"cosine\": 0.3779644730092272, \"dice\": 0.36363636363636365, \"overlap\": 0.5, \"jaccard\": 0.22222222222222221}]\n",
      "0.36595576471695324\t[\"circumstantial - study\", {\"cosine\": 0.3779644730092272, \"dice\": 0.36363636363636365, \"overlap\": 0.5, \"jaccard\": 0.22222222222222221}]\n",
      "0.36595576471695324\t[\"case - general\", {\"cosine\": 0.3779644730092272, \"dice\": 0.36363636363636365, \"overlap\": 0.5, \"jaccard\": 0.22222222222222221}]\n",
      "0.36595576471695324\t[\"case - george\", {\"cosine\": 0.3779644730092272, \"dice\": 0.36363636363636365, \"overlap\": 0.5, \"jaccard\": 0.22222222222222221}]\n",
      "0.36595576471695324\t[\"case - tales\", {\"cosine\": 0.3779644730092272, \"dice\": 0.36363636363636365, \"overlap\": 0.5, \"jaccard\": 0.22222222222222221}]\n",
      "0.36595576471695324\t[\"biography - study\", {\"cosine\": 0.3779644730092272, \"dice\": 0.36363636363636365, \"overlap\": 0.5, \"jaccard\": 0.22222222222222221}]\n",
      "0.36595576471695324\t[\"biography - the\", {\"cosine\": 0.3779644730092272, \"dice\": 0.36363636363636365, \"overlap\": 0.5, \"jaccard\": 0.22222222222222221}]\n",
      "0.36595576471695324\t[\"biography - case\", {\"cosine\": 0.3779644730092272, \"dice\": 0.36363636363636365, \"overlap\": 0.5, \"jaccard\": 0.22222222222222221}]\n",
      "0.36595576471695324\t[\"george - the\", {\"cosine\": 0.3779644730092272, \"dice\": 0.36363636363636365, \"overlap\": 0.5, \"jaccard\": 0.22222222222222221}]\n",
      "0.36595576471695324\t[\"general - the\", {\"cosine\": 0.3779644730092272, \"dice\": 0.36363636363636365, \"overlap\": 0.5, \"jaccard\": 0.22222222222222221}]\n",
      "0.36595576471695324\t[\"general - study\", {\"cosine\": 0.3779644730092272, \"dice\": 0.36363636363636365, \"overlap\": 0.5, \"jaccard\": 0.22222222222222221}]\n",
      "0.36595576471695324\t[\"study - tales\", {\"cosine\": 0.3779644730092272, \"dice\": 0.36363636363636365, \"overlap\": 0.5, \"jaccard\": 0.22222222222222221}]\n",
      "0.36595576471695324\t[\"tales - the\", {\"cosine\": 0.3779644730092272, \"dice\": 0.36363636363636365, \"overlap\": 0.5, \"jaccard\": 0.22222222222222221}]\n",
      "0.36595576471695324\t[\"female - the\", {\"cosine\": 0.3779644730092272, \"dice\": 0.36363636363636365, \"overlap\": 0.5, \"jaccard\": 0.22222222222222221}]\n",
      "0.36595576471695324\t[\"george - study\", {\"cosine\": 0.3779644730092272, \"dice\": 0.36363636363636365, \"overlap\": 0.5, \"jaccard\": 0.22222222222222221}]\n",
      "0.36595576471695324\t[\"limited - the\", {\"cosine\": 0.3779644730092272, \"dice\": 0.36363636363636365, \"overlap\": 0.5, \"jaccard\": 0.22222222222222221}]\n",
      "0.36595576471695324\t[\"narrative - study\", {\"cosine\": 0.3779644730092272, \"dice\": 0.36363636363636365, \"overlap\": 0.5, \"jaccard\": 0.22222222222222221}]\n",
      "0.36595576471695324\t[\"fairy - the\", {\"cosine\": 0.3779644730092272, \"dice\": 0.36363636363636365, \"overlap\": 0.5, \"jaccard\": 0.22222222222222221}]\n",
      "0.36595576471695324\t[\"fairy - study\", {\"cosine\": 0.3779644730092272, \"dice\": 0.36363636363636365, \"overlap\": 0.5, \"jaccard\": 0.22222222222222221}]\n",
      "0.36595576471695324\t[\"study - wales\", {\"cosine\": 0.3779644730092272, \"dice\": 0.36363636363636365, \"overlap\": 0.5, \"jaccard\": 0.22222222222222221}]\n",
      "0.33484159470861108\t[\"a - bill\", {\"cosine\": 0.28867513459481287, \"dice\": 0.19354838709677419, \"overlap\": 0.75, \"jaccard\": 0.10714285714285714}]\n",
      "0.33484159470861108\t[\"a - wales\", {\"cosine\": 0.28867513459481287, \"dice\": 0.19354838709677419, \"overlap\": 0.75, \"jaccard\": 0.10714285714285714}]\n",
      "0.33484159470861108\t[\"a - tales\", {\"cosine\": 0.28867513459481287, \"dice\": 0.19354838709677419, \"overlap\": 0.75, \"jaccard\": 0.10714285714285714}]\n",
      "0.33484159470861108\t[\"a - sea\", {\"cosine\": 0.28867513459481287, \"dice\": 0.19354838709677419, \"overlap\": 0.75, \"jaccard\": 0.10714285714285714}]\n",
      "0.33484159470861108\t[\"a - religious\", {\"cosine\": 0.28867513459481287, \"dice\": 0.19354838709677419, \"overlap\": 0.75, \"jaccard\": 0.10714285714285714}]\n",
      "0.33484159470861108\t[\"a - narrative\", {\"cosine\": 0.28867513459481287, \"dice\": 0.19354838709677419, \"overlap\": 0.75, \"jaccard\": 0.10714285714285714}]\n",
      "0.33484159470861108\t[\"a - limited\", {\"cosine\": 0.28867513459481287, \"dice\": 0.19354838709677419, \"overlap\": 0.75, \"jaccard\": 0.10714285714285714}]\n",
      "0.33484159470861108\t[\"a - government\", {\"cosine\": 0.28867513459481287, \"dice\": 0.19354838709677419, \"overlap\": 0.75, \"jaccard\": 0.10714285714285714}]\n",
      "0.33484159470861108\t[\"a - george\", {\"cosine\": 0.28867513459481287, \"dice\": 0.19354838709677419, \"overlap\": 0.75, \"jaccard\": 0.10714285714285714}]\n",
      "0.33484159470861108\t[\"a - general\", {\"cosine\": 0.28867513459481287, \"dice\": 0.19354838709677419, \"overlap\": 0.75, \"jaccard\": 0.10714285714285714}]\n",
      "0.33484159470861108\t[\"a - for\", {\"cosine\": 0.28867513459481287, \"dice\": 0.19354838709677419, \"overlap\": 0.75, \"jaccard\": 0.10714285714285714}]\n",
      "0.33484159470861108\t[\"a - female\", {\"cosine\": 0.28867513459481287, \"dice\": 0.19354838709677419, \"overlap\": 0.75, \"jaccard\": 0.10714285714285714}]\n",
      "0.33484159470861108\t[\"a - fairy\", {\"cosine\": 0.28867513459481287, \"dice\": 0.19354838709677419, \"overlap\": 0.75, \"jaccard\": 0.10714285714285714}]\n",
      "0.33484159470861108\t[\"a - establishing\", {\"cosine\": 0.28867513459481287, \"dice\": 0.19354838709677419, \"overlap\": 0.75, \"jaccard\": 0.10714285714285714}]\n",
      "0.33484159470861108\t[\"a - city\", {\"cosine\": 0.28867513459481287, \"dice\": 0.19354838709677419, \"overlap\": 0.75, \"jaccard\": 0.10714285714285714}]\n",
      "0.33484159470861108\t[\"a - circumstantial\", {\"cosine\": 0.28867513459481287, \"dice\": 0.19354838709677419, \"overlap\": 0.75, \"jaccard\": 0.10714285714285714}]\n",
      "0.33484159470861108\t[\"a - christmas\", {\"cosine\": 0.28867513459481287, \"dice\": 0.19354838709677419, \"overlap\": 0.75, \"jaccard\": 0.10714285714285714}]\n",
      "0.33484159470861108\t[\"a - child's\", {\"cosine\": 0.28867513459481287, \"dice\": 0.19354838709677419, \"overlap\": 0.75, \"jaccard\": 0.10714285714285714}]\n",
      "0.33484159470861108\t[\"a - by\", {\"cosine\": 0.28867513459481287, \"dice\": 0.19354838709677419, \"overlap\": 0.75, \"jaccard\": 0.10714285714285714}]\n",
      "0.33484159470861108\t[\"a - biography\", {\"cosine\": 0.28867513459481287, \"dice\": 0.19354838709677419, \"overlap\": 0.75, \"jaccard\": 0.10714285714285714}]\n",
      "0.32800782147221519\t[\"forms - of\", {\"cosine\": 0.29814239699997197, \"dice\": 0.22222222222222221, \"overlap\": 0.66666666666666663, \"jaccard\": 0.125}]\n",
      "0.31784875880618496\t[\"collection - study\", {\"cosine\": 0.33806170189140661, \"dice\": 0.33333333333333331, \"overlap\": 0.40000000000000002, \"jaccard\": 0.20000000000000001}]\n",
      "0.31784875880618496\t[\"collection - the\", {\"cosine\": 0.33806170189140661, \"dice\": 0.33333333333333331, \"overlap\": 0.40000000000000002, \"jaccard\": 0.20000000000000001}]\n",
      "0.31784875880618496\t[\"case - collection\", {\"cosine\": 0.33806170189140661, \"dice\": 0.33333333333333331, \"overlap\": 0.40000000000000002, \"jaccard\": 0.20000000000000001}]\n",
      "0.28799086500634163\t[\"of - the\", {\"cosine\": 0.29277002188455992, \"dice\": 0.27272727272727271, \"overlap\": 0.42857142857142855, \"jaccard\": 0.15789473684210525}]\n",
      "0.28799086500634163\t[\"in - of\", {\"cosine\": 0.29277002188455992, \"dice\": 0.27272727272727271, \"overlap\": 0.42857142857142855, \"jaccard\": 0.15789473684210525}]\n",
      "0.27341269841269839\t[\"a - forms\", {\"cosine\": 0.22222222222222227, \"dice\": 0.13333333333333333, \"overlap\": 0.66666666666666663, \"jaccard\": 0.071428571428571425}]\n",
      "0.27159306609004102\t[\"by - of\", {\"cosine\": 0.2581988897471611, \"dice\": 0.21052631578947367, \"overlap\": 0.5, \"jaccard\": 0.11764705882352941}]\n",
      "0.27159306609004102\t[\"city - of\", {\"cosine\": 0.2581988897471611, \"dice\": 0.21052631578947367, \"overlap\": 0.5, \"jaccard\": 0.11764705882352941}]\n",
      "0.27159306609004102\t[\"of - sea\", {\"cosine\": 0.2581988897471611, \"dice\": 0.21052631578947367, \"overlap\": 0.5, \"jaccard\": 0.11764705882352941}]\n",
      "0.26859735507727467\t[\"forms - wales\", {\"cosine\": 0.28867513459481292, \"dice\": 0.2857142857142857, \"overlap\": 0.33333333333333331, \"jaccard\": 0.16666666666666666}]\n",
      "0.26859735507727467\t[\"city - forms\", {\"cosine\": 0.28867513459481292, \"dice\": 0.2857142857142857, \"overlap\": 0.33333333333333331, \"jaccard\": 0.16666666666666666}]\n",
      "0.26859735507727467\t[\"forms - religious\", {\"cosine\": 0.28867513459481292, \"dice\": 0.2857142857142857, \"overlap\": 0.33333333333333331, \"jaccard\": 0.16666666666666666}]\n",
      "0.26859735507727467\t[\"for - forms\", {\"cosine\": 0.28867513459481292, \"dice\": 0.2857142857142857, \"overlap\": 0.33333333333333331, \"jaccard\": 0.16666666666666666}]\n",
      "0.26859735507727467\t[\"forms - sea\", {\"cosine\": 0.28867513459481292, \"dice\": 0.2857142857142857, \"overlap\": 0.33333333333333331, \"jaccard\": 0.16666666666666666}]\n",
      "0.26859735507727467\t[\"establishing - forms\", {\"cosine\": 0.28867513459481292, \"dice\": 0.2857142857142857, \"overlap\": 0.33333333333333331, \"jaccard\": 0.16666666666666666}]\n",
      "0.26859735507727467\t[\"forms - government\", {\"cosine\": 0.28867513459481292, \"dice\": 0.2857142857142857, \"overlap\": 0.33333333333333331, \"jaccard\": 0.16666666666666666}]\n",
      "0.26859735507727467\t[\"christmas - forms\", {\"cosine\": 0.28867513459481292, \"dice\": 0.2857142857142857, \"overlap\": 0.33333333333333331, \"jaccard\": 0.16666666666666666}]\n",
      "0.26859735507727467\t[\"child's - forms\", {\"cosine\": 0.28867513459481292, \"dice\": 0.2857142857142857, \"overlap\": 0.33333333333333331, \"jaccard\": 0.16666666666666666}]\n",
      "0.26859735507727467\t[\"bill - forms\", {\"cosine\": 0.28867513459481292, \"dice\": 0.2857142857142857, \"overlap\": 0.33333333333333331, \"jaccard\": 0.16666666666666666}]\n",
      "0.26859735507727467\t[\"by - forms\", {\"cosine\": 0.28867513459481292, \"dice\": 0.2857142857142857, \"overlap\": 0.33333333333333331, \"jaccard\": 0.16666666666666666}]\n",
      "0.25595238095238093\t[\"case - the\", {\"cosine\": 0.28571428571428564, \"dice\": 0.2857142857142857, \"overlap\": 0.2857142857142857, \"jaccard\": 0.16666666666666666}]\n",
      "0.25595238095238093\t[\"study - the\", {\"cosine\": 0.28571428571428564, \"dice\": 0.2857142857142857, \"overlap\": 0.2857142857142857, \"jaccard\": 0.16666666666666666}]\n",
      "0.2232142857142857\t[\"sea - tales\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"sea - wales\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"general - wales\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"for - wales\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"for - tales\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"city - fairy\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"for - sea\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"george - government\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"city - general\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"for - narrative\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"for - limited\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"religious - tales\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"for - government\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"for - george\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"for - general\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"female - wales\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"limited - religious\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"limited - sea\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"female - sea\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"tales - wales\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"limited - wales\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"government - narrative\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"narrative - religious\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"narrative - wales\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"city - for\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"female - for\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"fairy - wales\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"city - government\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"fairy - sea\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"fairy - religious\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"george - wales\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"george - religious\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"city - limited\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"female - religious\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"fairy - government\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"city - religious\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"george - sea\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"fairy - for\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"city - tales\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"establishing - wales\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"religious - sea\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"establishing - tales\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"city - female\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"establishing - sea\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"city - wales\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"city - george\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"establishing - narrative\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"establishing - limited\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"establishing - government\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"establishing - george\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"establishing - general\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"establishing - female\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"establishing - fairy\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"general - religious\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"general - sea\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"government - religious\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"government - sea\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"religious - wales\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"general - government\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"government - tales\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"biography - establishing\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"by - government\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"by - george\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"child's - circumstantial\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"child's - city\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"child's - establishing\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"child's - fairy\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"child's - female\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"child's - for\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"by - general\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"child's - general\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"child's - george\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"by - for\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"by - female\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"by - fairy\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"by - establishing\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"by - tales\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"christmas - circumstantial\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"by - christmas\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"by - child's\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"by - wales\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"biography - wales\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"christmas - city\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"christmas - establishing\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"biography - sea\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"biography - religious\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"christmas - fairy\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"christmas - female\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"christmas - for\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"child's - sea\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"biography - government\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"christmas - general\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"christmas - george\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"biography - for\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"christmas - limited\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"christmas - narrative\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"child's - limited\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"biography - city\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"christmas - religious\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"biography - christmas\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"biography - child's\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"christmas - sea\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"biography - by\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"bill - wales\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"child's - narrative\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"bill - tales\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"by - religious\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"bill - sea\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"christmas - tales\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"bill - narrative\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"bill - limited\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"bill - government\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"bill - george\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"bill - general\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"child's - tales\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"bill - female\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"bill - fairy\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"circumstantial - establishing\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"bill - city\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"bill - circumstantial\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"bill - christmas\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"bill - child's\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"by - limited\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"bill - by\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"bill - biography\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"circumstantial - for\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"circumstantial - religious\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"circumstantial - government\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"city - establishing\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"circumstantial - wales\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.2232142857142857\t[\"child's - religious\", {\"cosine\": 0.25, \"dice\": 0.25, \"overlap\": 0.25, \"jaccard\": 0.14285714285714285}]\n",
      "0.21566558367010924\t[\"forms - in\", {\"cosine\": 0.21821789023599239, \"dice\": 0.20000000000000001, \"overlap\": 0.33333333333333331, \"jaccard\": 0.1111111111111111}]\n",
      "0.20520725499305029\t[\"collection - wales\", {\"cosine\": 0.22360679774997896, \"dice\": 0.22222222222222221, \"overlap\": 0.25, \"jaccard\": 0.125}]\n",
      "0.20520725499305029\t[\"collection - religious\", {\"cosine\": 0.22360679774997896, \"dice\": 0.22222222222222221, \"overlap\": 0.25, \"jaccard\": 0.125}]\n",
      "0.20520725499305029\t[\"collection - for\", {\"cosine\": 0.22360679774997896, \"dice\": 0.22222222222222221, \"overlap\": 0.25, \"jaccard\": 0.125}]\n",
      "0.20520725499305029\t[\"collection - establishing\", {\"cosine\": 0.22360679774997896, \"dice\": 0.22222222222222221, \"overlap\": 0.25, \"jaccard\": 0.125}]\n",
      "0.20520725499305029\t[\"collection - sea\", {\"cosine\": 0.22360679774997896, \"dice\": 0.22222222222222221, \"overlap\": 0.25, \"jaccard\": 0.125}]\n",
      "0.20520725499305029\t[\"collection - government\", {\"cosine\": 0.22360679774997896, \"dice\": 0.22222222222222221, \"overlap\": 0.25, \"jaccard\": 0.125}]\n",
      "0.20520725499305029\t[\"christmas - collection\", {\"cosine\": 0.22360679774997896, \"dice\": 0.22222222222222221, \"overlap\": 0.25, \"jaccard\": 0.125}]\n",
      "0.20520725499305029\t[\"child's - collection\", {\"cosine\": 0.22360679774997896, \"dice\": 0.22222222222222221, \"overlap\": 0.25, \"jaccard\": 0.125}]\n",
      "0.20520725499305029\t[\"bill - collection\", {\"cosine\": 0.22360679774997896, \"dice\": 0.22222222222222221, \"overlap\": 0.25, \"jaccard\": 0.125}]\n",
      "0.20520725499305029\t[\"city - collection\", {\"cosine\": 0.22360679774997896, \"dice\": 0.22222222222222221, \"overlap\": 0.25, \"jaccard\": 0.125}]\n",
      "0.20520725499305029\t[\"by - collection\", {\"cosine\": 0.22360679774997896, \"dice\": 0.22222222222222221, \"overlap\": 0.25, \"jaccard\": 0.125}]\n",
      "0.18020010458069885\t[\"bill - the\", {\"cosine\": 0.1889822365046136, \"dice\": 0.18181818181818182, \"overlap\": 0.25, \"jaccard\": 0.10000000000000001}]\n",
      "0.18020010458069885\t[\"by - study\", {\"cosine\": 0.1889822365046136, \"dice\": 0.18181818181818182, \"overlap\": 0.25, \"jaccard\": 0.10000000000000001}]\n",
      "0.18020010458069885\t[\"by - in\", {\"cosine\": 0.1889822365046136, \"dice\": 0.18181818181818182, \"overlap\": 0.25, \"jaccard\": 0.10000000000000001}]\n",
      "0.18020010458069885\t[\"child's - the\", {\"cosine\": 0.1889822365046136, \"dice\": 0.18181818181818182, \"overlap\": 0.25, \"jaccard\": 0.10000000000000001}]\n",
      "0.18020010458069885\t[\"by - case\", {\"cosine\": 0.1889822365046136, \"dice\": 0.18181818181818182, \"overlap\": 0.25, \"jaccard\": 0.10000000000000001}]\n",
      "0.18020010458069885\t[\"biography - in\", {\"cosine\": 0.1889822365046136, \"dice\": 0.18181818181818182, \"overlap\": 0.25, \"jaccard\": 0.10000000000000001}]\n",
      "0.18020010458069885\t[\"bill - study\", {\"cosine\": 0.1889822365046136, \"dice\": 0.18181818181818182, \"overlap\": 0.25, \"jaccard\": 0.10000000000000001}]\n",
      "0.18020010458069885\t[\"bill - in\", {\"cosine\": 0.1889822365046136, \"dice\": 0.18181818181818182, \"overlap\": 0.25, \"jaccard\": 0.10000000000000001}]\n",
      "0.18020010458069885\t[\"christmas - the\", {\"cosine\": 0.1889822365046136, \"dice\": 0.18181818181818182, \"overlap\": 0.25, \"jaccard\": 0.10000000000000001}]\n",
      "0.18020010458069885\t[\"bill - case\", {\"cosine\": 0.1889822365046136, \"dice\": 0.18181818181818182, \"overlap\": 0.25, \"jaccard\": 0.10000000000000001}]\n",
      "0.18020010458069885\t[\"circumstantial - in\", {\"cosine\": 0.1889822365046136, \"dice\": 0.18181818181818182, \"overlap\": 0.25, \"jaccard\": 0.10000000000000001}]\n",
      "0.18020010458069885\t[\"case - sea\", {\"cosine\": 0.1889822365046136, \"dice\": 0.18181818181818182, \"overlap\": 0.25, \"jaccard\": 0.10000000000000001}]\n",
      "0.18020010458069885\t[\"case - religious\", {\"cosine\": 0.1889822365046136, \"dice\": 0.18181818181818182, \"overlap\": 0.25, \"jaccard\": 0.10000000000000001}]\n",
      "0.18020010458069885\t[\"case - for\", {\"cosine\": 0.1889822365046136, \"dice\": 0.18181818181818182, \"overlap\": 0.25, \"jaccard\": 0.10000000000000001}]\n",
      "0.18020010458069885\t[\"case - establishing\", {\"cosine\": 0.1889822365046136, \"dice\": 0.18181818181818182, \"overlap\": 0.25, \"jaccard\": 0.10000000000000001}]\n",
      "0.18020010458069885\t[\"case - city\", {\"cosine\": 0.1889822365046136, \"dice\": 0.18181818181818182, \"overlap\": 0.25, \"jaccard\": 0.10000000000000001}]\n",
      "0.18020010458069885\t[\"the - wales\", {\"cosine\": 0.1889822365046136, \"dice\": 0.18181818181818182, \"overlap\": 0.25, \"jaccard\": 0.10000000000000001}]\n",
      "0.18020010458069885\t[\"sea - study\", {\"cosine\": 0.1889822365046136, \"dice\": 0.18181818181818182, \"overlap\": 0.25, \"jaccard\": 0.10000000000000001}]\n",
      "0.18020010458069885\t[\"religious - the\", {\"cosine\": 0.1889822365046136, \"dice\": 0.18181818181818182, \"overlap\": 0.25, \"jaccard\": 0.10000000000000001}]\n",
      "0.18020010458069885\t[\"religious - study\", {\"cosine\": 0.1889822365046136, \"dice\": 0.18181818181818182, \"overlap\": 0.25, \"jaccard\": 0.10000000000000001}]\n",
      "0.18020010458069885\t[\"in - tales\", {\"cosine\": 0.1889822365046136, \"dice\": 0.18181818181818182, \"overlap\": 0.25, \"jaccard\": 0.10000000000000001}]\n",
      "0.18020010458069885\t[\"in - sea\", {\"cosine\": 0.1889822365046136, \"dice\": 0.18181818181818182, \"overlap\": 0.25, \"jaccard\": 0.10000000000000001}]\n",
      "0.18020010458069885\t[\"in - religious\", {\"cosine\": 0.1889822365046136, \"dice\": 0.18181818181818182, \"overlap\": 0.25, \"jaccard\": 0.10000000000000001}]\n",
      "0.18020010458069885\t[\"in - narrative\", {\"cosine\": 0.1889822365046136, \"dice\": 0.18181818181818182, \"overlap\": 0.25, \"jaccard\": 0.10000000000000001}]\n",
      "0.18020010458069885\t[\"government - the\", {\"cosine\": 0.1889822365046136, \"dice\": 0.18181818181818182, \"overlap\": 0.25, \"jaccard\": 0.10000000000000001}]\n",
      "0.18020010458069885\t[\"george - in\", {\"cosine\": 0.1889822365046136, \"dice\": 0.18181818181818182, \"overlap\": 0.25, \"jaccard\": 0.10000000000000001}]\n",
      "0.18020010458069885\t[\"general - in\", {\"cosine\": 0.1889822365046136, \"dice\": 0.18181818181818182, \"overlap\": 0.25, \"jaccard\": 0.10000000000000001}]\n",
      "0.18020010458069885\t[\"for - the\", {\"cosine\": 0.1889822365046136, \"dice\": 0.18181818181818182, \"overlap\": 0.25, \"jaccard\": 0.10000000000000001}]\n",
      "0.18020010458069885\t[\"for - in\", {\"cosine\": 0.1889822365046136, \"dice\": 0.18181818181818182, \"overlap\": 0.25, \"jaccard\": 0.10000000000000001}]\n",
      "0.18020010458069885\t[\"fairy - in\", {\"cosine\": 0.1889822365046136, \"dice\": 0.18181818181818182, \"overlap\": 0.25, \"jaccard\": 0.10000000000000001}]\n",
      "0.18020010458069885\t[\"establishing - the\", {\"cosine\": 0.1889822365046136, \"dice\": 0.18181818181818182, \"overlap\": 0.25, \"jaccard\": 0.10000000000000001}]\n",
      "0.18020010458069885\t[\"establishing - study\", {\"cosine\": 0.1889822365046136, \"dice\": 0.18181818181818182, \"overlap\": 0.25, \"jaccard\": 0.10000000000000001}]\n",
      "0.18020010458069885\t[\"establishing - in\", {\"cosine\": 0.1889822365046136, \"dice\": 0.18181818181818182, \"overlap\": 0.25, \"jaccard\": 0.10000000000000001}]\n",
      "0.18020010458069885\t[\"city - study\", {\"cosine\": 0.1889822365046136, \"dice\": 0.18181818181818182, \"overlap\": 0.25, \"jaccard\": 0.10000000000000001}]\n",
      "0.18020010458069885\t[\"city - in\", {\"cosine\": 0.1889822365046136, \"dice\": 0.18181818181818182, \"overlap\": 0.25, \"jaccard\": 0.10000000000000001}]\n",
      "0.18020010458069885\t[\"for - study\", {\"cosine\": 0.1889822365046136, \"dice\": 0.18181818181818182, \"overlap\": 0.25, \"jaccard\": 0.10000000000000001}]\n",
      "0.15665165213036522\t[\"collection - in\", {\"cosine\": 0.1690308509457033, \"dice\": 0.16666666666666666, \"overlap\": 0.20000000000000001, \"jaccard\": 0.090909090909090912}]\n",
      "0.13497953958096823\t[\"establishing - of\", {\"cosine\": 0.12909944487358055, \"dice\": 0.10526315789473684, \"overlap\": 0.25, \"jaccard\": 0.055555555555555552}]\n",
      "0.13497953958096823\t[\"for - of\", {\"cosine\": 0.12909944487358055, \"dice\": 0.10526315789473684, \"overlap\": 0.25, \"jaccard\": 0.055555555555555552}]\n",
      "0.13497953958096823\t[\"of - religious\", {\"cosine\": 0.12909944487358055, \"dice\": 0.10526315789473684, \"overlap\": 0.25, \"jaccard\": 0.055555555555555552}]\n",
      "0.13497953958096823\t[\"of - wales\", {\"cosine\": 0.12909944487358055, \"dice\": 0.10526315789473684, \"overlap\": 0.25, \"jaccard\": 0.055555555555555552}]\n",
      "0.13497953958096823\t[\"child's - of\", {\"cosine\": 0.12909944487358055, \"dice\": 0.10526315789473684, \"overlap\": 0.25, \"jaccard\": 0.055555555555555552}]\n",
      "0.13497953958096823\t[\"christmas - of\", {\"cosine\": 0.12909944487358055, \"dice\": 0.10526315789473684, \"overlap\": 0.25, \"jaccard\": 0.055555555555555552}]\n",
      "0.13497953958096823\t[\"bill - of\", {\"cosine\": 0.12909944487358055, \"dice\": 0.10526315789473684, \"overlap\": 0.25, \"jaccard\": 0.055555555555555552}]\n",
      "0.12637362637362637\t[\"in - the\", {\"cosine\": 0.14285714285714282, \"dice\": 0.14285714285714285, \"overlap\": 0.14285714285714285, \"jaccard\": 0.076923076923076927}]\n"
     ]
    }
   ],
   "source": [
    "# check the output for systems_test_similarities_1\n",
    "!hadoop fs -ls {OUTPUT_PATH}/\n",
    "!hadoop fs -cat {OUTPUT_PATH}/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/10/11 22:50:14 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 5760 minutes, Emptier interval = 360 minutes.\n",
      "Moved: 'hdfs://nn-ia.s3s.altiscale.com:8020/user/jenncasper/hw540_outputs/systems_test_similarities_2' to trash at: hdfs://nn-ia.s3s.altiscale.com:8020/user/jenncasper/.Trash/Current\n",
      "No configs found; falling back on auto-configuration\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Creating temp directory /tmp/similarity.jenncasper.20171011.225015.728342\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/jenncasper/tmp/mrjob/similarity.jenncasper.20171011.225015.728342/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob2682895391716844303.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1506640654827_2724\n",
      "  Submitted application application_1506640654827_2724\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1506640654827_2724/\n",
      "  Running job: job_1506640654827_2724\n",
      "  Job job_1506640654827_2724 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1506640654827_2724 completed successfully\n",
      "  Output directory: hdfs:///user/jenncasper/tmp/mrjob/similarity.jenncasper.20171011.225015.728342/step-output/0000\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=260\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=763\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=177\n",
      "\t\tFILE: Number of bytes written=398431\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=558\n",
      "\t\tHDFS: Number of bytes written=763\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=16272384\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=15178240\n",
      "\t\tTotal time spent by all map tasks (ms)=10594\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=31782\n",
      "\t\tTotal time spent by all reduce tasks (ms)=5929\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=29645\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=10594\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=5929\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2620\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=228\n",
      "\t\tInput split bytes=298\n",
      "\t\tMap input records=4\n",
      "\t\tMap output bytes=404\n",
      "\t\tMap output materialized bytes=282\n",
      "\t\tMap output records=8\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1891209216\n",
      "\t\tReduce input groups=6\n",
      "\t\tReduce input records=8\n",
      "\t\tReduce output records=6\n",
      "\t\tReduce shuffle bytes=282\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=16\n",
      "\t\tTotal committed heap usage (bytes)=2238709760\n",
      "\t\tVirtual memory (bytes) snapshot=11412586496\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 2 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob737580301661200281.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1506640654827_2727\n",
      "  Submitted application application_1506640654827_2727\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1506640654827_2727/\n",
      "  Running job: job_1506640654827_2727\n",
      "  Job job_1506640654827_2727 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1506640654827_2727 completed successfully\n",
      "  Output directory: hdfs:///user/jenncasper/hw540_outputs/systems_test_similarities_2\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=1145\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=763\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=303\n",
      "\t\tFILE: Number of bytes written=398510\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=1519\n",
      "\t\tHDFS: Number of bytes written=763\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=15820800\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=14766080\n",
      "\t\tTotal time spent by all map tasks (ms)=10300\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=30900\n",
      "\t\tTotal time spent by all reduce tasks (ms)=5768\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=28840\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=10300\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=5768\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2640\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=234\n",
      "\t\tInput split bytes=374\n",
      "\t\tMap input records=6\n",
      "\t\tMap output bytes=774\n",
      "\t\tMap output materialized bytes=414\n",
      "\t\tMap output records=6\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1894404096\n",
      "\t\tReduce input groups=6\n",
      "\t\tReduce input records=6\n",
      "\t\tReduce output records=6\n",
      "\t\tReduce shuffle bytes=414\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=12\n",
      "\t\tTotal committed heap usage (bytes)=2330460160\n",
      "\t\tVirtual memory (bytes) snapshot=11410481152\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Removing HDFS temp directory hdfs:///user/jenncasper/tmp/mrjob/similarity.jenncasper.20171011.225015.728342...\n",
      "Removing temp directory /tmp/similarity.jenncasper.20171011.225015.728342...\n"
     ]
    }
   ],
   "source": [
    "# similarities for systems_test_similarities_2\n",
    "!hadoop fs -rm -r hw540_outputs/systems_test_similarities_2\n",
    "INPUT_PATH = os.path.join('hdfs:///', OUTPUT_PATH_BASE[1:],'hw540_outputs/systems_test_index_2')\n",
    "OUTPUT_PATH = os.path.join(OUTPUT_PATH_BASE, 'hw540_outputs/systems_test_similarities_2')\n",
    "!python similarity.py \\\n",
    "    -r hadoop {INPUT_PATH} \\\n",
    "    --output-dir={OUTPUT_PATH} \\\n",
    "    --no-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "-rw-r--r--   3 jenncasper users          0 2017-10-11 22:52 /user/jenncasper/hw540_outputs/systems_test_similarities_2/_SUCCESS\n",
      "-rw-r--r--   3 jenncasper users        763 2017-10-11 22:52 /user/jenncasper/hw540_outputs/systems_test_similarities_2/part-00000\n",
      "1.0\t[\"atlas - cava\", {\"cosine\": 0.99999999999999978, \"dice\": 1.0, \"overlap\": 1.0, \"jaccard\": 1.0}]\n",
      "0.625\t[\"boon - dipped\", {\"cosine\": 0.66666666666666685, \"dice\": 0.66666666666666663, \"overlap\": 0.66666666666666663, \"jaccard\": 0.5}]\n",
      "0.38956207261596576\t[\"cava - dipped\", {\"cosine\": 0.40824829046386302, \"dice\": 0.40000000000000002, \"overlap\": 0.5, \"jaccard\": 0.25}]\n",
      "0.38956207261596576\t[\"boon - cava\", {\"cosine\": 0.40824829046386302, \"dice\": 0.40000000000000002, \"overlap\": 0.5, \"jaccard\": 0.25}]\n",
      "0.38956207261596576\t[\"atlas - dipped\", {\"cosine\": 0.40824829046386302, \"dice\": 0.40000000000000002, \"overlap\": 0.5, \"jaccard\": 0.25}]\n",
      "0.38956207261596576\t[\"atlas - boon\", {\"cosine\": 0.40824829046386302, \"dice\": 0.40000000000000002, \"overlap\": 0.5, \"jaccard\": 0.25}]\n"
     ]
    }
   ],
   "source": [
    "# check the output for systems_test_similarities_2\n",
    "!hadoop fs -ls {OUTPUT_PATH}/\n",
    "!hadoop fs -cat {OUTPUT_PATH}/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/10/11 22:55:03 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 5760 minutes, Emptier interval = 360 minutes.\n",
      "Moved: 'hdfs://nn-ia.s3s.altiscale.com:8020/user/jenncasper/hw540_outputs/systems_test_similarities_3' to trash at: hdfs://nn-ia.s3s.altiscale.com:8020/user/jenncasper/.Trash/Current\n",
      "No configs found; falling back on auto-configuration\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Creating temp directory /tmp/similarity.jenncasper.20171011.225504.488275\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/jenncasper/tmp/mrjob/similarity.jenncasper.20171011.225504.488275/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob1518399921217597913.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1506640654827_2729\n",
      "  Submitted application application_1506640654827_2729\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1506640654827_2729/\n",
      "  Running job: job_1506640654827_2729\n",
      "  Job job_1506640654827_2729 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1506640654827_2729 completed successfully\n",
      "  Output directory: hdfs:///user/jenncasper/tmp/mrjob/similarity.jenncasper.20171011.225504.488275/step-output/0000\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=213\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=453\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=146\n",
      "\t\tFILE: Number of bytes written=398316\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=511\n",
      "\t\tHDFS: Number of bytes written=453\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=9699840\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=8691200\n",
      "\t\tTotal time spent by all map tasks (ms)=6315\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=18945\n",
      "\t\tTotal time spent by all reduce tasks (ms)=3395\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=16975\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=6315\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=3395\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2620\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=268\n",
      "\t\tInput split bytes=298\n",
      "\t\tMap input records=5\n",
      "\t\tMap output bytes=245\n",
      "\t\tMap output materialized bytes=198\n",
      "\t\tMap output records=5\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1890254848\n",
      "\t\tReduce input groups=4\n",
      "\t\tReduce input records=5\n",
      "\t\tReduce output records=3\n",
      "\t\tReduce shuffle bytes=198\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=10\n",
      "\t\tTotal committed heap usage (bytes)=2264924160\n",
      "\t\tVirtual memory (bytes) snapshot=11411701760\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 2 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob3869925357017488528.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1506640654827_2731\n",
      "  Submitted application application_1506640654827_2731\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1506640654827_2731/\n",
      "  Running job: job_1506640654827_2731\n",
      "  Job job_1506640654827_2731 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1506640654827_2731 completed successfully\n",
      "  Output directory: hdfs:///user/jenncasper/hw540_outputs/systems_test_similarities_3\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=680\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=453\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=318\n",
      "\t\tFILE: Number of bytes written=398496\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=1054\n",
      "\t\tHDFS: Number of bytes written=453\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=8730624\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=8240640\n",
      "\t\tTotal time spent by all map tasks (ms)=5684\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=17052\n",
      "\t\tTotal time spent by all reduce tasks (ms)=3219\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=16095\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=5684\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=3219\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2380\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=242\n",
      "\t\tInput split bytes=374\n",
      "\t\tMap input records=3\n",
      "\t\tMap output bytes=459\n",
      "\t\tMap output materialized bytes=382\n",
      "\t\tMap output records=3\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1884303360\n",
      "\t\tReduce input groups=3\n",
      "\t\tReduce input records=3\n",
      "\t\tReduce output records=3\n",
      "\t\tReduce shuffle bytes=382\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=6\n",
      "\t\tTotal committed heap usage (bytes)=2165309440\n",
      "\t\tVirtual memory (bytes) snapshot=11410907136\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Removing HDFS temp directory hdfs:///user/jenncasper/tmp/mrjob/similarity.jenncasper.20171011.225504.488275...\n",
      "Removing temp directory /tmp/similarity.jenncasper.20171011.225504.488275...\n"
     ]
    }
   ],
   "source": [
    "# similarities for systems_test_similarities_3\n",
    "!hadoop fs -rm -r hw540_outputs/systems_test_similarities_3\n",
    "INPUT_PATH = os.path.join('hdfs:///', OUTPUT_PATH_BASE[1:],'hw540_outputs/systems_test_index_3')\n",
    "OUTPUT_PATH = os.path.join(OUTPUT_PATH_BASE, 'hw540_outputs/systems_test_similarities_3')\n",
    "!python similarity.py \\\n",
    "    -r hadoop {INPUT_PATH} \\\n",
    "    --output-dir={OUTPUT_PATH} \\\n",
    "    --no-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "-rw-r--r--   3 jenncasper users          0 2017-10-11 22:56 /user/jenncasper/hw540_outputs/systems_test_similarities_3/_SUCCESS\n",
      "-rw-r--r--   3 jenncasper users        453 2017-10-11 22:56 /user/jenncasper/hw540_outputs/systems_test_similarities_3/part-00000\n",
      "0.82079081189859815\t[\"DocA - DocB\", {\"cosine\": 0.81649658092772603, \"dice\": 0.80000000000000004, \"overlap\": 1.0, \"jaccard\": 0.66666666666666663}]\n",
      "0.55386137682121594\t[\"DocA - DocC\", {\"cosine\": 0.57735026918962584, \"dice\": 0.5714285714285714, \"overlap\": 0.66666666666666663, \"jaccard\": 0.40000000000000002}]\n",
      "0.34672168098165174\t[\"DocB - DocC\", {\"cosine\": 0.35355339059327373, \"dice\": 0.33333333333333331, \"overlap\": 0.5, \"jaccard\": 0.20000000000000001}]\n"
     ]
    }
   ],
   "source": [
    "# check the output for systems_test_similarities_3\n",
    "!hadoop fs -ls {OUTPUT_PATH}/\n",
    "!hadoop fs -cat {OUTPUT_PATH}/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Systems test  1  - Similarity measures\n",
      "\n",
      "   average |                pair |         cosine |        jaccard |        overlap |           dice\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "  1.000000 |    female - limited |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "  0.868292 |       fairy - forms |       0.866025 |       0.750000 |       1.000000 |       0.857143\n",
      "  0.868292 |       forms - tales |       0.866025 |       0.750000 |       1.000000 |       0.857143\n",
      "  0.830357 |        case - study |       0.857143 |       0.750000 |       0.857143 |       0.857143\n",
      "  0.712500 |          bill - for |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "  0.712500 |   christmas - wales |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "  0.712500 |            by - sea |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "  0.712500 |circumstantial - narrative |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "  0.712500 |           by - city |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "  0.712500 |     child's - wales |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "  0.712500 |  biography - george |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "  0.712500 | biography - general |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "  0.712500 | child's - christmas |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "  0.712500 |    bill - religious |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "  0.712500 | bill - establishing |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "  0.712500 |government - limited |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "  0.712500 |  establishing - for |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "  0.712500 |establishing - religious |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "  0.712500 |          city - sea |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "  0.712500 |       fairy - tales |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "  0.712500 | female - government |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "  0.712500 |     for - religious |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "  0.712500 |    general - george |       0.750000 |       0.600000 |       0.750000 |       0.750000\n",
      "  0.698916 |              a - of |       0.695666 |       0.500000 |       0.933333 |       0.666667\n",
      "  0.646872 |  collection - fairy |       0.670820 |       0.500000 |       0.750000 |       0.666667\n",
      "  0.646872 |  collection - tales |       0.670820 |       0.500000 |       0.750000 |       0.666667\n",
      "  0.559350 |          city - the |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "  0.559350 |  government - study |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "  0.559350 |     narrative - the |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "  0.559350 |         female - in |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "  0.559350 |     limited - study |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "  0.559350 |      female - study |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "  0.559350 |          in - wales |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "  0.559350 |     government - in |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "  0.559350 |           sea - the |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "  0.559350 |        in - limited |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "  0.559350 |   case - government |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "  0.559350 |       case - female |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "  0.559350 |        child's - in |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "  0.559350 |            by - the |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "  0.559350 |      case - limited |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "  0.559350 |      christmas - in |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "  0.559350 |circumstantial - the |       0.566947 |       0.375000 |       0.750000 |       0.545455\n",
      "  0.553861 |   biography - forms |       0.577350 |       0.400000 |       0.666667 |       0.571429\n",
      "  0.553861 |circumstantial - forms |       0.577350 |       0.400000 |       0.666667 |       0.571429\n",
      "  0.553861 |     forms - general |       0.577350 |       0.400000 |       0.666667 |       0.571429\n",
      "  0.553861 |      forms - george |       0.577350 |       0.400000 |       0.666667 |       0.571429\n",
      "  0.553861 |     forms - limited |       0.577350 |       0.400000 |       0.666667 |       0.571429\n",
      "  0.553861 |   forms - narrative |       0.577350 |       0.400000 |       0.666667 |       0.571429\n",
      "  0.553861 |      female - forms |       0.577350 |       0.400000 |       0.666667 |       0.571429\n",
      "  0.504099 |  collection - forms |       0.516398 |       0.333333 |       0.666667 |       0.500000\n",
      "  0.477970 |     collection - of |       0.461880 |       0.250000 |       0.800000 |       0.400000\n",
      "  0.465201 |           a - study |       0.436436 |       0.214286 |       0.857143 |       0.352941\n",
      "  0.465201 |            a - case |       0.436436 |       0.214286 |       0.857143 |       0.352941\n",
      "  0.465201 |             a - the |       0.436436 |       0.214286 |       0.857143 |       0.352941\n",
      "  0.465201 |              a - in |       0.436436 |       0.214286 |       0.857143 |       0.352941\n",
      "  0.458333 |circumstantial - city |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |circumstantial - fairy |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |biography - circumstantial |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |   biography - fairy |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |  biography - female |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |circumstantial - female |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |christmas - government |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |circumstantial - general |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |circumstantial - george |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 | biography - limited |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |biography - narrative |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |   biography - tales |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 | by - circumstantial |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |circumstantial - limited |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |      by - narrative |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |circumstantial - sea |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |child's - government |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |circumstantial - tales |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |   narrative - tales |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |     female - george |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |     narrative - sea |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 | general - narrative |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |  george - narrative |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |  female - narrative |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |     limited - tales |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |     fairy - general |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |      female - tales |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |     general - tales |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 | limited - narrative |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |      george - tales |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |    george - limited |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |      fairy - female |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |      fairy - george |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |    city - narrative |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |     fairy - limited |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |   fairy - narrative |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |   general - limited |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |    female - general |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.458333 |  government - wales |       0.500000 |       0.333333 |       0.500000 |       0.500000\n",
      "  0.438276 |       forms - study |       0.436436 |       0.250000 |       0.666667 |       0.400000\n",
      "  0.438276 |         forms - the |       0.436436 |       0.250000 |       0.666667 |       0.400000\n",
      "  0.438276 |        case - forms |       0.436436 |       0.250000 |       0.666667 |       0.400000\n",
      "  0.419343 |circumstantial - collection |       0.447214 |       0.285714 |       0.500000 |       0.444444\n",
      "  0.419343 |biography - collection |       0.447214 |       0.285714 |       0.500000 |       0.444444\n",
      "  0.419343 |collection - limited |       0.447214 |       0.285714 |       0.500000 |       0.444444\n",
      "  0.419343 | collection - george |       0.447214 |       0.285714 |       0.500000 |       0.444444\n",
      "  0.419343 |collection - general |       0.447214 |       0.285714 |       0.500000 |       0.444444\n",
      "  0.419343 | collection - female |       0.447214 |       0.285714 |       0.500000 |       0.444444\n",
      "  0.419343 |collection - narrative |       0.447214 |       0.285714 |       0.500000 |       0.444444\n",
      "  0.410147 |     government - of |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "  0.410147 |        general - of |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "  0.410147 |         george - of |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "  0.410147 |          fairy - of |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "  0.410147 |      narrative - of |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "  0.410147 |         female - of |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "  0.410147 |        limited - of |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "  0.410147 |          of - tales |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "  0.410147 |      biography - of |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "  0.410147 | circumstantial - of |       0.387298 |       0.187500 |       0.750000 |       0.315789\n",
      "  0.389610 |           case - in |       0.428571 |       0.272727 |       0.428571 |       0.428571\n",
      "  0.389610 |          in - study |       0.428571 |       0.272727 |       0.428571 |       0.428571\n",
      "  0.386912 |          of - study |       0.390360 |       0.222222 |       0.571429 |       0.363636\n",
      "  0.386912 |           case - of |       0.390360 |       0.222222 |       0.571429 |       0.363636\n",
      "  0.384281 |      a - collection |       0.344265 |       0.142857 |       0.800000 |       0.250000\n",
      "  0.365956 |    case - narrative |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "  0.365956 |     child's - study |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "  0.365956 |   christmas - study |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "  0.365956 |      case - child's |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "  0.365956 |    case - christmas |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "  0.365956 |case - circumstantial |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "  0.365956 |        case - wales |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "  0.365956 |        case - fairy |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "  0.365956 |circumstantial - study |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "  0.365956 |      case - general |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "  0.365956 |       case - george |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "  0.365956 |        case - tales |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "  0.365956 |   biography - study |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "  0.365956 |     biography - the |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "  0.365956 |    biography - case |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "  0.365956 |        george - the |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "  0.365956 |       general - the |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "  0.365956 |     general - study |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "  0.365956 |       study - tales |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "  0.365956 |         tales - the |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "  0.365956 |        female - the |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "  0.365956 |      george - study |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "  0.365956 |       limited - the |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "  0.365956 |   narrative - study |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "  0.365956 |         fairy - the |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "  0.365956 |       fairy - study |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "  0.365956 |       study - wales |       0.377964 |       0.222222 |       0.500000 |       0.363636\n",
      "  0.334842 |            a - bill |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "  0.334842 |           a - wales |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "  0.334842 |           a - tales |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "  0.334842 |             a - sea |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "  0.334842 |       a - religious |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "  0.334842 |       a - narrative |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "  0.334842 |         a - limited |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "  0.334842 |      a - government |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "  0.334842 |          a - george |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "  0.334842 |         a - general |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "  0.334842 |             a - for |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "  0.334842 |          a - female |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "  0.334842 |           a - fairy |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "  0.334842 |    a - establishing |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "  0.334842 |            a - city |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "  0.334842 |  a - circumstantial |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "  0.334842 |       a - christmas |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "  0.334842 |         a - child's |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "  0.334842 |              a - by |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "  0.334842 |       a - biography |       0.288675 |       0.107143 |       0.750000 |       0.193548\n",
      "  0.328008 |          forms - of |       0.298142 |       0.125000 |       0.666667 |       0.222222\n",
      "  0.317849 |  collection - study |       0.338062 |       0.200000 |       0.400000 |       0.333333\n",
      "  0.317849 |    collection - the |       0.338062 |       0.200000 |       0.400000 |       0.333333\n",
      "  0.317849 |   case - collection |       0.338062 |       0.200000 |       0.400000 |       0.333333\n",
      "  0.287991 |            of - the |       0.292770 |       0.157895 |       0.428571 |       0.272727\n",
      "  0.287991 |             in - of |       0.292770 |       0.157895 |       0.428571 |       0.272727\n",
      "  0.273413 |           a - forms |       0.222222 |       0.071429 |       0.666667 |       0.133333\n",
      "  0.271593 |             by - of |       0.258199 |       0.117647 |       0.500000 |       0.210526\n",
      "  0.271593 |           city - of |       0.258199 |       0.117647 |       0.500000 |       0.210526\n",
      "  0.271593 |            of - sea |       0.258199 |       0.117647 |       0.500000 |       0.210526\n",
      "  0.268597 |       forms - wales |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "  0.268597 |        city - forms |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "  0.268597 |   forms - religious |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "  0.268597 |         for - forms |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "  0.268597 |         forms - sea |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "  0.268597 |establishing - forms |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "  0.268597 |  forms - government |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "  0.268597 |   christmas - forms |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "  0.268597 |     child's - forms |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "  0.268597 |        bill - forms |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "  0.268597 |          by - forms |       0.288675 |       0.166667 |       0.333333 |       0.285714\n",
      "  0.255952 |          case - the |       0.285714 |       0.166667 |       0.285714 |       0.285714\n",
      "  0.255952 |         study - the |       0.285714 |       0.166667 |       0.285714 |       0.285714\n",
      "  0.223214 |         sea - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |         sea - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |     general - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |         for - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |         for - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |        city - fairy |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |           for - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 | george - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |      city - general |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |     for - narrative |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |       for - limited |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |   religious - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |    for - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |        for - george |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |       for - general |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |      female - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 | limited - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |       limited - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |        female - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |       tales - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |     limited - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |government - narrative |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |narrative - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |   narrative - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |          city - for |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |        female - for |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |       fairy - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |   city - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |         fairy - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |   fairy - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |      george - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |  george - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |      city - limited |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |  female - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |  fairy - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |    city - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |        george - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |         fairy - for |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |        city - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |establishing - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |     religious - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |establishing - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |       city - female |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |  establishing - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |        city - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |       city - george |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |establishing - narrative |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |establishing - limited |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |establishing - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |establishing - george |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |establishing - general |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |establishing - female |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |establishing - fairy |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 | general - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |       general - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |government - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |    government - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |   religious - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |general - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |  government - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |biography - establishing |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |     by - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |         by - george |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |child's - circumstantial |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |      child's - city |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |child's - establishing |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |     child's - fairy |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |    child's - female |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |       child's - for |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |        by - general |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |   child's - general |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |    child's - george |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |            by - for |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |         by - female |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |          by - fairy |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |   by - establishing |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |          by - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |christmas - circumstantial |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |      by - christmas |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |        by - child's |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |          by - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |   biography - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |    christmas - city |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |christmas - establishing |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |     biography - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |biography - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |   christmas - fairy |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |  christmas - female |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |     christmas - for |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |       child's - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |biography - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 | christmas - general |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |  christmas - george |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |     biography - for |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 | christmas - limited |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |christmas - narrative |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |   child's - limited |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |    biography - city |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |christmas - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |biography - christmas |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 | biography - child's |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |     christmas - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |      biography - by |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |        bill - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 | child's - narrative |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |        bill - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |      by - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |          bill - sea |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |   christmas - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |    bill - narrative |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |      bill - limited |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |   bill - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |       bill - george |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |      bill - general |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |     child's - tales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |       bill - female |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |        bill - fairy |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |circumstantial - establishing |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |         bill - city |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |bill - circumstantial |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |    bill - christmas |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |      bill - child's |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |        by - limited |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |           bill - by |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |    bill - biography |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |circumstantial - for |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |circumstantial - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |circumstantial - government |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 | city - establishing |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 |circumstantial - wales |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.223214 | child's - religious |       0.250000 |       0.142857 |       0.250000 |       0.250000\n",
      "  0.215666 |          forms - in |       0.218218 |       0.111111 |       0.333333 |       0.200000\n",
      "  0.205207 |  collection - wales |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "  0.205207 |collection - religious |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "  0.205207 |    collection - for |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "  0.205207 |collection - establishing |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "  0.205207 |    collection - sea |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "  0.205207 |collection - government |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "  0.205207 |christmas - collection |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "  0.205207 |child's - collection |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "  0.205207 |   bill - collection |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "  0.205207 |   city - collection |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "  0.205207 |     by - collection |       0.223607 |       0.125000 |       0.250000 |       0.222222\n",
      "  0.180200 |          bill - the |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |          by - study |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |             by - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |       child's - the |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |           by - case |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |      biography - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |        bill - study |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |           bill - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |     christmas - the |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |         bill - case |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 | circumstantial - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |          case - sea |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |    case - religious |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |          case - for |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 | case - establishing |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |         case - city |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |         the - wales |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |         sea - study |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |     religious - the |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |   religious - study |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |          in - tales |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |            in - sea |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |      in - religious |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |      in - narrative |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |    government - the |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |         george - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |        general - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |           for - the |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |            for - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |          fairy - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |  establishing - the |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |establishing - study |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |   establishing - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |        city - study |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |           city - in |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.180200 |         for - study |       0.188982 |       0.100000 |       0.250000 |       0.181818\n",
      "  0.156652 |     collection - in |       0.169031 |       0.090909 |       0.200000 |       0.166667\n",
      "  0.134980 |   establishing - of |       0.129099 |       0.055556 |       0.250000 |       0.105263\n",
      "  0.134980 |            for - of |       0.129099 |       0.055556 |       0.250000 |       0.105263\n",
      "  0.134980 |      of - religious |       0.129099 |       0.055556 |       0.250000 |       0.105263\n",
      "  0.134980 |          of - wales |       0.129099 |       0.055556 |       0.250000 |       0.105263\n",
      "  0.134980 |        child's - of |       0.129099 |       0.055556 |       0.250000 |       0.105263\n",
      "  0.134980 |      christmas - of |       0.129099 |       0.055556 |       0.250000 |       0.105263\n",
      "  0.134980 |           bill - of |       0.129099 |       0.055556 |       0.250000 |       0.105263\n",
      "  0.126374 |            in - the |       0.142857 |       0.076923 |       0.142857 |       0.142857\n",
      "\n",
      "Systems test  2  - Similarity measures\n",
      "\n",
      "   average |                pair |         cosine |        jaccard |        overlap |           dice\n",
      "--------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.000000 |        atlas - cava |       1.000000 |       1.000000 |       1.000000 |       1.000000\n",
      "  0.625000 |       boon - dipped |       0.666667 |       0.500000 |       0.666667 |       0.666667\n",
      "  0.389562 |       cava - dipped |       0.408248 |       0.250000 |       0.500000 |       0.400000\n",
      "  0.389562 |         boon - cava |       0.408248 |       0.250000 |       0.500000 |       0.400000\n",
      "  0.389562 |      atlas - dipped |       0.408248 |       0.250000 |       0.500000 |       0.400000\n",
      "  0.389562 |        atlas - boon |       0.408248 |       0.250000 |       0.500000 |       0.400000\n",
      "\n",
      "Systems test  3  - Similarity measures\n",
      "\n",
      "   average |                pair |         cosine |        jaccard |        overlap |           dice\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "  0.820791 |         DocA - DocB |       0.816497 |       0.666667 |       1.000000 |       0.800000\n",
      "  0.553861 |         DocA - DocC |       0.577350 |       0.400000 |       0.666667 |       0.571429\n",
      "  0.346722 |         DocB - DocC |       0.353553 |       0.200000 |       0.500000 |       0.333333\n"
     ]
    }
   ],
   "source": [
    "############################################\n",
    "# Pretty print systems tests from HDFS\n",
    "############################################\n",
    "\n",
    "import json, ast\n",
    "import subprocess\n",
    "\n",
    "for i in range(1,4):\n",
    "    print ''*110\n",
    "    print \"Systems test \",i,\" - Similarity measures\"\n",
    "    print ''*110\n",
    "    print \"{0:>10} |{1:>20} |{2:>15} |{3:>15} |{4:>15} |{5:>15}\".format(\n",
    "          \"average\", \"pair\", \"cosine\", \"jaccard\", \"overlap\", \"dice\")\n",
    "    print '-'*110\n",
    "\n",
    "    INDEX_PATH = os.path.join(OUTPUT_PATH_BASE, 'hw540_outputs/systems_test_similarities_'+str(i), '*')\n",
    "    cat = subprocess.Popen([\"hadoop\", \"fs\", \"-cat\", INDEX_PATH], stdout=subprocess.PIPE)\n",
    "    for line in cat.stdout:\n",
    "        line = line.strip()\n",
    "        avg, stripe = line.split(\"\\t\")\n",
    "        pair, dist_dict = json.loads(stripe)\n",
    "            \n",
    "        print \"{0:>10f} |{1:>20} |{2:>15f} |{3:>15f} |{4:>15f} |{5:>15f}\".format(\n",
    "            float(avg), pair, float(dist_dict['cosine']), float(dist_dict['jaccard']), \n",
    "            float(dist_dict['overlap']), float(dist_dict['dice']))\n",
    "            \n",
    "        cat.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  HW5.4.1 <a name=\"5.4.1\"></a>Full-scale experiment: EDA of Google n-grams dataset (PHASE 2) (~14hrs)\n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "Do some EDA on this dataset using mrjob, e.g., \n",
    "\n",
    "- A. Longest 5-gram (number of characters)\n",
    "- B. Top 10 most frequent words (please use the count information), i.e., unigrams\n",
    "- C. 20 Most/Least densely appearing words (count/pages_count) sorted in decreasing order of relative frequency \n",
    "- D. Distribution of 5-gram sizes (character length).  E.g., count (using the count field) up how many times a 5-gram of 50 characters shows up. Plot the data graphically using a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           1          190         2156069116 /user/winegarj/data/full\n",
      "        none             inf            none             inf            0            1                  0 /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-1-filtered.txt\n",
      "        none             inf            none             inf            0            1                  0 /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-46-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-0-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-10-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-101-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-102-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-103-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-104-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-106-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-108-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-109-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-110-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-111-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-112-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-113-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-114-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-116-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-117-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-119-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-12-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-120-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-121-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-122-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-125-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-126-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-127-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-128-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-129-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-130-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-131-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-133-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-134-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-135-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-137-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-138-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-139-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-14-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-140-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-142-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-144-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-145-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-146-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-147-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-148-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-149-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-15-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-150-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-151-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-152-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-155-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-156-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-157-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-158-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-159-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-160-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-161-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-163-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-165-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-166-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-167-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-169-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-170-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-171-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-172-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-173-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-175-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-176-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-179-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-180-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-181-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-184-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-185-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-186-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-187-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-188-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-189-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-19-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-2-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-21-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-23-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-24-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-25-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-26-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-27-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-28-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-29-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-3-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-30-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-31-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-32-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-33-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-34-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-37-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-38-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-39-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-4-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-40-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-42-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-43-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-44-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-47-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-50-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-51-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-52-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-53-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-54-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-55-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-56-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-58-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-59-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-6-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-60-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-62-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-63-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-64-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-66-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-67-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-7-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-70-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-71-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-73-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-76-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-77-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-78-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-79-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-8-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-80-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-81-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-82-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-84-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-88-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-9-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-91-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-92-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-93-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-94-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-97-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-98-filtered.txt\n",
      "        none             inf            none             inf            0            1             10.9 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-99-filtered.txt\n",
      "        none             inf            none             inf            0            1             11.0 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-100-filtered.txt\n",
      "        none             inf            none             inf            0            1             11.0 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-105-filtered.txt\n",
      "        none             inf            none             inf            0            1             11.0 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-107-filtered.txt\n",
      "        none             inf            none             inf            0            1             11.0 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-11-filtered.txt\n",
      "        none             inf            none             inf            0            1             11.0 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-115-filtered.txt\n",
      "        none             inf            none             inf            0            1             11.0 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-118-filtered.txt\n",
      "        none             inf            none             inf            0            1             11.0 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-123-filtered.txt\n",
      "        none             inf            none             inf            0            1             11.0 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-124-filtered.txt\n",
      "        none             inf            none             inf            0            1             11.0 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-13-filtered.txt\n",
      "        none             inf            none             inf            0            1             11.0 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-132-filtered.txt\n",
      "        none             inf            none             inf            0            1             11.0 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-136-filtered.txt\n",
      "        none             inf            none             inf            0            1             11.0 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-141-filtered.txt\n",
      "        none             inf            none             inf            0            1             11.0 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-143-filtered.txt\n",
      "        none             inf            none             inf            0            1             11.0 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-153-filtered.txt\n",
      "        none             inf            none             inf            0            1             11.0 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-154-filtered.txt\n",
      "        none             inf            none             inf            0            1             11.0 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-16-filtered.txt\n",
      "        none             inf            none             inf            0            1             11.0 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-162-filtered.txt\n",
      "        none             inf            none             inf            0            1             11.0 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-164-filtered.txt\n",
      "        none             inf            none             inf            0            1             11.0 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-168-filtered.txt\n",
      "        none             inf            none             inf            0            1             11.0 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-17-filtered.txt\n",
      "        none             inf            none             inf            0            1             11.0 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-174-filtered.txt\n",
      "        none             inf            none             inf            0            1             11.0 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-177-filtered.txt\n",
      "        none             inf            none             inf            0            1             11.0 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-178-filtered.txt\n",
      "        none             inf            none             inf            0            1             11.0 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-18-filtered.txt\n",
      "        none             inf            none             inf            0            1             11.0 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-182-filtered.txt\n",
      "        none             inf            none             inf            0            1             11.0 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-183-filtered.txt\n",
      "        none             inf            none             inf            0            1             11.0 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-20-filtered.txt\n",
      "        none             inf            none             inf            0            1             11.0 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-22-filtered.txt\n",
      "        none             inf            none             inf            0            1             11.0 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-35-filtered.txt\n",
      "        none             inf            none             inf            0            1             11.0 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-36-filtered.txt\n",
      "        none             inf            none             inf            0            1             11.0 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-41-filtered.txt\n",
      "        none             inf            none             inf            0            1             11.0 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-45-filtered.txt\n",
      "        none             inf            none             inf            0            1             11.0 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-48-filtered.txt\n",
      "        none             inf            none             inf            0            1             11.0 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-49-filtered.txt\n",
      "        none             inf            none             inf            0            1             11.0 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-5-filtered.txt\n",
      "        none             inf            none             inf            0            1             11.0 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-57-filtered.txt\n",
      "        none             inf            none             inf            0            1             11.0 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-61-filtered.txt\n",
      "        none             inf            none             inf            0            1             11.0 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-65-filtered.txt\n",
      "        none             inf            none             inf            0            1             11.0 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-68-filtered.txt\n",
      "        none             inf            none             inf            0            1             11.0 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-69-filtered.txt\n",
      "        none             inf            none             inf            0            1             11.0 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-72-filtered.txt\n",
      "        none             inf            none             inf            0            1             11.0 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-74-filtered.txt\n",
      "        none             inf            none             inf            0            1             11.0 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-75-filtered.txt\n",
      "        none             inf            none             inf            0            1             11.0 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-83-filtered.txt\n",
      "        none             inf            none             inf            0            1             11.0 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-85-filtered.txt\n",
      "        none             inf            none             inf            0            1             11.0 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-86-filtered.txt\n",
      "        none             inf            none             inf            0            1             11.0 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-87-filtered.txt\n",
      "        none             inf            none             inf            0            1             11.0 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-89-filtered.txt\n",
      "        none             inf            none             inf            0            1             11.0 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-90-filtered.txt\n",
      "        none             inf            none             inf            0            1             11.0 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-95-filtered.txt\n",
      "        none             inf            none             inf            0            1             11.0 M /user/winegarj/data/full/googlebooks-eng-all-5gram-20090715-96-filtered.txt\n"
     ]
    }
   ],
   "source": [
    "# scope out the ngrams input files\n",
    "!hadoop fs -count /user/winegarj/data/full\n",
    "!hadoop fs -count -q -h /user/winegarj/data/full/* | sort -k7,7n\n",
    "# 2 of the 190 files are empty?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW5.4.1 - A. Longest 5-gram (number of characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting longest5gram.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile longest5gram.py\n",
    "#!~/anaconda2/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import re\n",
    "\n",
    "import mrjob\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "\n",
    "class longest5gram(MRJob):\n",
    "    \n",
    "    # START STUDENT CODE 5.4.1.A\n",
    "\n",
    "    MRJob.SORT_VALUES = True\n",
    "    \n",
    "    # purpose: need a mapper, combiner, and reducer in this case\n",
    "    def steps(self):\n",
    "        JOBCONF_STEP = {\n",
    "            'mapreduce.job.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "            'mapreduce.partition.keycomparator.options':'-k1,1',\n",
    "        }\n",
    "        return [\n",
    "            MRStep(jobconf = JOBCONF_STEP,\n",
    "                   mapper = self.mapper,\n",
    "                   combiner = self.combiner,\n",
    "                   reducer = self.reducer,\n",
    "            )\n",
    "        ]\n",
    "    \n",
    "    # purpose: figure out the length in chars of each ngram\n",
    "    # input: key(None), value(ngram\\tcount\\tpage\\tbook)\n",
    "    # output: key(None), value(ngram string, length of ngram string)\n",
    "    def mapper(self, _, line):\n",
    "        ngram, count, page, book = line.lower().strip().split(\"\\t\")\n",
    "        yield None, (ngram, len(ngram))\n",
    "    \n",
    "    # purpose: find the max length ngram\n",
    "    # input: key(None), value(ngram string, length of ngram string)\n",
    "    # output: key(None), value(max ngram string, max length of ngram string)\n",
    "    def combiner(self, _, data):\n",
    "        yield None, max(data, key=lambda item: item[1])\n",
    "    \n",
    "    # purpose: find the max length ngram across all mappers\n",
    "    def reducer(self, _, data):\n",
    "        yield max(data, key=lambda item: item[1])\n",
    "        \n",
    "    # END STUDENT CODE 5.4.1.A\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    longest5gram.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__On test data set:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "ignoring partitioner keyword arg (requires real Hadoop): 'org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner'\n",
      "Creating temp directory /tmp/longest5gram.jenncasper.20171009.180015.001257\n",
      "Running step 1 of 1...\n",
      "Streaming final output from /tmp/longest5gram.jenncasper.20171009.180015.001257/output...\n",
      "\"a bill for establishing religious\"\t33\n",
      "Removing temp directory /tmp/longest5gram.jenncasper.20171009.180015.001257...\n"
     ]
    }
   ],
   "source": [
    "# test longest5gram.py locally on the google sample\n",
    "!python longest5gram.py -r local googlebooks-eng-all-5gram-20090715-0-filtered-first-10-lines.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__On full data set:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `hw541_outputs/longest5gram': No such file or directory\n",
      "No configs found; falling back on auto-configuration\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Creating temp directory /tmp/longest5gram.jenncasper.20171009.180351.831061\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/jenncasper/tmp/mrjob/longest5gram.jenncasper.20171009.180351.831061/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 1...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob8502973787240079983.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 190\n",
      "  number of splits:190\n",
      "  Submitting tokens for job: job_1506640654827_1601\n",
      "  Submitted application application_1506640654827_1601\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1506640654827_1601/\n",
      "  Running job: job_1506640654827_1601\n",
      "  Job job_1506640654827_1601 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 1% reduce 0%\n",
      "   map 2% reduce 0%\n",
      "   map 3% reduce 0%\n",
      "   map 4% reduce 0%\n",
      "   map 5% reduce 0%\n",
      "   map 6% reduce 0%\n",
      "   map 7% reduce 0%\n",
      "   map 8% reduce 0%\n",
      "   map 9% reduce 0%\n",
      "   map 10% reduce 0%\n",
      "   map 11% reduce 0%\n",
      "   map 12% reduce 0%\n",
      "   map 13% reduce 0%\n",
      "   map 14% reduce 0%\n",
      "   map 15% reduce 0%\n",
      "   map 16% reduce 0%\n",
      "   map 17% reduce 0%\n",
      "   map 18% reduce 0%\n",
      "   map 19% reduce 0%\n",
      "   map 20% reduce 0%\n",
      "   map 21% reduce 0%\n",
      "   map 22% reduce 0%\n",
      "   map 23% reduce 0%\n",
      "   map 24% reduce 0%\n",
      "   map 25% reduce 0%\n",
      "   map 26% reduce 0%\n",
      "   map 27% reduce 0%\n",
      "   map 28% reduce 0%\n",
      "   map 29% reduce 0%\n",
      "   map 30% reduce 0%\n",
      "   map 31% reduce 0%\n",
      "   map 32% reduce 0%\n",
      "   map 33% reduce 0%\n",
      "   map 34% reduce 0%\n",
      "   map 35% reduce 0%\n",
      "   map 36% reduce 0%\n",
      "   map 37% reduce 0%\n",
      "   map 38% reduce 0%\n",
      "   map 39% reduce 0%\n",
      "   map 40% reduce 0%\n",
      "   map 41% reduce 0%\n",
      "   map 42% reduce 0%\n",
      "   map 43% reduce 0%\n",
      "   map 44% reduce 0%\n",
      "   map 45% reduce 0%\n",
      "   map 46% reduce 0%\n",
      "   map 47% reduce 0%\n",
      "   map 48% reduce 0%\n",
      "   map 49% reduce 0%\n",
      "   map 50% reduce 0%\n",
      "   map 51% reduce 0%\n",
      "   map 52% reduce 0%\n",
      "   map 53% reduce 0%\n",
      "   map 54% reduce 0%\n",
      "   map 55% reduce 0%\n",
      "   map 56% reduce 0%\n",
      "   map 57% reduce 0%\n",
      "   map 58% reduce 0%\n",
      "   map 59% reduce 0%\n",
      "   map 60% reduce 0%\n",
      "   map 61% reduce 0%\n",
      "   map 62% reduce 0%\n",
      "   map 63% reduce 0%\n",
      "   map 64% reduce 0%\n",
      "   map 65% reduce 0%\n",
      "   map 66% reduce 0%\n",
      "   map 67% reduce 0%\n",
      "   map 68% reduce 0%\n",
      "   map 69% reduce 0%\n",
      "   map 70% reduce 0%\n",
      "   map 71% reduce 0%\n",
      "   map 72% reduce 0%\n",
      "   map 73% reduce 0%\n",
      "   map 74% reduce 0%\n",
      "   map 75% reduce 0%\n",
      "   map 76% reduce 0%\n",
      "   map 77% reduce 0%\n",
      "   map 78% reduce 0%\n",
      "   map 79% reduce 0%\n",
      "   map 80% reduce 0%\n",
      "   map 81% reduce 0%\n",
      "   map 82% reduce 0%\n",
      "   map 83% reduce 0%\n",
      "   map 84% reduce 0%\n",
      "   map 85% reduce 0%\n",
      "   map 86% reduce 0%\n",
      "   map 87% reduce 0%\n",
      "   map 88% reduce 0%\n",
      "   map 89% reduce 0%\n",
      "   map 90% reduce 0%\n",
      "   map 91% reduce 0%\n",
      "   map 92% reduce 0%\n",
      "   map 93% reduce 0%\n",
      "   map 94% reduce 0%\n",
      "   map 95% reduce 0%\n",
      "   map 96% reduce 0%\n",
      "   map 97% reduce 0%\n",
      "   map 98% reduce 0%\n",
      "   map 99% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1506640654827_1601 completed successfully\n",
      "  Output directory: hdfs:///user/jenncasper/hw541_outputs/longest5gram\n",
      "Counters: 51\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=2156069116\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=166\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=8576\n",
      "\t\tFILE: Number of bytes written=25431439\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=2156099976\n",
      "\t\tHDFS: Number of bytes written=166\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=573\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tKilled map tasks=2\n",
      "\t\tLaunched map tasks=192\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tOther local map tasks=2\n",
      "\t\tRack-local map tasks=190\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=23929168896\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=8325120\n",
      "\t\tTotal time spent by all map tasks (ms)=15578886\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=46736658\n",
      "\t\tTotal time spent by all reduce tasks (ms)=3252\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=16260\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=15578886\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=3252\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=6939920\n",
      "\t\tCombine input records=58682266\n",
      "\t\tCombine output records=188\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=99831\n",
      "\t\tInput split bytes=30860\n",
      "\t\tMap input records=58682266\n",
      "\t\tMap output bytes=2390412759\n",
      "\t\tMap output materialized bytes=17738\n",
      "\t\tMap output records=58682266\n",
      "\t\tMerged Map outputs=190\n",
      "\t\tPhysical memory (bytes) snapshot=153501384704\n",
      "\t\tReduce input groups=1\n",
      "\t\tReduce input records=188\n",
      "\t\tReduce output records=1\n",
      "\t\tReduce shuffle bytes=17738\n",
      "\t\tShuffled Maps =190\n",
      "\t\tSpilled Records=376\n",
      "\t\tTotal committed heap usage (bytes)=168563834880\n",
      "\t\tVirtual memory (bytes) snapshot=654644191232\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Removing HDFS temp directory hdfs:///user/jenncasper/tmp/mrjob/longest5gram.jenncasper.20171009.180351.831061...\n",
      "Removing temp directory /tmp/longest5gram.jenncasper.20171009.180351.831061...\n"
     ]
    }
   ],
   "source": [
    "# longest5gram.py on the full data set\n",
    "!hadoop fs -rm -r hw541_outputs/longest5gram\n",
    "OUTPUT_PATH = os.path.join(OUTPUT_PATH_BASE, 'hw541_outputs/longest5gram')\n",
    "!python longest5gram.py \\\n",
    "    -r hadoop hdfs:///user/winegarj/data/full/ \\\n",
    "    --output-dir={OUTPUT_PATH} \\\n",
    "    --no-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "-rw-r--r--   3 jenncasper users          0 2017-10-09 18:19 /user/jenncasper/hw541_outputs/longest5gram/_SUCCESS\n",
      "-rw-r--r--   3 jenncasper users        166 2017-10-09 18:19 /user/jenncasper/hw541_outputs/longest5gram/part-00000\n",
      "\"aiopjumrxuyvaslyhypsibemapodikr ufrydiuuolbigasuaurusrexlisnaye rnoondqsrunsubunougrabberyairtc utahraptoredileipmilbdummyuveri syevrahvelocyallosauruslinrotsr\"\t159\n"
     ]
    }
   ],
   "source": [
    "# check longest5gram.py output\n",
    "!hadoop fs -ls {OUTPUT_PATH}\n",
    "!hadoop fs -cat {OUTPUT_PATH}/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report stats for longest5gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Longest 5grams MR stats\n",
    "\n",
    "\n",
    "__Step 1:__  \n",
    "\n",
    "    CPU time spent (ms)=6939920  \n",
    "    Map tasks = 192\n",
    "    Reduce tasks = 1 \n",
    "    \n",
    "__Step 2:__   \n",
    "\n",
    "    N/A  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW5.4.1 - B. Top 10 most frequent words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jenncasper/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the nltk stopwords\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mostFrequentWords.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mostFrequentWords.py\n",
    "#!~/anaconda2/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import re\n",
    "\n",
    "import mrjob\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "from collections import defaultdict\n",
    "\n",
    "class mostFrequentWords(MRJob):\n",
    "    \n",
    "    # START STUDENT CODE 5.4.1.B\n",
    "    \n",
    "    MRJob.SORT_VALUES = True\n",
    "    \n",
    "    # purpose: steps needed to find the top 10 most frequent words\n",
    "    def steps(self):\n",
    "        JOBCONF_STEP = {\n",
    "            'mapreduce.job.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "            'mapreduce.partition.keycomparator.options':'-k1,1',\n",
    "        }\n",
    "        JOBCONF_STEP2 = {\n",
    "            'mapreduce.job.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "            'mapreduce.partition.keycomparator.options':'-k1,1nr',\n",
    "        }\n",
    "        \n",
    "        return [\n",
    "            MRStep(jobconf = JOBCONF_STEP,\n",
    "                   mapper_init = self.mapper_init,\n",
    "                   mapper = self.mapper,\n",
    "                   mapper_final = self.mapper_final,\n",
    "                   combiner = self.combiner,\n",
    "                   reducer = self.reducer,\n",
    "            ),\n",
    "            MRStep(jobconf = JOBCONF_STEP2,\n",
    "                   mapper = None,\n",
    "                   reducer = self.reducer_sort,  \n",
    "            ),\n",
    "        ]\n",
    "    \n",
    "    # purpose: define the mapper's dict used to track word freq\n",
    "    def mapper_init(self):\n",
    "        self.word_counts = defaultdict(int)\n",
    "        self.stopWords = [sw for sw in open('english').read().strip().split('\\n')]\n",
    "    \n",
    "    # purpose: split the line and capture the count for each ngram word\n",
    "    # input: key(None), value(ngram\\tcount\\tpage\\tbook)\n",
    "    # output: nothing; counts are stored in the mapper's internal dict word_counts\n",
    "    def mapper(self, _, line):\n",
    "        ngram, count, page, book = line.lower().strip().split(\"\\t\")\n",
    "        # drop word if it is an nltk stopword\n",
    "        for word in ngram.split(' '):\n",
    "            if word not in self.stopWords:\n",
    "                self.word_counts[word] += int(count)\n",
    "            \n",
    "    # purpose: emit the word and count pairs to the combiner for summing counts for each word\n",
    "    # input: use the mapper's internal word_counts dict\n",
    "    # output: key(word), value(count for the word emitted from the mapper)\n",
    "    def mapper_final(self):\n",
    "        for word, count in self.word_counts.iteritems():\n",
    "            yield word, count\n",
    "    \n",
    "    # purpose: sum up the counts for the same words processed by a mapper\n",
    "    # input: key(word), value(count for the word emitted from the mapper)\n",
    "    # output: key(word), value(sum of the word's counts)\n",
    "    def combiner(self, word, count):\n",
    "        yield word, sum(count)\n",
    "    \n",
    "    # purpose: sum up all of the word counts across the mappers\n",
    "    # input: key(word), value(sum of the word's counts from the combiners)\n",
    "    # output: key(sum of the word's counts), value(word)\n",
    "    def reducer(self, word, count):\n",
    "        #yield None, (int(sum(count)), word)\n",
    "        yield sum(count), word\n",
    "    \n",
    "    # purpose: get the sorted outputs\n",
    "    def reducer_sort(self, count, word):\n",
    "        for w in word:\n",
    "            yield count, w\n",
    "    \n",
    "    # END STUDENT CODE 5.4.1.B\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    mostFrequentWords.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__On the test data set:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /tmp/mostFrequentWords.jenncasper.20171011.141345.092184\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/jenncasper/tmp/mrjob/mostFrequentWords.jenncasper.20171011.141345.092184/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob4411733989974011021.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1506640654827_2433\n",
      "  Submitted application application_1506640654827_2433\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1506640654827_2433/\n",
      "  Running job: job_1506640654827_2433\n",
      "  Job job_1506640654827_2433 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1506640654827_2433 completed successfully\n",
      "  Output directory: hdfs:///user/jenncasper/tmp/mrjob/mostFrequentWords.jenncasper.20171011.141345.092184/step-output/0000\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=563\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=301\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=352\n",
      "\t\tFILE: Number of bytes written=401745\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=1037\n",
      "\t\tHDFS: Number of bytes written=301\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=10355712\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=9062400\n",
      "\t\tTotal time spent by all map tasks (ms)=6742\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=20226\n",
      "\t\tTotal time spent by all reduce tasks (ms)=3540\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=17700\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=6742\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=3540\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=3050\n",
      "\t\tCombine input records=22\n",
      "\t\tCombine output records=22\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=205\n",
      "\t\tInput split bytes=474\n",
      "\t\tMap input records=10\n",
      "\t\tMap output bytes=323\n",
      "\t\tMap output materialized bytes=370\n",
      "\t\tMap output records=22\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1895714816\n",
      "\t\tReduce input groups=22\n",
      "\t\tReduce input records=22\n",
      "\t\tReduce output records=22\n",
      "\t\tReduce shuffle bytes=370\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=44\n",
      "\t\tTotal committed heap usage (bytes)=2263351296\n",
      "\t\tVirtual memory (bytes) snapshot=11411243008\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 2 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob3060717247430032525.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1506640654827_2434\n",
      "  Submitted application application_1506640654827_2434\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1506640654827_2434/\n",
      "  Running job: job_1506640654827_2434\n",
      "  Job job_1506640654827_2434 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1506640654827_2434 completed successfully\n",
      "  Output directory: hdfs:///user/jenncasper/tmp/mrjob/mostFrequentWords.jenncasper.20171011.141345.092184/output\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=452\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=301\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=329\n",
      "\t\tFILE: Number of bytes written=400171\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=840\n",
      "\t\tHDFS: Number of bytes written=301\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=8256000\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=15193600\n",
      "\t\tTotal time spent by all map tasks (ms)=5375\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=16125\n",
      "\t\tTotal time spent by all reduce tasks (ms)=5935\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=29675\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=5375\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=5935\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2630\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=232\n",
      "\t\tInput split bytes=388\n",
      "\t\tMap input records=22\n",
      "\t\tMap output bytes=323\n",
      "\t\tMap output materialized bytes=373\n",
      "\t\tMap output records=22\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1890578432\n",
      "\t\tReduce input groups=22\n",
      "\t\tReduce input records=22\n",
      "\t\tReduce output records=22\n",
      "\t\tReduce shuffle bytes=373\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=44\n",
      "\t\tTotal committed heap usage (bytes)=2209349632\n",
      "\t\tVirtual memory (bytes) snapshot=11412295680\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Streaming final output from hdfs:///user/jenncasper/tmp/mrjob/mostFrequentWords.jenncasper.20171011.141345.092184/output...\n",
      "1099\t\"wales\"\n",
      "1099\t\"christmas\"\n",
      "1099\t\"child's\"\n",
      "604\t\"case\"\n",
      "604\t\"study\"\n",
      "447\t\"female\"\n",
      "239\t\"collection\"\n",
      "123\t\"fairy\"\n",
      "123\t\"tales\"\n",
      "116\t\"forms\"\n",
      "102\t\"government\"\n",
      "92\t\"george\"\n",
      "92\t\"general\"\n",
      "92\t\"biography\"\n",
      "62\t\"city\"\n",
      "62\t\"circumstantial\"\n",
      "62\t\"sea\"\n",
      "62\t\"narrative\"\n",
      "59\t\"religious\"\n",
      "59\t\"establishing\"\n",
      "59\t\"bill\"\n",
      "55\t\"limited\"\n",
      "Removing HDFS temp directory hdfs:///user/jenncasper/tmp/mrjob/mostFrequentWords.jenncasper.20171011.141345.092184...\n",
      "Removing temp directory /tmp/mostFrequentWords.jenncasper.20171011.141345.092184...\n"
     ]
    }
   ],
   "source": [
    "# test mostFrequentWords.py locally on the google sample dropping stopwords\n",
    "!python mostFrequentWords.py -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered-first-10-lines.txt --file english #| sort -k1,1nr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__On the full data set:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `hw541_outputs/mostFrequentWords': No such file or directory\n",
      "No configs found; falling back on auto-configuration\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Creating temp directory /tmp/mostFrequentWords.jenncasper.20171011.141946.761004\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/jenncasper/tmp/mrjob/mostFrequentWords.jenncasper.20171011.141946.761004/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob7683168149773987239.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 190\n",
      "  number of splits:190\n",
      "  Submitting tokens for job: job_1506640654827_2435\n",
      "  Submitted application application_1506640654827_2435\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1506640654827_2435/\n",
      "  Running job: job_1506640654827_2435\n",
      "  Job job_1506640654827_2435 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 1% reduce 0%\n",
      "   map 2% reduce 0%\n",
      "   map 3% reduce 0%\n",
      "   map 5% reduce 0%\n",
      "   map 8% reduce 0%\n",
      "   map 10% reduce 0%\n",
      "   map 12% reduce 0%\n",
      "   map 15% reduce 0%\n",
      "   map 16% reduce 0%\n",
      "   map 18% reduce 0%\n",
      "   map 21% reduce 0%\n",
      "   map 24% reduce 0%\n",
      "   map 28% reduce 0%\n",
      "   map 33% reduce 0%\n",
      "   map 38% reduce 0%\n",
      "   map 41% reduce 0%\n",
      "   map 44% reduce 0%\n",
      "   map 48% reduce 0%\n",
      "   map 53% reduce 0%\n",
      "   map 56% reduce 0%\n",
      "   map 59% reduce 0%\n",
      "   map 61% reduce 0%\n",
      "   map 65% reduce 0%\n",
      "   map 69% reduce 0%\n",
      "   map 73% reduce 0%\n",
      "   map 77% reduce 0%\n",
      "   map 78% reduce 0%\n",
      "   map 81% reduce 0%\n",
      "   map 85% reduce 0%\n",
      "   map 92% reduce 0%\n",
      "   map 97% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 55%\n",
      "   map 100% reduce 67%\n",
      "   map 100% reduce 68%\n",
      "   map 100% reduce 69%\n",
      "   map 100% reduce 70%\n",
      "   map 100% reduce 71%\n",
      "   map 100% reduce 72%\n",
      "   map 100% reduce 73%\n",
      "   map 100% reduce 74%\n",
      "   map 100% reduce 75%\n",
      "   map 100% reduce 76%\n",
      "   map 100% reduce 77%\n",
      "   map 100% reduce 78%\n",
      "   map 100% reduce 79%\n",
      "   map 100% reduce 80%\n",
      "   map 100% reduce 81%\n",
      "   map 100% reduce 82%\n",
      "   map 100% reduce 83%\n",
      "   map 100% reduce 84%\n",
      "   map 100% reduce 85%\n",
      "   map 100% reduce 86%\n",
      "   map 100% reduce 87%\n",
      "   map 100% reduce 88%\n",
      "   map 100% reduce 89%\n",
      "   map 100% reduce 90%\n",
      "   map 100% reduce 91%\n",
      "   map 100% reduce 92%\n",
      "   map 100% reduce 93%\n",
      "   map 100% reduce 94%\n",
      "   map 100% reduce 95%\n",
      "   map 100% reduce 96%\n",
      "   map 100% reduce 97%\n",
      "   map 100% reduce 98%\n",
      "   map 100% reduce 99%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1506640654827_2435 completed successfully\n",
      "  Output directory: hdfs:///user/jenncasper/tmp/mrjob/mostFrequentWords.jenncasper.20171011.141946.761004/step-output/0000\n",
      "Counters: 51\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=2156069116\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=4156343\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=38821342\n",
      "\t\tFILE: Number of bytes written=137729699\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=2156099976\n",
      "\t\tHDFS: Number of bytes written=4156343\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=573\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tKilled map tasks=2\n",
      "\t\tLaunched map tasks=192\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tOther local map tasks=2\n",
      "\t\tRack-local map tasks=190\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=13079855616\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=317785600\n",
      "\t\tTotal time spent by all map tasks (ms)=8515531\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=25546593\n",
      "\t\tTotal time spent by all reduce tasks (ms)=124135\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=620675\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=8515531\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=124135\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2647090\n",
      "\t\tCombine input records=6794902\n",
      "\t\tCombine output records=6794902\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=57285\n",
      "\t\tInput split bytes=30860\n",
      "\t\tMap input records=58682266\n",
      "\t\tMap output bytes=107414348\n",
      "\t\tMap output materialized bytes=73396463\n",
      "\t\tMap output records=6794902\n",
      "\t\tMerged Map outputs=190\n",
      "\t\tPhysical memory (bytes) snapshot=154536525824\n",
      "\t\tReduce input groups=269186\n",
      "\t\tReduce input records=6794902\n",
      "\t\tReduce output records=269186\n",
      "\t\tReduce shuffle bytes=73396463\n",
      "\t\tShuffled Maps =190\n",
      "\t\tSpilled Records=13589804\n",
      "\t\tTotal committed heap usage (bytes)=169106997248\n",
      "\t\tVirtual memory (bytes) snapshot=654864580608\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 2 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob6759194898473863017.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1506640654827_2436\n",
      "  Submitted application application_1506640654827_2436\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1506640654827_2436/\n",
      "  Running job: job_1506640654827_2436\n",
      "  Job job_1506640654827_2436 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 89%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1506640654827_2436 completed successfully\n",
      "  Output directory: hdfs:///user/jenncasper/hw541_outputs/mostFrequentWords\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=4175324\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=4156343\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=2951703\n",
      "\t\tFILE: Number of bytes written=6318309\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=4175712\n",
      "\t\tHDFS: Number of bytes written=4156343\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=18536448\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=35041280\n",
      "\t\tTotal time spent by all map tasks (ms)=12068\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=36204\n",
      "\t\tTotal time spent by all reduce tasks (ms)=13688\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=68440\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=12068\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=13688\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=15290\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=331\n",
      "\t\tInput split bytes=388\n",
      "\t\tMap input records=269186\n",
      "\t\tMap output bytes=4425529\n",
      "\t\tMap output materialized bytes=2967256\n",
      "\t\tMap output records=269186\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1937154048\n",
      "\t\tReduce input groups=269186\n",
      "\t\tReduce input records=269186\n",
      "\t\tReduce output records=269186\n",
      "\t\tReduce shuffle bytes=2967256\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=538372\n",
      "\t\tTotal committed heap usage (bytes)=2285895680\n",
      "\t\tVirtual memory (bytes) snapshot=11411574784\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Removing HDFS temp directory hdfs:///user/jenncasper/tmp/mrjob/mostFrequentWords.jenncasper.20171011.141946.761004...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing temp directory /tmp/mostFrequentWords.jenncasper.20171011.141946.761004...\r\n"
     ]
    }
   ],
   "source": [
    "# mostFrequentWords.py on the full data set\n",
    "!hadoop fs -rm -r hw541_outputs/mostFrequentWords\n",
    "OUTPUT_PATH = os.path.join(OUTPUT_PATH_BASE, 'hw541_outputs/mostFrequentWords')\n",
    "!python mostFrequentWords.py \\\n",
    "    -r hadoop hdfs:///user/winegarj/data/full/ \\\n",
    "    --file english \\\n",
    "    --output-dir={OUTPUT_PATH} \\\n",
    "    --no-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "-rw-r--r--   3 jenncasper users          0 2017-10-11 14:25 /user/jenncasper/hw541_outputs/mostFrequentWords/_SUCCESS\n",
      "-rw-r--r--   3 jenncasper users    4156343 2017-10-11 14:25 /user/jenncasper/hw541_outputs/mostFrequentWords/part-00000\n",
      "Top 10 most frequent words with stopwords dropped:\n",
      "180195771\t\"one\"\n",
      "139313915\t\"would\"\n",
      "126853684\t\"time\"\n",
      "108486904\t\"may\"\n",
      "79528921\t\"part\"\n",
      "78780613\t\"could\"\n",
      "78089800\t\"first\"\n",
      "74978840\t\"made\"\n",
      "72793319\t\"way\"\n",
      "68693179\t\"two\"\n",
      "cat: Unable to write to output stream.\n",
      "cat: Unable to write to output stream.\n"
     ]
    }
   ],
   "source": [
    "# check mostFrequentWords.py output and get the top 10\n",
    "!hadoop fs -ls {OUTPUT_PATH}\n",
    "!printf \"Top 10 most frequent words with stopwords dropped:\\n\"\n",
    "!hadoop fs -cat {OUTPUT_PATH}/* | head -10\n",
    "\n",
    "# write the top 9k most frequent words to a file for use later\n",
    "!hadoop fs -cat {OUTPUT_PATH}/* | head -9000 > mostFrequent_10k\n",
    "\n",
    "# crop the last 1k lines of mostFrequent_10k as basis for vocab to use later\n",
    "!hadoop fs -cat {OUTPUT_PATH}/* | head -10000 | tail -1000 > leastmostFrequent_1k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most frequent words MR stats\n",
    "\n",
    "    \n",
    "__Step 1:__   \n",
    "\n",
    "    CPU time spent (ms)=2647090   \n",
    "    Launched map tasks=192  \n",
    "    Launched reduce tasks=1   \n",
    "\n",
    "__Step 2:__  \n",
    "\n",
    "    CPU time spent (ms)=15290   \n",
    "    Launched map tasks=2\n",
    "    Launched reduce tasks=1  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW5.4.1 - C. 20 Most/Least densely appearing words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mostLeastDenseWords.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mostLeastDenseWords.py\n",
    "#!~/anaconda2/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import division\n",
    "import re\n",
    "import numpy as np\n",
    "import mrjob\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "from collections import defaultdict\n",
    "\n",
    "class mostLeastDenseWords(MRJob):\n",
    "    \n",
    "    # START STUDENT CODE 5.4.1.C\n",
    "    \n",
    "    MRJob.SORT_VALUES = True\n",
    "    \n",
    "    # purpose: we are defining dense as counts per page\n",
    "    def steps(self):\n",
    "        JOBCONF_STEP = {\n",
    "            'mapreduce.job.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "            'mapreduce.partition.keycomparator.options':'-k1,1',\n",
    "        }\n",
    "        JOBCONF_STEP2 = {\n",
    "            'mapreduce.job.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "            'mapreduce.partition.keycomparator.options':'-k1,1nr',\n",
    "        }\n",
    "        \n",
    "        return [\n",
    "            MRStep(jobconf = JOBCONF_STEP,\n",
    "                   mapper_init = self.mapper_init,\n",
    "                   mapper = self.mapper,\n",
    "                   mapper_final = self.mapper_final,\n",
    "                   combiner = self.combiner,\n",
    "                   reducer = self.reducer,\n",
    "            ),\n",
    "            MRStep(jobconf = JOBCONF_STEP2,\n",
    "                   mapper = None,\n",
    "                   reducer = self.reducer_sort,  \n",
    "            ),\n",
    "        ]\n",
    "    \n",
    "    # purpose: define the mapper's dict used to track count and pages\n",
    "    def mapper_init(self):\n",
    "        self.word_counts = defaultdict(int)\n",
    "        self.word_pages = defaultdict(int)\n",
    "    \n",
    "    # purpose: split the line and capture the count and pages for each ngram word\n",
    "    # input: key(None), value(ngram\\tcount\\tpage\\tbook)\n",
    "    # output: nothing; counts and pages are stored in the mapper's internal dicts\n",
    "    def mapper(self, _, line):\n",
    "        ngram, count, page, book = line.lower().strip().split(\"\\t\")\n",
    "        for word in ngram.split(' '):\n",
    "            self.word_counts[word] += int(count)\n",
    "            self.word_pages[word] += int(page)\n",
    "            \n",
    "    # purpose: emit the word counts and pages pairs to the combiner for summing counts and pages for each word\n",
    "    # input: use the mapper's internal dicts\n",
    "    # output: key(word), value(count and pages for the word emitted from the mapper)\n",
    "    def mapper_final(self):\n",
    "        for word, count in self.word_counts.iteritems():\n",
    "            yield word, (count, self.word_pages[word])\n",
    "    \n",
    "    # purpose: sum up the counts and pages for the same words processed by a mapper\n",
    "    # input: key(word), value(count and pages for the word emitted from the mapper)\n",
    "    # output: key(word), value(sum of the word's counts and pages)\n",
    "    def combiner(self, word, counts):\n",
    "        c = [i for i in counts]\n",
    "        count = sum([i[0] for i in c])\n",
    "        pages = sum([i[1] for i in c])\n",
    "        yield word, (count, pages)\n",
    "\n",
    "    # purpose: sum up all of the word counts and pages across the mappers\n",
    "    # input: key(word), value(sum of the word's counts and pages)\n",
    "    # output: key(word), calculated density\n",
    "    def reducer(self, word, counts):\n",
    "        c = [i for i in counts]\n",
    "        count = sum([i[0] for i in c])\n",
    "        pages = sum([i[1] for i in c])\n",
    "        yield (float(count)/pages), word\n",
    "    \n",
    "    # purpose: get the sorted outputs\n",
    "    def reducer_sort(self, density, word):\n",
    "        for w in word:\n",
    "            yield density, w  \n",
    "    \n",
    "    # END STUDENT CODE 5.4.1.C\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    mostLeastDenseWords.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__On the test data set:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "ignoring partitioner keyword arg (requires real Hadoop): 'org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner'\n",
      "Creating temp directory /tmp/mostLeastDenseWords.jenncasper.20171011.103123.743509\n",
      "Running step 1 of 2...\n",
      "Running step 2 of 2...\n",
      "Streaming final output from /tmp/mostLeastDenseWords.jenncasper.20171011.103123.743509/output...\n",
      "Removing temp directory /tmp/mostLeastDenseWords.jenncasper.20171011.103123.743509...\n",
      "1.1262135922\t\"forms\"\n",
      "1.0863636364\t\"collection\"\n",
      "1.0512820513\t\"fairy\"\n",
      "1.0512820513\t\"tales\"\n",
      "1.0358152686\t\"child's\"\n",
      "1.0358152686\t\"christmas\"\n",
      "1.0358152686\t\"wales\"\n",
      "1.0348004094\t\"of\"\n",
      "1.0333333333\t\"by\"\n",
      "1.0333333333\t\"city\"\n",
      "1.0333333333\t\"sea\"\n",
      "1.0326741187\t\"in\"\n",
      "1.0282931354\t\"a\"\n",
      "1.0222222222\t\"biography\"\n",
      "1.0222222222\t\"general\"\n",
      "1.0222222222\t\"george\"\n",
      "1.0163934426\t\"the\"\n",
      "1.0\t\"bill\"\n",
      "1.0\t\"case\"\n",
      "1.0\t\"circumstantial\"\n",
      "1.0\t\"establishing\"\n",
      "1.0\t\"female\"\n",
      "1.0\t\"for\"\n",
      "1.0\t\"government\"\n",
      "1.0\t\"limited\"\n",
      "1.0\t\"narrative\"\n",
      "1.0\t\"religious\"\n",
      "1.0\t\"study\"\n"
     ]
    }
   ],
   "source": [
    "# test mostLeastDenseWords.py locally on the google sample\n",
    "!python mostLeastDenseWords.py -r local googlebooks-eng-all-5gram-20090715-0-filtered-first-10-lines.txt | sort -k1,1nr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__On the full data set:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `hw541_outputs/mostLeastDenseWords': No such file or directory\n",
      "No configs found; falling back on auto-configuration\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Creating temp directory /tmp/mostLeastDenseWords.jenncasper.20171011.101905.692471\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/jenncasper/tmp/mrjob/mostLeastDenseWords.jenncasper.20171011.101905.692471/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob4856495035958724215.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 190\n",
      "  number of splits:190\n",
      "  Submitting tokens for job: job_1506640654827_2409\n",
      "  Submitted application application_1506640654827_2409\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1506640654827_2409/\n",
      "  Running job: job_1506640654827_2409\n",
      "  Job job_1506640654827_2409 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 1% reduce 0%\n",
      "   map 3% reduce 0%\n",
      "   map 4% reduce 0%\n",
      "   map 8% reduce 0%\n",
      "   map 10% reduce 0%\n",
      "   map 11% reduce 0%\n",
      "   map 14% reduce 0%\n",
      "   map 15% reduce 0%\n",
      "   map 17% reduce 0%\n",
      "   map 18% reduce 0%\n",
      "   map 19% reduce 0%\n",
      "   map 21% reduce 0%\n",
      "   map 23% reduce 0%\n",
      "   map 25% reduce 0%\n",
      "   map 29% reduce 0%\n",
      "   map 33% reduce 0%\n",
      "   map 38% reduce 0%\n",
      "   map 41% reduce 0%\n",
      "   map 43% reduce 0%\n",
      "   map 45% reduce 0%\n",
      "   map 48% reduce 0%\n",
      "   map 50% reduce 0%\n",
      "   map 51% reduce 0%\n",
      "   map 53% reduce 0%\n",
      "   map 55% reduce 0%\n",
      "   map 57% reduce 0%\n",
      "   map 58% reduce 0%\n",
      "   map 60% reduce 0%\n",
      "   map 62% reduce 0%\n",
      "   map 64% reduce 0%\n",
      "   map 66% reduce 0%\n",
      "   map 69% reduce 0%\n",
      "   map 73% reduce 0%\n",
      "   map 74% reduce 0%\n",
      "   map 77% reduce 0%\n",
      "   map 79% reduce 0%\n",
      "   map 80% reduce 0%\n",
      "   map 82% reduce 0%\n",
      "   map 85% reduce 0%\n",
      "   map 87% reduce 0%\n",
      "   map 90% reduce 0%\n",
      "   map 96% reduce 0%\n",
      "   map 97% reduce 0%\n",
      "   map 99% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 53%\n",
      "   map 100% reduce 65%\n",
      "   map 100% reduce 67%\n",
      "   map 100% reduce 68%\n",
      "   map 100% reduce 69%\n",
      "   map 100% reduce 70%\n",
      "   map 100% reduce 71%\n",
      "   map 100% reduce 72%\n",
      "   map 100% reduce 73%\n",
      "   map 100% reduce 74%\n",
      "   map 100% reduce 75%\n",
      "   map 100% reduce 76%\n",
      "   map 100% reduce 77%\n",
      "   map 100% reduce 78%\n",
      "   map 100% reduce 79%\n",
      "   map 100% reduce 80%\n",
      "   map 100% reduce 81%\n",
      "   map 100% reduce 82%\n",
      "   map 100% reduce 83%\n",
      "   map 100% reduce 84%\n",
      "   map 100% reduce 85%\n",
      "   map 100% reduce 86%\n",
      "   map 100% reduce 87%\n",
      "   map 100% reduce 88%\n",
      "   map 100% reduce 89%\n",
      "   map 100% reduce 90%\n",
      "   map 100% reduce 91%\n",
      "   map 100% reduce 92%\n",
      "   map 100% reduce 93%\n",
      "   map 100% reduce 94%\n",
      "   map 100% reduce 95%\n",
      "   map 100% reduce 96%\n",
      "   map 100% reduce 97%\n",
      "   map 100% reduce 98%\n",
      "   map 100% reduce 99%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1506640654827_2409 completed successfully\n",
      "  Output directory: hdfs:///user/jenncasper/tmp/mrjob/mostLeastDenseWords.jenncasper.20171011.101905.692471/step-output/0000\n",
      "Counters: 51\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=2156069116\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=6135569\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=60765148\n",
      "\t\tFILE: Number of bytes written=185029509\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=2156099976\n",
      "\t\tHDFS: Number of bytes written=6135569\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=573\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tKilled map tasks=1\n",
      "\t\tLaunched map tasks=191\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tOther local map tasks=2\n",
      "\t\tRack-local map tasks=189\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=13842107904\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=646673920\n",
      "\t\tTotal time spent by all map tasks (ms)=9011789\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=27035367\n",
      "\t\tTotal time spent by all reduce tasks (ms)=252607\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=1263035\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=9011789\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=252607\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=3107220\n",
      "\t\tCombine input records=6822745\n",
      "\t\tCombine output records=6822745\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=58661\n",
      "\t\tInput split bytes=30860\n",
      "\t\tMap input records=58682266\n",
      "\t\tMap output bytes=155278077\n",
      "\t\tMap output materialized bytes=98830204\n",
      "\t\tMap output records=6822745\n",
      "\t\tMerged Map outputs=190\n",
      "\t\tPhysical memory (bytes) snapshot=154251608064\n",
      "\t\tReduce input groups=269339\n",
      "\t\tReduce input records=6822745\n",
      "\t\tReduce output records=269339\n",
      "\t\tReduce shuffle bytes=98830204\n",
      "\t\tShuffled Maps =190\n",
      "\t\tSpilled Records=13645490\n",
      "\t\tTotal committed heap usage (bytes)=168907243520\n",
      "\t\tVirtual memory (bytes) snapshot=654751318016\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 2 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob2458037316551899315.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1506640654827_2410\n",
      "  Submitted application application_1506640654827_2410\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1506640654827_2410/\n",
      "  Running job: job_1506640654827_2410\n",
      "  Job job_1506640654827_2410 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 87%\n",
      "   map 100% reduce 97%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1506640654827_2410 completed successfully\n",
      "  Output directory: hdfs:///user/jenncasper/hw541_outputs/mostLeastDenseWords\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=6213513\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=6135569\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=3506596\n",
      "\t\tFILE: Number of bytes written=7480270\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=6213905\n",
      "\t\tHDFS: Number of bytes written=6135569\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=18338304\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=33794560\n",
      "\t\tTotal time spent by all map tasks (ms)=11939\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=35817\n",
      "\t\tTotal time spent by all reduce tasks (ms)=13201\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=66005\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=11939\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=13201\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=18150\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=244\n",
      "\t\tInput split bytes=392\n",
      "\t\tMap input records=269339\n",
      "\t\tMap output bytes=6404908\n",
      "\t\tMap output materialized bytes=3575539\n",
      "\t\tMap output records=269339\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1929838592\n",
      "\t\tReduce input groups=269339\n",
      "\t\tReduce input records=269339\n",
      "\t\tReduce output records=269339\n",
      "\t\tReduce shuffle bytes=3575539\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=538678\n",
      "\t\tTotal committed heap usage (bytes)=2196242432\n",
      "\t\tVirtual memory (bytes) snapshot=11409649664\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Removing HDFS temp directory hdfs:///user/jenncasper/tmp/mrjob/mostLeastDenseWords.jenncasper.20171011.101905.692471...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing temp directory /tmp/mostLeastDenseWords.jenncasper.20171011.101905.692471...\r\n"
     ]
    }
   ],
   "source": [
    "# mostLeastDenseWords.py on the full data set\n",
    "!hadoop fs -rm -r hw541_outputs/mostLeastDenseWords\n",
    "OUTPUT_PATH = os.path.join(OUTPUT_PATH_BASE, 'hw541_outputs/mostLeastDenseWords')\n",
    "!python mostLeastDenseWords.py \\\n",
    "    -r hadoop hdfs:///user/winegarj/data/full/ \\\n",
    "    --output-dir={OUTPUT_PATH} \\\n",
    "    --no-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "-rw-r--r--   3 jenncasper users          0 2017-10-11 10:25 hdfs:/user/jenncasper/hw541_outputs/mostLeastDenseWords/_SUCCESS\n",
      "-rw-r--r--   3 jenncasper users    6135569 2017-10-11 10:25 hdfs:/user/jenncasper/hw541_outputs/mostLeastDenseWords/part-00000\n",
      "Most frequent: \n",
      "11.557291666666666\t\"xxxx\"\n",
      "cat: Unable to write to output stream.\n",
      "Least frequent: \n",
      "1.0\t\"lawton's\"\n"
     ]
    }
   ],
   "source": [
    "# check mostFrequentWords.py output and get the top 10\n",
    "!hadoop fs -ls {OUTPUT_PATH}\n",
    "!printf \"Most frequent: \\n\"\n",
    "!hadoop fs -cat {OUTPUT_PATH}/* | head -1\n",
    "!printf \"Least frequent: \\n\" \n",
    "!hadoop fs -cat {OUTPUT_PATH}/* | tail -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word density MR stats\n",
    "    \n",
    "__Step 1:__ \n",
    "\n",
    "    CPU time spent (ms)=3107220  \n",
    "    Launched map tasks=191  \n",
    "    Launched reduce tasks=1     \n",
    "\n",
    "__Step 2:__  \n",
    "\n",
    "    CPU time spent (ms)=18150    \n",
    "    Launched map tasks=2   \n",
    "    Launched reduce tasks=1   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW5.4.1 - D. Distribution of 5-gram sizes (character length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting distribution.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile distribution.py\n",
    "#!~/anaconda2/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import mrjob\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "\n",
    "class distribution(MRJob):\n",
    "    \n",
    "    # START STUDENT CODE 5.4.1.D\n",
    "    \n",
    "    MRJob.SORT_VALUES = True\n",
    "    \n",
    "    # purpose: need a mapper, combiner, and reducer in this case\n",
    "    def steps(self):\n",
    "        JOBCONF_STEP = {\n",
    "            'mapreduce.job.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "            'mapreduce.partition.keycomparator.options':'-k1,1n',\n",
    "        }\n",
    "        return [\n",
    "            MRStep(jobconf = JOBCONF_STEP,\n",
    "                   mapper = self.mapper,\n",
    "                   combiner = self.combiner,\n",
    "                   reducer = self.reducer,\n",
    "            )\n",
    "        ]\n",
    "    \n",
    "    # purpose: emit ngram length counts\n",
    "    # input: key(None), value(ngram\\tcount\\tpage\\tbook)\n",
    "    # output: key(ngram length), value(1)\n",
    "    def mapper(self, _, line):\n",
    "        ngram, count, page, book = line.lower().strip().split(\"\\t\")\n",
    "        yield len(ngram), 1\n",
    "    \n",
    "    # purpose: sum the ngram length counts for mappers\n",
    "    # input: key(ngram length), value(1)\n",
    "    # output: key(ngram length), value(count)\n",
    "    def combiner(self, length, count):\n",
    "        yield int(length), sum(count)\n",
    "    \n",
    "    # purpose: sum the ngram length counts across mappers\n",
    "    def reducer(self, length, count):\n",
    "        yield int(length), sum(count)\n",
    "    \n",
    "    # END STUDENT CODE 5.4.1.D\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    distribution.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__On the test data set:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "ignoring partitioner keyword arg (requires real Hadoop): 'org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner'\n",
      "Creating temp directory /tmp/distribution.jenncasper.20171011.104329.451361\n",
      "Running step 1 of 1...\n",
      "Streaming final output from /tmp/distribution.jenncasper.20171011.104329.451361/output...\n",
      "17\t1\n",
      "22\t1\n",
      "23\t1\n",
      "24\t1\n",
      "26\t1\n",
      "27\t1\n",
      "28\t1\n",
      "29\t1\n",
      "33\t2\n",
      "Removing temp directory /tmp/distribution.jenncasper.20171011.104329.451361...\n"
     ]
    }
   ],
   "source": [
    "# test distribution.py locally on the google sample\n",
    "!python distribution.py -r local googlebooks-eng-all-5gram-20090715-0-filtered-first-10-lines.txt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__On the full data set:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `hw541_outputs/distribution': No such file or directory\n",
      "No configs found; falling back on auto-configuration\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Creating temp directory /tmp/distribution.jenncasper.20171011.104508.107314\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/jenncasper/tmp/mrjob/distribution.jenncasper.20171011.104508.107314/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 1...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob2460263134155880238.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 190\n",
      "  number of splits:190\n",
      "  Submitting tokens for job: job_1506640654827_2415\n",
      "  Submitted application application_1506640654827_2415\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1506640654827_2415/\n",
      "  Running job: job_1506640654827_2415\n",
      "  Job job_1506640654827_2415 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 1% reduce 0%\n",
      "   map 3% reduce 0%\n",
      "   map 4% reduce 0%\n",
      "   map 6% reduce 0%\n",
      "   map 7% reduce 0%\n",
      "   map 8% reduce 0%\n",
      "   map 9% reduce 0%\n",
      "   map 10% reduce 0%\n",
      "   map 12% reduce 0%\n",
      "   map 13% reduce 0%\n",
      "   map 14% reduce 0%\n",
      "   map 19% reduce 0%\n",
      "   map 22% reduce 0%\n",
      "   map 23% reduce 0%\n",
      "   map 26% reduce 0%\n",
      "   map 29% reduce 0%\n",
      "   map 31% reduce 0%\n",
      "   map 33% reduce 0%\n",
      "   map 37% reduce 0%\n",
      "   map 38% reduce 0%\n",
      "   map 41% reduce 0%\n",
      "   map 44% reduce 0%\n",
      "   map 46% reduce 0%\n",
      "   map 48% reduce 0%\n",
      "   map 51% reduce 0%\n",
      "   map 53% reduce 0%\n",
      "   map 55% reduce 0%\n",
      "   map 57% reduce 0%\n",
      "   map 60% reduce 0%\n",
      "   map 63% reduce 0%\n",
      "   map 64% reduce 0%\n",
      "   map 65% reduce 0%\n",
      "   map 67% reduce 0%\n",
      "   map 68% reduce 0%\n",
      "   map 69% reduce 0%\n",
      "   map 70% reduce 0%\n",
      "   map 71% reduce 0%\n",
      "   map 72% reduce 0%\n",
      "   map 74% reduce 0%\n",
      "   map 75% reduce 0%\n",
      "   map 76% reduce 0%\n",
      "   map 79% reduce 0%\n",
      "   map 83% reduce 0%\n",
      "   map 88% reduce 0%\n",
      "   map 91% reduce 0%\n",
      "   map 95% reduce 0%\n",
      "   map 97% reduce 0%\n",
      "   map 98% reduce 0%\n",
      "   map 99% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1506640654827_2415 completed successfully\n",
      "  Output directory: hdfs:///user/jenncasper/hw541_outputs/distribution\n",
      "Counters: 51\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=2156069116\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=624\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=28984\n",
      "\t\tFILE: Number of bytes written=25512317\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=2156099976\n",
      "\t\tHDFS: Number of bytes written=624\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=573\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tKilled map tasks=1\n",
      "\t\tLaunched map tasks=191\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tOther local map tasks=2\n",
      "\t\tRack-local map tasks=189\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=16506745344\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=8888320\n",
      "\t\tTotal time spent by all map tasks (ms)=10746579\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=32239737\n",
      "\t\tTotal time spent by all reduce tasks (ms)=3472\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=17360\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=10746579\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=3472\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=3687080\n",
      "\t\tCombine input records=58682266\n",
      "\t\tCombine output records=9172\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=68951\n",
      "\t\tInput split bytes=30860\n",
      "\t\tMap input records=58682266\n",
      "\t\tMap output bytes=352093476\n",
      "\t\tMap output materialized bytes=78017\n",
      "\t\tMap output records=58682266\n",
      "\t\tMerged Map outputs=190\n",
      "\t\tPhysical memory (bytes) snapshot=153184583680\n",
      "\t\tReduce input groups=80\n",
      "\t\tReduce input records=9172\n",
      "\t\tReduce output records=80\n",
      "\t\tReduce shuffle bytes=78017\n",
      "\t\tShuffled Maps =190\n",
      "\t\tSpilled Records=18344\n",
      "\t\tTotal committed heap usage (bytes)=168888893440\n",
      "\t\tVirtual memory (bytes) snapshot=654553010176\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Removing HDFS temp directory hdfs:///user/jenncasper/tmp/mrjob/distribution.jenncasper.20171011.104508.107314...\n",
      "Removing temp directory /tmp/distribution.jenncasper.20171011.104508.107314...\n"
     ]
    }
   ],
   "source": [
    "# distribution.py on the full data set\n",
    "!hadoop fs -rm -r hw541_outputs/distribution\n",
    "OUTPUT_PATH = os.path.join(OUTPUT_PATH_BASE, 'hw541_outputs/distribution')\n",
    "!python distribution.py \\\n",
    "    -r hadoop hdfs:///user/winegarj/data/full/ \\\n",
    "    --output-dir={OUTPUT_PATH} \\\n",
    "    --no-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\r\n",
      "-rw-r--r--   3 jenncasper users          0 2017-10-11 10:47 /user/jenncasper/hw541_outputs/distribution/_SUCCESS\r\n",
      "-rw-r--r--   3 jenncasper users        624 2017-10-11 10:47 /user/jenncasper/hw541_outputs/distribution/part-00000\r\n"
     ]
    }
   ],
   "source": [
    "# check distribution.py output and get the top 10\n",
    "!hadoop fs -ls {OUTPUT_PATH}\n",
    "!hadoop fs -cat {OUTPUT_PATH}/* > distributions.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution MRJob stats\n",
    "\n",
    "__Step 1:__ \n",
    "\n",
    "    CPU time spent (ms)=3687080  \n",
    "    Launched map tasks=191  \n",
    "    Launched reduce tasks=1   \n",
    "    \n",
    "__Step 2:__  \n",
    "\n",
    "    N/A  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/oAAAG1CAYAAABJd48xAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRoqTslCwAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f15ac19b8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "\n",
    "results_A = []\n",
    "for line in open(\"distributions.txt\").readlines():\n",
    "    line = line.strip()\n",
    "    X,Y = line.split(\"\\t\")\n",
    "    results_A.append([int(X),int(Y)])\n",
    "\n",
    "items = (np.array(results_A)[::-1].T)\n",
    "fig = pl.figure(figsize=(17,7))\n",
    "ax = pl.subplot(111)\n",
    "width=0.8\n",
    "ax.bar(range(len(items[0])), items[1], width=width)\n",
    "ax.set_xticks(np.arange(len(items[0])) + width/2)\n",
    "ax.set_xticklabels(items[0], rotation=90)\n",
    "\n",
    "\n",
    "\n",
    "pl.title(\"Distributions of 5 Gram lengths\")\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  HW5.4.2 <a name=\"5.4.2\"></a>OPTIONAL Question: log-log plots (PHASE 2)\n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "Plot the log-log plot of the frequency distributuion of unigrams. Does it follow power law distribution?\n",
    "\n",
    "For more background see:\n",
    "- https://en.wikipedia.org/wiki/Log%E2%80%93log_plot\n",
    "- https://en.wikipedia.org/wiki/Power_law"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  HW5.5  <a name=\"5.5\"></a> Synonym detection over 2Gig of Data with extra Preprocessing steps (HW5.3 plus some preprocessing)   (Phase 2) (~60 hrs)\n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "For the remainder of this assignment please feel free to eliminate stop words from your analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">There is also a corpus of stopwords, that is, high-frequency words like \"the\", \"to\" and \"also\" that we sometimes want to filter out of a document before further processing. Stopwords usually have little lexical content, and their presence in a text fails to distinguish it from other texts. Python's nltk comes with a prebuilt list of stopwords (see below). Using this stopword list filter out these tokens from your analysis and rerun the experiments in 5.5 and disucuss the results of using a stopword list and without using a stopword list.\n",
    "\n",
    "> from nltk.corpus import stopwords\n",
    " stopwords.words('english')\n",
    "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours',\n",
    "'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers',\n",
    "'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves',\n",
    "'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are',\n",
    "'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does',\n",
    "'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until',\n",
    "'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into',\n",
    "'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down',\n",
    "'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here',\n",
    "'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\n",
    "'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so',\n",
    "'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2: A large subset of the Google n-grams dataset as was described above\n",
    "\n",
    "For each HW 5.4 -5.5.1 Please unit test and system test your code with respect \n",
    "to SYSTEMS TEST DATASET and show the results. \n",
    "Please compute the expected answer by hand and show your hand calculations for the \n",
    "SYSTEMS TEST DATASET. Then show the results you get with your system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the assignment we will focus on developing methods for detecting synonyms, using the Google 5-grams dataset. At a high level:\n",
    "\n",
    "\n",
    "1. remove stopwords\n",
    "2. get 10,0000 most frequent\n",
    "3. get 1000 (9001-10000) features\n",
    "3. build stripes\n",
    "\n",
    "To accomplish this you must script two main tasks using MRJob:\n",
    "\n",
    "\n",
    "__TASK (1)__ Build stripes for the most frequent 10,000 words using cooccurence information based on\n",
    "the words ranked from 9001,-10,000 as a basis/vocabulary (drop stopword-like terms),\n",
    "and output to a file in your bucket on s3 (bigram analysis, though the words are non-contiguous).\n",
    "\n",
    "\n",
    "__TASK (2)__ Using two (symmetric) comparison methods of your choice \n",
    "(e.g., correlations, distances, similarities), pairwise compare \n",
    "all stripes (vectors), and output to a file in your bucket on s3.\n",
    "\n",
    "#### Design notes for TASK (1)\n",
    "For this task you will be able to modify the pattern we used in HW 3.2\n",
    "(feel free to use the solution as reference). To total the word counts \n",
    "across the 5-grams, output the support from the mappers using the total \n",
    "order inversion pattern:\n",
    "\n",
    "<*word,count>\n",
    "\n",
    "to ensure that the support arrives before the cooccurrences.\n",
    "\n",
    "In addition to ensuring the determination of the total word counts,\n",
    "the mapper must also output co-occurrence counts for the pairs of\n",
    "words inside of each 5-gram. Treat these words as a basket,\n",
    "as we have in HW 3, but count all stripes or pairs in both orders,\n",
    "i.e., count both orderings: (word1,word2), and (word2,word1), to preserve\n",
    "symmetry in our output for TASK (2).\n",
    "\n",
    "#### Design notes for _TASK (2)_\n",
    "For this task you will have to determine a method of comparison.\n",
    "Here are a few that you might consider:\n",
    "\n",
    "- Jaccard\n",
    "- Cosine similarity\n",
    "- Spearman correlation\n",
    "- Euclidean distance\n",
    "- Taxicab (Manhattan) distance\n",
    "- Shortest path graph distance (a graph, because our data is symmetric!)\n",
    "- Pearson correlation\n",
    "- Kendall correlation\n",
    "\n",
    "However, be cautioned that some comparison methods are more difficult to\n",
    "parallelize than others, and do not perform more associations than is necessary, \n",
    "since your choice of association will be symmetric.\n",
    "\n",
    "Please use the inverted index (discussed in live session #5) based pattern to compute the pairwise (term-by-term) similarity matrix. \n",
    "\n",
    "Please report the size of the cluster used and the amount of time it takes to run for the index construction task and for the synonym calculation task. How many pairs need to be processed (HINT: use the posting list length to calculate directly)? Report your  Cluster configuration!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example MR stats: (report times!)\n",
    "    took ~11 minutes on 5 m3.xlarge nodes\n",
    "    Data-local map tasks=188\n",
    "\tLaunched map tasks=190\n",
    "\tLaunched reduce tasks=15\n",
    "\tOther local map tasks=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# START STUDENT CODE 5.5\n",
    "# ADD OR REMOVE CELLS AS NEEDED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting buildStripes10k.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile buildStripes10k.py\n",
    "#!~/anaconda2/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import division\n",
    "import re\n",
    "import mrjob\n",
    "import json\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import sys, itertools\n",
    "from collections import defaultdict\n",
    "\n",
    "class MRbuildStripes10k(MRJob):\n",
    "  \n",
    "    MRJob.SORT_VALUES = True\n",
    "    \n",
    "    # purpose: produce stripes for the most frequent words only - use a combiner to reduce traffic   \n",
    "    def steps(self):\n",
    "        JOBCONF_STEP = {\n",
    "            'mapreduce.job.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "            'mapreduce.partition.keycomparator.options':'-k1,1',\n",
    "            'mapreduce.tasktracker.map.tasks.maximum' : 40,  \n",
    "            'mapreduce.tasktracker.reduce.tasks.maximum' : 40,\n",
    "        }\n",
    "        return [\n",
    "            MRStep(jobconf = JOBCONF_STEP,\n",
    "                   mapper_init = self.mapper_init,\n",
    "                   mapper = self.mapper,\n",
    "                   combiner = self.combiner,\n",
    "                   reducer = self.reducer,\n",
    "            )\n",
    "        ]\n",
    "    \n",
    "    def mapper_init(self):\n",
    "        # get the list of keeper words from the previously produced mostFrequent_10k\n",
    "        self.keeper_words = [kw.split('\\t')[1].strip('\"') for kw in open('mostFrequent_10k').read().strip().split('\\n')]\n",
    "        # get the list of keeper words from the previously produced mostFrequent_10k\n",
    "        self.vocab_words = [kw.split('\\t')[1].strip('\"') for kw in open('leastmostFrequent_1k').read().strip().split('\\n')]\n",
    "        \n",
    "    # purpose: split out the word pair counts for the ngrams\n",
    "    # input: line from ngram input file - ngram \\t count \\t page count \\t book count\n",
    "    # output: key(word in ngram), value(dict of remaining ngram words with counts)\n",
    "    def mapper(self, _, line):\n",
    "        line = line.strip().split('\\t')\n",
    "        # capture the n-gram words\n",
    "        words = line[0].lower().split()\n",
    "        # only keep the words that are in the keeper_words list\n",
    "        kwords = [w for w in words if w in self.keeper_words]\n",
    "        # capture the count, pages_count, books_count values; only keep the count for use\n",
    "        #count = int(line[1:][0])\n",
    "        # use a count of 1 for capturing the instance\n",
    "        count = 1\n",
    "        # handle any ngrams with duplicate words\n",
    "        total_inst = defaultdict(int)\n",
    "        for w in kwords:\n",
    "            total_inst[w] += 1\n",
    "        # init the dictionary for emitting\n",
    "        H = {}\n",
    "        \n",
    "        # there has got to be a quicker/better way to do this\n",
    "        for w1, w2 in itertools.combinations(sorted(set(kwords)), 2):\n",
    "            # check the first in the pair and only keep the count\n",
    "            if (w1 not in self.vocab_words) and (w2 in self.vocab_words):\n",
    "                if w1 not in H.keys():\n",
    "                    H[w1] = {}\n",
    "                    H[w1][w2] = total_inst[w2] * count\n",
    "                elif w2 not in H[w1]:\n",
    "                    H[w1][w2] = total_inst[w2] * count\n",
    "                else:\n",
    "                    H[w1][w2] += (total_inst[w2] * count)\n",
    "                \n",
    "            # check the reverse pair to capture the symmetry relationship\n",
    "            if (w2 not in self.vocab_words) and (w1 in self.vocab_words):\n",
    "                if w2 not in H.keys():\n",
    "                    H[w2] = {}\n",
    "                    H[w2][w1] = total_inst[w2] * count\n",
    "                elif w1 not in H[w2]:\n",
    "                    H[w2][w1] = total_inst[w2] * count\n",
    "                else:\n",
    "                    H[w2][w1] += (total_inst[w2] * count)\n",
    " \n",
    "        for key in H.keys():\n",
    "            yield key, (H[key])\n",
    "\n",
    "    # purpose: combine the sorted-by-key mapper outputs into stripes for each mapper\n",
    "    # input: key(word in ngram), value(dict of remaining ngram words with counts)\n",
    "    # output: key(word in ngram), value(dict of remaining ngram words with total counts)\n",
    "    def combiner(self, key, value):\n",
    "        d = defaultdict(int)\n",
    "        for item in value:\n",
    "            for k, v in item.iteritems():\n",
    "                d[k] += int(v)\n",
    "        yield key, dict(d)\n",
    "    \n",
    "    # purpose: combine the stripes across mappers\n",
    "    # input: key(word in ngram), value(dict of remaining ngram words with total counts)\n",
    "    # output: key(word in ngram), value(dict of remaining ngram words with total counts)\n",
    "    def reducer(self, key, value):\n",
    "        d = defaultdict(int)\n",
    "        for item in value:\n",
    "            for k, v in item.iteritems():\n",
    "                d[k] += int(v)\n",
    "        yield key, dict(d)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRbuildStripes10k.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "ignoring partitioner keyword arg (requires real Hadoop): 'org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner'\n",
      "Creating temp directory /tmp/buildStripes10k.jenncasper.20171011.190648.400501\n",
      "Running step 1 of 1...\n",
      "Streaming final output from /tmp/buildStripes10k.jenncasper.20171011.190648.400501/output...\n",
      "Removing temp directory /tmp/buildStripes10k.jenncasper.20171011.190648.400501...\n"
     ]
    }
   ],
   "source": [
    "# check for functionality by running local\n",
    "!python buildStripes10k.py -r local googlebooks-eng-all-5gram-20090715-0-filtered-first-10-lines.txt --file mostFrequent_10k  --file leastmostFrequent_1k > systems_test_stripes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/10/11 18:46:01 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 5760 minutes, Emptier interval = 360 minutes.\n",
      "Moved: 'hdfs://nn-ia.s3s.altiscale.com:8020/user/jenncasper/hw550_outputs/systems_test_stripes' to trash at: hdfs://nn-ia.s3s.altiscale.com:8020/user/jenncasper/.Trash/Current\n",
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /tmp/buildStripes10k.jenncasper.20171011.184603.296590\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/jenncasper/tmp/mrjob/buildStripes10k.jenncasper.20171011.184603.296590/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 1...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob2183168774894306441.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1506640654827_2573\n",
      "  Submitted application application_1506640654827_2573\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1506640654827_2573/\n",
      "  Running job: job_1506640654827_2573\n",
      "  Job job_1506640654827_2573 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1506640654827_2573 completed successfully\n",
      "  Output directory: hdfs:///user/jenncasper/hw550_outputs/systems_test_stripes\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=563\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=786\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=486\n",
      "\t\tFILE: Number of bytes written=403412\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=1033\n",
      "\t\tHDFS: Number of bytes written=786\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=9523200\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=14082560\n",
      "\t\tTotal time spent by all map tasks (ms)=6200\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=18600\n",
      "\t\tTotal time spent by all reduce tasks (ms)=5501\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=27505\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=6200\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=5501\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2630\n",
      "\t\tCombine input records=25\n",
      "\t\tCombine output records=20\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=207\n",
      "\t\tInput split bytes=470\n",
      "\t\tMap input records=10\n",
      "\t\tMap output bytes=905\n",
      "\t\tMap output materialized bytes=501\n",
      "\t\tMap output records=25\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1900781568\n",
      "\t\tReduce input groups=20\n",
      "\t\tReduce input records=20\n",
      "\t\tReduce output records=20\n",
      "\t\tReduce shuffle bytes=501\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=40\n",
      "\t\tTotal committed heap usage (bytes)=2197291008\n",
      "\t\tVirtual memory (bytes) snapshot=11406159872\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Removing HDFS temp directory hdfs:///user/jenncasper/tmp/mrjob/buildStripes10k.jenncasper.20171011.184603.296590...\n",
      "Removing temp directory /tmp/buildStripes10k.jenncasper.20171011.184603.296590...\n"
     ]
    }
   ],
   "source": [
    "# check that the test works for hadoop\n",
    "!hadoop fs -rm -r hw550_outputs/systems_test_stripes\n",
    "OUTPUT_PATH = os.path.join(OUTPUT_PATH_BASE,'hw550_outputs/systems_test_stripes')\n",
    "!python buildStripes10k.py \\\n",
    "    -r hadoop googlebooks-eng-all-5gram-20090715-0-filtered-first-10-lines.txt \\\n",
    "    --file mostFrequent_10k \\\n",
    "    --file leastmostFrequent_1k \\\n",
    "    --output-dir={OUTPUT_PATH} \\\n",
    "    --no-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8997\r\n"
     ]
    }
   ],
   "source": [
    "#!hadoop fs -cat /user/jenncasper/hw550_outputs/stripes_10k/* | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "-rw-r--r--   3 jenncasper users          0 2017-10-11 18:46 /user/jenncasper/hw550_outputs/systems_test_stripes/_SUCCESS\n",
      "-rw-r--r--   3 jenncasper users        786 2017-10-11 18:46 /user/jenncasper/hw550_outputs/systems_test_stripes/part-00000\n",
      "\"bill\"\t{\"religious\": 1, \"establishing\": 1}\n",
      "\"biography\"\t{\"george\": 1, \"general\": 1}\n",
      "\"case\"\t{\"limited\": 1, \"study\": 3, \"female\": 1, \"government\": 1}\n",
      "\"child's\"\t{\"wales\": 1, \"christmas\": 1}\n",
      "\"christmas\"\t{\"wales\": 1, \"child's\": 1}\n",
      "\"city\"\t{\"sea\": 1}\n",
      "\"collection\"\t{\"forms\": 1, \"fairy\": 1, \"tales\": 1}\n",
      "\"establishing\"\t{\"bill\": 1, \"religious\": 1}\n",
      "\"fairy\"\t{\"tales\": 1, \"collection\": 1}\n",
      "\"female\"\t{\"case\": 1, \"study\": 1}\n",
      "\"forms\"\t{\"collection\": 1}\n",
      "\"general\"\t{\"george\": 1, \"biography\": 1}\n",
      "\"george\"\t{\"biography\": 1, \"general\": 1}\n",
      "\"government\"\t{\"case\": 1, \"study\": 1}\n",
      "\"limited\"\t{\"case\": 1, \"study\": 1}\n",
      "\"religious\"\t{\"bill\": 1, \"establishing\": 1}\n",
      "\"sea\"\t{\"city\": 1}\n",
      "\"study\"\t{\"case\": 3, \"limited\": 1, \"female\": 1, \"government\": 1}\n",
      "\"tales\"\t{\"fairy\": 1, \"collection\": 1}\n",
      "\"wales\"\t{\"christmas\": 1, \"child's\": 1}\n"
     ]
    }
   ],
   "source": [
    "# check buildStripes10k.py test output\n",
    "!hadoop fs -ls {OUTPUT_PATH}\n",
    "!hadoop fs -cat {OUTPUT_PATH}/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/10/11 18:18:44 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 5760 minutes, Emptier interval = 360 minutes.\n",
      "Moved: 'hdfs://nn-ia.s3s.altiscale.com:8020/user/jenncasper/hw550_outputs/stripes_10k' to trash at: hdfs://nn-ia.s3s.altiscale.com:8020/user/jenncasper/.Trash/Current\n",
      "No configs found; falling back on auto-configuration\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Creating temp directory /tmp/buildStripes10k.jenncasper.20171011.181845.941475\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/jenncasper/tmp/mrjob/buildStripes10k.jenncasper.20171011.181845.941475/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 1...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob1795517113783390631.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 190\n",
      "  number of splits:190\n",
      "  Submitting tokens for job: job_1506640654827_2562\n",
      "  Submitted application application_1506640654827_2562\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1506640654827_2562/\n",
      "  Running job: job_1506640654827_2562\n",
      "  Job job_1506640654827_2562 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 1% reduce 0%\n",
      "   map 2% reduce 0%\n",
      "   map 3% reduce 0%\n",
      "   map 4% reduce 0%\n",
      "   map 5% reduce 0%\n",
      "   map 6% reduce 0%\n",
      "   map 7% reduce 0%\n",
      "   map 8% reduce 0%\n",
      "   map 9% reduce 0%\n",
      "   map 10% reduce 0%\n",
      "   map 11% reduce 0%\n",
      "   map 12% reduce 0%\n",
      "   map 13% reduce 0%\n",
      "   map 14% reduce 0%\n",
      "   map 15% reduce 0%\n",
      "   map 16% reduce 0%\n",
      "   map 17% reduce 0%\n",
      "   map 18% reduce 0%\n",
      "   map 19% reduce 0%\n",
      "   map 20% reduce 0%\n",
      "   map 21% reduce 0%\n",
      "   map 22% reduce 0%\n",
      "   map 23% reduce 0%\n",
      "   map 24% reduce 0%\n",
      "   map 25% reduce 0%\n",
      "   map 26% reduce 0%\n",
      "   map 27% reduce 0%\n",
      "   map 28% reduce 0%\n",
      "   map 29% reduce 0%\n",
      "   map 30% reduce 0%\n",
      "   map 31% reduce 0%\n",
      "   map 32% reduce 0%\n",
      "   map 33% reduce 0%\n",
      "   map 34% reduce 0%\n",
      "   map 35% reduce 0%\n",
      "   map 36% reduce 0%\n",
      "   map 37% reduce 0%\n",
      "   map 38% reduce 0%\n",
      "   map 39% reduce 0%\n",
      "   map 40% reduce 0%\n",
      "   map 41% reduce 0%\n",
      "   map 42% reduce 0%\n",
      "   map 43% reduce 0%\n",
      "   map 44% reduce 0%\n",
      "   map 45% reduce 0%\n",
      "   map 46% reduce 0%\n",
      "   map 47% reduce 0%\n",
      "   map 48% reduce 0%\n",
      "   map 49% reduce 0%\n",
      "   map 50% reduce 0%\n",
      "   map 51% reduce 0%\n",
      "   map 52% reduce 0%\n",
      "   map 53% reduce 0%\n",
      "   map 54% reduce 0%\n",
      "   map 55% reduce 0%\n",
      "   map 56% reduce 0%\n",
      "   map 57% reduce 0%\n",
      "   map 58% reduce 0%\n",
      "   map 59% reduce 0%\n",
      "   map 60% reduce 0%\n",
      "   map 61% reduce 0%\n",
      "   map 62% reduce 0%\n",
      "   map 63% reduce 0%\n",
      "   map 64% reduce 0%\n",
      "   map 65% reduce 0%\n",
      "   map 66% reduce 0%\n",
      "   map 67% reduce 0%\n",
      "   map 68% reduce 0%\n",
      "   map 69% reduce 0%\n",
      "   map 70% reduce 0%\n",
      "   map 71% reduce 0%\n",
      "   map 72% reduce 0%\n",
      "   map 73% reduce 0%\n",
      "   map 74% reduce 0%\n",
      "   map 75% reduce 0%\n",
      "   map 76% reduce 0%\n",
      "   map 77% reduce 0%\n",
      "   map 78% reduce 0%\n",
      "   map 79% reduce 0%\n",
      "   map 80% reduce 0%\n",
      "   map 81% reduce 0%\n",
      "   map 82% reduce 0%\n",
      "   map 83% reduce 0%\n",
      "   map 84% reduce 0%\n",
      "   map 85% reduce 0%\n",
      "   map 86% reduce 0%\n",
      "   map 87% reduce 0%\n",
      "   map 88% reduce 0%\n",
      "   map 89% reduce 0%\n",
      "   map 90% reduce 0%\n",
      "   map 91% reduce 0%\n",
      "   map 92% reduce 0%\n",
      "   map 93% reduce 0%\n",
      "   map 94% reduce 0%\n",
      "   map 95% reduce 0%\n",
      "   map 96% reduce 0%\n",
      "   map 97% reduce 0%\n",
      "   map 98% reduce 0%\n",
      "   map 99% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 71%\n",
      "   map 100% reduce 74%\n",
      "   map 100% reduce 77%\n",
      "   map 100% reduce 80%\n",
      "   map 100% reduce 83%\n",
      "   map 100% reduce 86%\n",
      "   map 100% reduce 89%\n",
      "   map 100% reduce 92%\n",
      "   map 100% reduce 95%\n",
      "   map 100% reduce 98%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1506640654827_2562 completed successfully\n",
      "  Output directory: hdfs:///user/jenncasper/hw550_outputs/stripes_10k\n",
      "Counters: 51\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=2156069116\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=9097978\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=13564631\n",
      "\t\tFILE: Number of bytes written=58835123\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=2156099976\n",
      "\t\tHDFS: Number of bytes written=9097978\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=573\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tKilled map tasks=10\n",
      "\t\tLaunched map tasks=200\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tOther local map tasks=2\n",
      "\t\tRack-local map tasks=198\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=141039834624\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=97881600\n",
      "\t\tTotal time spent by all map tasks (ms)=91822809\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=275468427\n",
      "\t\tTotal time spent by all reduce tasks (ms)=38235\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=191175\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=91822809\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=38235\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=51460120\n",
      "\t\tCombine input records=1577158\n",
      "\t\tCombine output records=639819\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=133901\n",
      "\t\tInput split bytes=30860\n",
      "\t\tMap input records=58682266\n",
      "\t\tMap output bytes=43394873\n",
      "\t\tMap output materialized bytes=19670165\n",
      "\t\tMap output records=1577158\n",
      "\t\tMerged Map outputs=190\n",
      "\t\tPhysical memory (bytes) snapshot=155761635328\n",
      "\t\tReduce input groups=8997\n",
      "\t\tReduce input records=639819\n",
      "\t\tReduce output records=8997\n",
      "\t\tReduce shuffle bytes=19670165\n",
      "\t\tShuffled Maps =190\n",
      "\t\tSpilled Records=1279638\n",
      "\t\tTotal committed heap usage (bytes)=165796118528\n",
      "\t\tVirtual memory (bytes) snapshot=655075770368\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Removing HDFS temp directory hdfs:///user/jenncasper/tmp/mrjob/buildStripes10k.jenncasper.20171011.181845.941475...\n",
      "Removing temp directory /tmp/buildStripes10k.jenncasper.20171011.181845.941475...\n"
     ]
    }
   ],
   "source": [
    "# buildStripes10k.py for all data\n",
    "!hadoop fs -rm -r hw550_outputs/stripes_10k\n",
    "OUTPUT_PATH = os.path.join(OUTPUT_PATH_BASE,'hw550_outputs/stripes_10k')\n",
    "!python buildStripes10k.py \\\n",
    "    -r hadoop hdfs:///user/winegarj/data/full/ \\\n",
    "    --file mostFrequent_10k \\\n",
    "    --file leastmostFrequent_1k \\\n",
    "    --output-dir={OUTPUT_PATH} \\\n",
    "    --no-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "-rw-r--r--   3 jenncasper users          0 2017-10-11 18:38 /user/jenncasper/hw550_outputs/stripes_10k/_SUCCESS\n",
      "-rw-r--r--   3 jenncasper users      8.7 M 2017-10-11 18:38 /user/jenncasper/hw550_outputs/stripes_10k/part-00000\n",
      "\"ab\"\t{\"conveying\": 273, \"chord\": 1006, \"parallels\": 89, \"subscribed\": 44, \"binary\": 76, \"residential\": 77, \"consul\": 48, \"amplifier\": 91, \"ce\": 58, \"terminals\": 141, \"narratives\": 89, \"est\": 256, \"qui\": 1445, \"lever\": 77, \"wires\": 51}\n",
      "cat: Unable to write to output stream.\n"
     ]
    }
   ],
   "source": [
    "# check the output for the strips_10k\n",
    "!hadoop fs -ls -h {OUTPUT_PATH}\n",
    "!hadoop fs -cat {OUTPUT_PATH}/* | head -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### buildStripes10k stats\n",
    "\n",
    "    Reduce output records=8997\n",
    "    CPU time spent (ms)=51460120\n",
    "    Rack-local map tasks=198\n",
    "\tLaunched map tasks=200\n",
    "\tLaunched reduce tasks=1\n",
    "\tOther local map tasks=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing invertedIndex10k.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile invertedIndex10k.py\n",
    "#!~/anaconda2/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import division\n",
    "import collections\n",
    "import re\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import itertools\n",
    "import mrjob\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import sys, ast\n",
    "\n",
    "class MRinvertedIndex10k(MRJob):\n",
    "    \n",
    "    MRJob.SORT_VALUES = True\n",
    "    \n",
    "    def steps(self):\n",
    "        JOBCONF_STEP = {\n",
    "            'mapreduce.job.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "            'mapreduce.partition.keycomparator.options':'-k1,1',\n",
    "        }\n",
    "        return [\n",
    "            MRStep(jobconf = JOBCONF_STEP,\n",
    "                   mapper = self.mapper,\n",
    "                   reducer = self.reducer,\n",
    "            )\n",
    "        ]  \n",
    "\n",
    "    # purpose: split out the word pair counts for the ngrams\n",
    "    # input: line from stripes file\n",
    "    # output: key(word in ngram), value(doc and doc lengths)\n",
    "    def mapper(self, _, line):\n",
    "        # splice out the input from the stripes file      \n",
    "        items = line.strip().split('\\t')\n",
    "        doc = items[0].replace(\"\\\"\",\"\")\n",
    "        stripe = ast.literal_eval(items[1])\n",
    "        # determine the ngram length and output\n",
    "        length = len(stripe.keys())\n",
    "        for word, cnt in sorted(stripe.iteritems()):\n",
    "            yield word, (doc, length)\n",
    "    \n",
    "    # purpose: take the sorted input and prep for output\n",
    "    # input: key(word in ngram), value(doc and doc lengths)\n",
    "    # output: key(word in ngram), value(list of doc and doc lengths)\n",
    "    def reducer(self, word, doc_len_list):\n",
    "        doc_lens = [i for i in doc_len_list]\n",
    "        yield word, doc_lens    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRinvertedIndex10k.run() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "ignoring partitioner keyword arg (requires real Hadoop): 'org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner'\n",
      "Creating temp directory /tmp/invertedIndex10k.jenncasper.20171011.195401.056806\n",
      "Running step 1 of 1...\n",
      "Streaming final output from /tmp/invertedIndex10k.jenncasper.20171011.195401.056806/output...\n",
      "Removing temp directory /tmp/invertedIndex10k.jenncasper.20171011.195401.056806...\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "# check for functionality by running local\n",
    "!python invertedIndex10k.py -r local systems_test_stripes > systems_test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `hw550_outputs/systems_test_index': No such file or directory\n",
      "No configs found; falling back on auto-configuration\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Creating temp directory /tmp/invertedIndex10k.jenncasper.20171011.191311.948799\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/jenncasper/tmp/mrjob/invertedIndex10k.jenncasper.20171011.191311.948799/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 1...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob2236247771059410225.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1506640654827_2594\n",
      "  Submitted application application_1506640654827_2594\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1506640654827_2594/\n",
      "  Running job: job_1506640654827_2594\n",
      "  Job job_1506640654827_2594 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1506640654827_2594 completed successfully\n",
      "  Output directory: hdfs:///user/jenncasper/hw550_outputs/systems_test_index\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=1179\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=870\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=540\n",
      "\t\tFILE: Number of bytes written=399330\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=1477\n",
      "\t\tHDFS: Number of bytes written=870\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=23987712\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=15452160\n",
      "\t\tTotal time spent by all map tasks (ms)=15617\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=46851\n",
      "\t\tTotal time spent by all reduce tasks (ms)=6036\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=30180\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=15617\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=6036\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2680\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=352\n",
      "\t\tInput split bytes=298\n",
      "\t\tMap input records=20\n",
      "\t\tMap output bytes=1064\n",
      "\t\tMap output materialized bytes=697\n",
      "\t\tMap output records=42\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1891868672\n",
      "\t\tReduce input groups=42\n",
      "\t\tReduce input records=42\n",
      "\t\tReduce output records=20\n",
      "\t\tReduce shuffle bytes=697\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=84\n",
      "\t\tTotal committed heap usage (bytes)=2269642752\n",
      "\t\tVirtual memory (bytes) snapshot=11411222528\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Removing HDFS temp directory hdfs:///user/jenncasper/tmp/mrjob/invertedIndex10k.jenncasper.20171011.191311.948799...\n",
      "Removing temp directory /tmp/invertedIndex10k.jenncasper.20171011.191311.948799...\n"
     ]
    }
   ],
   "source": [
    "# check that the test works for hadoop\n",
    "!hadoop fs -rm -r hw550_outputs/systems_test_index\n",
    "OUTPUT_PATH = os.path.join(OUTPUT_PATH_BASE,'hw550_outputs/systems_test_index')\n",
    "!python invertedIndex10k.py \\\n",
    "    -r hadoop hdfs:///user/jenncasper/hw550_outputs/systems_test_stripes \\\n",
    "    --output-dir={OUTPUT_PATH} \\\n",
    "    --no-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\r\n"
     ]
    }
   ],
   "source": [
    "# check the output for the index test\n",
    "!hadoop fs -ls -h {OUTPUT_PATH}\n",
    "!hadoop fs -cat {OUTPUT_PATH}/* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `hw550_outputs/index_10k': No such file or directory\n",
      "No configs found; falling back on auto-configuration\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Creating temp directory /tmp/invertedIndex10k.jenncasper.20171011.192506.259255\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/jenncasper/tmp/mrjob/invertedIndex10k.jenncasper.20171011.192506.259255/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 1...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob9190715603547387903.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1506640654827_2601\n",
      "  Submitted application application_1506640654827_2601\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1506640654827_2601/\n",
      "  Running job: job_1506640654827_2601\n",
      "  Job job_1506640654827_2601 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 6% reduce 0%\n",
      "   map 11% reduce 0%\n",
      "   map 15% reduce 0%\n",
      "   map 20% reduce 0%\n",
      "   map 24% reduce 0%\n",
      "   map 31% reduce 0%\n",
      "   map 35% reduce 0%\n",
      "   map 40% reduce 0%\n",
      "   map 44% reduce 0%\n",
      "   map 50% reduce 0%\n",
      "   map 54% reduce 0%\n",
      "   map 58% reduce 0%\n",
      "   map 65% reduce 0%\n",
      "   map 66% reduce 0%\n",
      "   map 67% reduce 0%\n",
      "   map 83% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 74%\n",
      "   map 100% reduce 78%\n",
      "   map 100% reduce 81%\n",
      "   map 100% reduce 84%\n",
      "   map 100% reduce 86%\n",
      "   map 100% reduce 89%\n",
      "   map 100% reduce 91%\n",
      "   map 100% reduce 95%\n",
      "   map 100% reduce 98%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1506640654827_2601 completed successfully\n",
      "  Output directory: hdfs:///user/jenncasper/hw550_outputs/index_10k\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=9136509\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=9271913\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=6156954\n",
      "\t\tFILE: Number of bytes written=12465366\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=9136789\n",
      "\t\tHDFS: Number of bytes written=9271913\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=155406336\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=136652800\n",
      "\t\tTotal time spent by all map tasks (ms)=101176\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=303528\n",
      "\t\tTotal time spent by all reduce tasks (ms)=53380\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=266900\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=101176\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=53380\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=64870\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=1429\n",
      "\t\tInput split bytes=280\n",
      "\t\tMap input records=8997\n",
      "\t\tMap output bytes=15245053\n",
      "\t\tMap output materialized bytes=5910373\n",
      "\t\tMap output records=543036\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1992470528\n",
      "\t\tReduce input groups=543036\n",
      "\t\tReduce input records=543036\n",
      "\t\tReduce output records=1000\n",
      "\t\tReduce shuffle bytes=5910373\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=1086072\n",
      "\t\tTotal committed heap usage (bytes)=2157445120\n",
      "\t\tVirtual memory (bytes) snapshot=11410743296\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Removing HDFS temp directory hdfs:///user/jenncasper/tmp/mrjob/invertedIndex10k.jenncasper.20171011.192506.259255...\n",
      "Removing temp directory /tmp/invertedIndex10k.jenncasper.20171011.192506.259255...\n"
     ]
    }
   ],
   "source": [
    "# invertedIndex10k.py for all data\n",
    "!hadoop fs -rm -r hw550_outputs/index_10k\n",
    "OUTPUT_PATH = os.path.join(OUTPUT_PATH_BASE,'hw550_outputs/index_10k')\n",
    "!python invertedIndex10k.py \\\n",
    "    -r hadoop hdfs:///user/jenncasper/hw550_outputs/stripes_10k \\\n",
    "    --output-dir={OUTPUT_PATH} \\\n",
    "    --no-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "-rw-r--r--   3 jenncasper users          0 2017-10-11 19:28 /user/jenncasper/hw550_outputs/index_10k/_SUCCESS\n",
      "-rw-r--r--   3 jenncasper users      8.8 M 2017-10-11 19:28 /user/jenncasper/hw550_outputs/index_10k/part-00000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "# check the output for the index_10k\n",
    "!hadoop fs -ls -h {OUTPUT_PATH}\n",
    "!hadoop fs -cat {OUTPUT_PATH}/* | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### invertedIndex10k stats\n",
    "\n",
    "    Reduce output records=1000\n",
    "    CPU time spent (ms)=64870\n",
    "    Rack-local map tasks=2\n",
    "\tLaunched map tasks=2\n",
    "\tLaunched reduce tasks=1\n",
    "\tOther local map tasks=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting similarity10k.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile similarity10k.py\n",
    "#!~/anaconda2/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import division\n",
    "import collections\n",
    "import re\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import itertools\n",
    "import mrjob\n",
    "from mrjob.protocol import RawProtocol\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "\n",
    "class MRsimilarity10k(MRJob):\n",
    "\n",
    "    MRJob.SORT_VALUES = True \n",
    "    \n",
    "    def steps(self):\n",
    "        JOBCONF_STEP1 = {\n",
    "            'mapreduce.job.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "            'mapreduce.partition.keycomparator.options':'-k1,1',\n",
    "        }\n",
    "        JOBCONF_STEP2 = { \n",
    "            'mapreduce.job.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "            'mapreduce.partition.keycomparator.options':'-k1,1nr',\n",
    "        }\n",
    "        return [MRStep(jobconf = JOBCONF_STEP1,\n",
    "                    mapper = self.mapper_pair_sim,\n",
    "                    reducer = self.reducer_pair_sim,\n",
    "                ),\n",
    "                #MRStep(jobconf = JOBCONF_STEP2,\n",
    "                #    mapper = None,   \n",
    "                #    reducer = self.reducer_sort,\n",
    "                #)\n",
    "        ]\n",
    "    \n",
    "    # purpose: break apart the doc mappings and calculate a partial similarity for each pair\n",
    "    def mapper_pair_sim(self, _, line):\n",
    "        line = line.strip()\n",
    "        index, posting = line.split(\"\\t\")\n",
    "        posting = json.loads(posting)\n",
    "\n",
    "        # build out all of the document pairs for the line\n",
    "        for subset in itertools.combinations(posting, 2):\n",
    "            # output the values necessary for jaccard and similarity calculations\n",
    "            doc1 = subset[0][0]\n",
    "            doc2 = subset[1][0]\n",
    "            # for jaccard\n",
    "            inter_cnt = 1\n",
    "            doc1_len = subset[0][1]\n",
    "            doc2_len = subset[1][1]\n",
    "            # for cosine\n",
    "            product = (1 / math.sqrt(doc1_len)) * (1 / math.sqrt(doc2_len))\n",
    "\n",
    "            # order the doc names so the reducer gets the correct key packages\n",
    "            yield (sorted([doc1, doc2])), (inter_cnt, doc1_len, doc2_len, product)\n",
    "\n",
    "\n",
    "    # purpose: sum the partial similarities\n",
    "    def reducer_pair_sim(self, key, value):\n",
    "        \n",
    "        inter_cnt = 0\n",
    "        cosine = 0\n",
    "        d = {}\n",
    "        \n",
    "        # sum for final dist values\n",
    "        final_key = key[0] + ' - ' + key[1]\n",
    "        for i in value:\n",
    "            inter_cnt += i[0]\n",
    "            doc1_len = i[1]\n",
    "            doc2_len = i[2]\n",
    "            cosine += i[3]\n",
    "        jaccard = inter_cnt / (doc1_len + doc2_len - inter_cnt)\n",
    "        # overlap - size of the intersection divided by the smaller of the size of the two sets  \n",
    "        overlap = inter_cnt / min(doc1_len, doc2_len)\n",
    "        # dice - 2 times the intersection divided by the sum of the two set sizes\n",
    "        dice = (2 * inter_cnt) / (doc1_len + doc2_len)\n",
    "        \n",
    "        # similarity value results\n",
    "        d['cosine'] = cosine\n",
    "        d['jaccard'] = jaccard\n",
    "        d['overlap'] = overlap\n",
    "        d['dice'] = dice\n",
    "        \n",
    "        # similarity average\n",
    "        avg = np.mean(d.values())\n",
    "\n",
    "        yield float(d['cosine']), (final_key, avg, d)\n",
    "    \n",
    "    # purpose: sort the final output by the avg or other dist value\n",
    "    def reducer_sort(self, key, value):\n",
    "        # sort by cosine value\n",
    "        for v in value:\n",
    "            yield key, v\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRsimilarity10k.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "ignoring partitioner keyword arg (requires real Hadoop): 'org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner'\n",
      "Creating temp directory /tmp/similarity10k.jenncasper.20171012.013832.933878\n",
      "Running step 1 of 2...\n",
      "Running step 2 of 2...\n",
      "Streaming final output from /tmp/similarity10k.jenncasper.20171012.013832.933878/output...\n",
      "Removing temp directory /tmp/similarity10k.jenncasper.20171012.013832.933878...\n",
      "1.0\t[\"female - government\",1.0,{\"cosine\":1.0,\"dice\":1.0,\"overlap\":1.0,\"jaccard\":1.0}]\n",
      "1.0\t[\"female - limited\",1.0,{\"cosine\":1.0,\"dice\":1.0,\"overlap\":1.0,\"jaccard\":1.0}]\n",
      "1.0\t[\"government - limited\",1.0,{\"cosine\":1.0,\"dice\":1.0,\"overlap\":1.0,\"jaccard\":1.0}]\n",
      "0.75\t[\"case - study\",0.7125,{\"cosine\":0.75,\"dice\":0.75,\"overlap\":0.75,\"jaccard\":0.6}]\n",
      "0.7071067812\t[\"fairy - forms\",0.718443362,{\"cosine\":0.7071067812,\"dice\":0.6666666667,\"overlap\":1.0,\"jaccard\":0.5}]\n",
      "0.7071067812\t[\"forms - tales\",0.718443362,{\"cosine\":0.7071067812,\"dice\":0.6666666667,\"overlap\":1.0,\"jaccard\":0.5}]\n",
      "0.5\t[\"bill - establishing\",0.4583333333,{\"cosine\":0.5,\"dice\":0.5,\"overlap\":0.5,\"jaccard\":0.3333333333}]\n",
      "0.5\t[\"bill - religious\",0.4583333333,{\"cosine\":0.5,\"dice\":0.5,\"overlap\":0.5,\"jaccard\":0.3333333333}]\n",
      "0.5\t[\"biography - general\",0.4583333333,{\"cosine\":0.5,\"dice\":0.5,\"overlap\":0.5,\"jaccard\":0.3333333333}]\n",
      "0.5\t[\"biography - george\",0.4583333333,{\"cosine\":0.5,\"dice\":0.5,\"overlap\":0.5,\"jaccard\":0.3333333333}]\n",
      "0.5\t[\"child's - christmas\",0.4583333333,{\"cosine\":0.5,\"dice\":0.5,\"overlap\":0.5,\"jaccard\":0.3333333333}]\n",
      "0.5\t[\"child's - wales\",0.4583333333,{\"cosine\":0.5,\"dice\":0.5,\"overlap\":0.5,\"jaccard\":0.3333333333}]\n",
      "0.5\t[\"christmas - wales\",0.4583333333,{\"cosine\":0.5,\"dice\":0.5,\"overlap\":0.5,\"jaccard\":0.3333333333}]\n",
      "0.5\t[\"establishing - religious\",0.4583333333,{\"cosine\":0.5,\"dice\":0.5,\"overlap\":0.5,\"jaccard\":0.3333333333}]\n",
      "0.5\t[\"fairy - tales\",0.4583333333,{\"cosine\":0.5,\"dice\":0.5,\"overlap\":0.5,\"jaccard\":0.3333333333}]\n",
      "0.5\t[\"general - george\",0.4583333333,{\"cosine\":0.5,\"dice\":0.5,\"overlap\":0.5,\"jaccard\":0.3333333333}]\n",
      "0.4082482905\t[\"collection - fairy\",0.3895620726,{\"cosine\":0.4082482905,\"dice\":0.4,\"overlap\":0.5,\"jaccard\":0.25}]\n",
      "0.4082482905\t[\"collection - tales\",0.3895620726,{\"cosine\":0.4082482905,\"dice\":0.4,\"overlap\":0.5,\"jaccard\":0.25}]\n",
      "0.3535533906\t[\"case - female\",0.346721681,{\"cosine\":0.3535533906,\"dice\":0.3333333333,\"overlap\":0.5,\"jaccard\":0.2}]\n",
      "0.3535533906\t[\"case - government\",0.346721681,{\"cosine\":0.3535533906,\"dice\":0.3333333333,\"overlap\":0.5,\"jaccard\":0.2}]\n",
      "0.3535533906\t[\"case - limited\",0.346721681,{\"cosine\":0.3535533906,\"dice\":0.3333333333,\"overlap\":0.5,\"jaccard\":0.2}]\n",
      "0.3535533906\t[\"female - study\",0.346721681,{\"cosine\":0.3535533906,\"dice\":0.3333333333,\"overlap\":0.5,\"jaccard\":0.2}]\n",
      "0.3535533906\t[\"government - study\",0.346721681,{\"cosine\":0.3535533906,\"dice\":0.3333333333,\"overlap\":0.5,\"jaccard\":0.2}]\n",
      "0.3535533906\t[\"limited - study\",0.346721681,{\"cosine\":0.3535533906,\"dice\":0.3333333333,\"overlap\":0.5,\"jaccard\":0.2}]\n"
     ]
    }
   ],
   "source": [
    "# check for functionality by running local\n",
    "!python similarity10k.py -r local systems_test_index | sort -k1,1nr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/10/12 01:38:50 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 5760 minutes, Emptier interval = 360 minutes.\n",
      "Moved: 'hdfs://nn-ia.s3s.altiscale.com:8020/user/jenncasper/hw550_outputs/systems_test_similarities' to trash at: hdfs://nn-ia.s3s.altiscale.com:8020/user/jenncasper/.Trash/Current\n",
      "No configs found; falling back on auto-configuration\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Creating temp directory /tmp/similarity10k.jenncasper.20171012.013851.598860\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/jenncasper/tmp/mrjob/similarity10k.jenncasper.20171012.013851.598860/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob1004929625854441720.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1506640654827_2809\n",
      "  Submitted application application_1506640654827_2809\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1506640654827_2809/\n",
      "  Running job: job_1506640654827_2809\n",
      "  Job job_1506640654827_2809 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1506640654827_2809 completed successfully\n",
      "  Output directory: hdfs:///user/jenncasper/tmp/mrjob/similarity10k.jenncasper.20171012.013851.598860/step-output/0000\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=1305\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=3728\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=522\n",
      "\t\tFILE: Number of bytes written=399359\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=1599\n",
      "\t\tHDFS: Number of bytes written=3728\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=16227840\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=15201280\n",
      "\t\tTotal time spent by all map tasks (ms)=10565\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=31695\n",
      "\t\tTotal time spent by all reduce tasks (ms)=5938\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=29690\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=10565\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=5938\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2710\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=227\n",
      "\t\tInput split bytes=294\n",
      "\t\tMap input records=20\n",
      "\t\tMap output bytes=1532\n",
      "\t\tMap output materialized bytes=741\n",
      "\t\tMap output records=29\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1887494144\n",
      "\t\tReduce input groups=24\n",
      "\t\tReduce input records=29\n",
      "\t\tReduce output records=24\n",
      "\t\tReduce shuffle bytes=741\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=58\n",
      "\t\tTotal committed heap usage (bytes)=2310012928\n",
      "\t\tVirtual memory (bytes) snapshot=11408936960\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 2 of 2...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob1101442851018087992.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1506640654827_2810\n",
      "  Submitted application application_1506640654827_2810\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1506640654827_2810/\n",
      "  Running job: job_1506640654827_2810\n",
      "  Job job_1506640654827_2810 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1506640654827_2810 completed successfully\n",
      "  Output directory: hdfs:///user/jenncasper/hw550_outputs/systems_test_similarities\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=5592\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=3728\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=855\n",
      "\t\tFILE: Number of bytes written=399922\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=5972\n",
      "\t\tHDFS: Number of bytes written=3728\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=15390720\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=8678400\n",
      "\t\tTotal time spent by all map tasks (ms)=10020\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=30060\n",
      "\t\tTotal time spent by all reduce tasks (ms)=3390\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=16950\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=10020\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=3390\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2480\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=246\n",
      "\t\tInput split bytes=380\n",
      "\t\tMap input records=24\n",
      "\t\tMap output bytes=3772\n",
      "\t\tMap output materialized bytes=1152\n",
      "\t\tMap output records=24\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1886511104\n",
      "\t\tReduce input groups=24\n",
      "\t\tReduce input records=24\n",
      "\t\tReduce output records=24\n",
      "\t\tReduce shuffle bytes=1152\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=48\n",
      "\t\tTotal committed heap usage (bytes)=2260205568\n",
      "\t\tVirtual memory (bytes) snapshot=11411079168\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Removing HDFS temp directory hdfs:///user/jenncasper/tmp/mrjob/similarity10k.jenncasper.20171012.013851.598860...\n",
      "Removing temp directory /tmp/similarity10k.jenncasper.20171012.013851.598860...\n"
     ]
    }
   ],
   "source": [
    "# check that the test works for hadoop\n",
    "!hadoop fs -rm -r hw550_outputs/systems_test_similarities\n",
    "OUTPUT_PATH = os.path.join(OUTPUT_PATH_BASE,'hw550_outputs/systems_test_similarities')\n",
    "!python similarity10k.py \\\n",
    "    -r hadoop hdfs:///user/jenncasper/hw550_outputs/systems_test_index \\\n",
    "    --output-dir={OUTPUT_PATH} \\\n",
    "    --no-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "-rw-r--r--   3 jenncasper users          0 2017-10-12 01:40 /user/jenncasper/hw550_outputs/systems_test_similarities/_SUCCESS\n",
      "-rw-r--r--   3 jenncasper users      3.6 K 2017-10-12 01:40 /user/jenncasper/hw550_outputs/systems_test_similarities/part-00000\n",
      "0.99999999999999978\t[\"government - limited\", 1.0, {\"cosine\": 0.99999999999999978, \"dice\": 1.0, \"overlap\": 1.0, \"jaccard\": 1.0}]\n",
      "0.99999999999999978\t[\"female - limited\", 1.0, {\"cosine\": 0.99999999999999978, \"dice\": 1.0, \"overlap\": 1.0, \"jaccard\": 1.0}]\n",
      "0.99999999999999978\t[\"female - government\", 1.0, {\"cosine\": 0.99999999999999978, \"dice\": 1.0, \"overlap\": 1.0, \"jaccard\": 1.0}]\n",
      "0.75\t[\"case - study\", 0.71250000000000002, {\"cosine\": 0.75, \"dice\": 0.75, \"overlap\": 0.75, \"jaccard\": 0.59999999999999998}]\n",
      "0.70710678118654746\t[\"forms - tales\", 0.7184433619633035, {\"cosine\": 0.70710678118654746, \"dice\": 0.66666666666666663, \"overlap\": 1.0, \"jaccard\": 0.5}]\n",
      "0.70710678118654746\t[\"fairy - forms\", 0.7184433619633035, {\"cosine\": 0.70710678118654746, \"dice\": 0.66666666666666663, \"overlap\": 1.0, \"jaccard\": 0.5}]\n",
      "0.49999999999999989\t[\"general - george\", 0.45833333333333331, {\"cosine\": 0.49999999999999989, \"dice\": 0.5, \"overlap\": 0.5, \"jaccard\": 0.33333333333333331}]\n",
      "0.49999999999999989\t[\"fairy - tales\", 0.45833333333333331, {\"cosine\": 0.49999999999999989, \"dice\": 0.5, \"overlap\": 0.5, \"jaccard\": 0.33333333333333331}]\n",
      "0.49999999999999989\t[\"establishing - religious\", 0.45833333333333331, {\"cosine\": 0.49999999999999989, \"dice\": 0.5, \"overlap\": 0.5, \"jaccard\": 0.33333333333333331}]\n",
      "0.49999999999999989\t[\"christmas - wales\", 0.45833333333333331, {\"cosine\": 0.49999999999999989, \"dice\": 0.5, \"overlap\": 0.5, \"jaccard\": 0.33333333333333331}]\n",
      "0.49999999999999989\t[\"child's - wales\", 0.45833333333333331, {\"cosine\": 0.49999999999999989, \"dice\": 0.5, \"overlap\": 0.5, \"jaccard\": 0.33333333333333331}]\n",
      "0.49999999999999989\t[\"child's - christmas\", 0.45833333333333331, {\"cosine\": 0.49999999999999989, \"dice\": 0.5, \"overlap\": 0.5, \"jaccard\": 0.33333333333333331}]\n",
      "0.49999999999999989\t[\"biography - george\", 0.45833333333333331, {\"cosine\": 0.49999999999999989, \"dice\": 0.5, \"overlap\": 0.5, \"jaccard\": 0.33333333333333331}]\n",
      "0.49999999999999989\t[\"biography - general\", 0.45833333333333331, {\"cosine\": 0.49999999999999989, \"dice\": 0.5, \"overlap\": 0.5, \"jaccard\": 0.33333333333333331}]\n",
      "0.49999999999999989\t[\"bill - religious\", 0.45833333333333331, {\"cosine\": 0.49999999999999989, \"dice\": 0.5, \"overlap\": 0.5, \"jaccard\": 0.33333333333333331}]\n",
      "0.49999999999999989\t[\"bill - establishing\", 0.45833333333333331, {\"cosine\": 0.49999999999999989, \"dice\": 0.5, \"overlap\": 0.5, \"jaccard\": 0.33333333333333331}]\n",
      "0.40824829046386302\t[\"collection - fairy\", 0.38956207261596576, {\"cosine\": 0.40824829046386302, \"dice\": 0.40000000000000002, \"overlap\": 0.5, \"jaccard\": 0.25}]\n",
      "0.40824829046386302\t[\"collection - tales\", 0.38956207261596576, {\"cosine\": 0.40824829046386302, \"dice\": 0.40000000000000002, \"overlap\": 0.5, \"jaccard\": 0.25}]\n",
      "0.35355339059327373\t[\"limited - study\", 0.34672168098165174, {\"cosine\": 0.35355339059327373, \"dice\": 0.33333333333333331, \"overlap\": 0.5, \"jaccard\": 0.20000000000000001}]\n",
      "0.35355339059327373\t[\"government - study\", 0.34672168098165174, {\"cosine\": 0.35355339059327373, \"dice\": 0.33333333333333331, \"overlap\": 0.5, \"jaccard\": 0.20000000000000001}]\n",
      "0.35355339059327373\t[\"female - study\", 0.34672168098165174, {\"cosine\": 0.35355339059327373, \"dice\": 0.33333333333333331, \"overlap\": 0.5, \"jaccard\": 0.20000000000000001}]\n",
      "0.35355339059327373\t[\"case - limited\", 0.34672168098165174, {\"cosine\": 0.35355339059327373, \"dice\": 0.33333333333333331, \"overlap\": 0.5, \"jaccard\": 0.20000000000000001}]\n",
      "0.35355339059327373\t[\"case - government\", 0.34672168098165174, {\"cosine\": 0.35355339059327373, \"dice\": 0.33333333333333331, \"overlap\": 0.5, \"jaccard\": 0.20000000000000001}]\n",
      "0.35355339059327373\t[\"case - female\", 0.34672168098165174, {\"cosine\": 0.35355339059327373, \"dice\": 0.33333333333333331, \"overlap\": 0.5, \"jaccard\": 0.20000000000000001}]\n"
     ]
    }
   ],
   "source": [
    "# check the output for the similarities test\n",
    "!hadoop fs -ls -h {OUTPUT_PATH}\n",
    "!hadoop fs -cat {OUTPUT_PATH}/* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `hw550_outputs/similarities_10k': No such file or directory\n",
      "No configs found; falling back on auto-configuration\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Creating temp directory /tmp/similarity10k.jenncasper.20171013.005638.684205\n",
      "Using Hadoop version 2.7.3\n",
      "Copying local files to hdfs:///user/jenncasper/tmp/mrjob/similarity10k.jenncasper.20171013.005638.684205/files/...\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar\n",
      "Detected hadoop configuration property names that do not match hadoop version 2.7.3:\n",
      "The have been translated as follows\n",
      " mapred.text.key.partitioner.options: mapreduce.partition.keypartitioner.options\n",
      "Running step 1 of 1...\n",
      "  packageJobJar: [] [/opt/hadoop-2.7.3/share/hadoop/tools/lib/hadoop-streaming-2.7.3.jar] /tmp/streamjob349648015288105209.jar tmpDir=null\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Timeline service address: http://rm-ia.s3s.altiscale.com:8188/ws/v1/timeline/\n",
      "  Connecting to ResourceManager at rm-ia.s3s.altiscale.com/10.251.255.108:8032\n",
      "  Connecting to Application History server at rm-ia.s3s.altiscale.com/10.251.255.108:10200\n",
      "  Loaded native gpl library from the embedded binaries\n",
      "  Successfully loaded & initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]\n",
      "  Total input paths to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1506640654827_3155\n",
      "  Submitted application application_1506640654827_3155\n",
      "  The url to track the job: http://rm-ia.s3s.altiscale.com:8088/proxy/application_1506640654827_3155/\n",
      "  Running job: job_1506640654827_3155\n",
      "  Job job_1506640654827_3155 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 2% reduce 0%\n",
      "   map 3% reduce 0%\n",
      "   map 4% reduce 0%\n",
      "   map 5% reduce 0%\n",
      "   map 6% reduce 0%\n",
      "   map 7% reduce 0%\n",
      "   map 8% reduce 0%\n",
      "   map 9% reduce 0%\n",
      "   map 10% reduce 0%\n",
      "   map 11% reduce 0%\n",
      "   map 12% reduce 0%\n",
      "   map 13% reduce 0%\n",
      "   map 14% reduce 0%\n",
      "   map 15% reduce 0%\n",
      "   map 16% reduce 0%\n",
      "   map 17% reduce 0%\n",
      "   map 18% reduce 0%\n",
      "   map 19% reduce 0%\n",
      "   map 20% reduce 0%\n",
      "   map 21% reduce 0%\n",
      "   map 22% reduce 0%\n",
      "   map 23% reduce 0%\n",
      "   map 24% reduce 0%\n",
      "   map 25% reduce 0%\n",
      "   map 26% reduce 0%\n",
      "   map 27% reduce 0%\n",
      "   map 28% reduce 0%\n",
      "   map 29% reduce 0%\n",
      "   map 30% reduce 0%\n",
      "   map 31% reduce 0%\n",
      "   map 32% reduce 0%\n",
      "   map 33% reduce 0%\n",
      "   map 34% reduce 0%\n",
      "   map 35% reduce 0%\n",
      "   map 36% reduce 0%\n",
      "   map 37% reduce 0%\n",
      "   map 38% reduce 0%\n",
      "   map 39% reduce 0%\n",
      "   map 40% reduce 0%\n",
      "   map 41% reduce 0%\n",
      "   map 42% reduce 0%\n",
      "   map 43% reduce 0%\n",
      "   map 44% reduce 0%\n",
      "   map 45% reduce 0%\n",
      "   map 46% reduce 0%\n",
      "   map 47% reduce 0%\n",
      "   map 48% reduce 0%\n",
      "   map 49% reduce 0%\n",
      "   map 50% reduce 0%\n",
      "   map 51% reduce 0%\n",
      "   map 52% reduce 0%\n",
      "   map 53% reduce 0%\n",
      "   map 54% reduce 0%\n",
      "   map 55% reduce 0%\n",
      "   map 56% reduce 0%\n",
      "   map 57% reduce 0%\n",
      "   map 58% reduce 0%\n",
      "   map 59% reduce 0%\n",
      "   map 61% reduce 0%\n",
      "   map 62% reduce 0%\n",
      "   map 63% reduce 0%\n",
      "   map 64% reduce 0%\n",
      "   map 65% reduce 0%\n",
      "   map 66% reduce 0%\n",
      "   map 67% reduce 0%\n",
      "   map 68% reduce 0%\n",
      "   map 69% reduce 0%\n",
      "   map 70% reduce 0%\n",
      "   map 71% reduce 0%\n",
      "   map 72% reduce 0%\n",
      "   map 73% reduce 0%\n",
      "   map 74% reduce 0%\n",
      "   map 75% reduce 0%\n",
      "   map 76% reduce 0%\n",
      "   map 77% reduce 0%\n",
      "   map 78% reduce 0%\n",
      "   map 79% reduce 0%\n",
      "   map 80% reduce 0%\n",
      "   map 81% reduce 0%\n",
      "   map 82% reduce 0%\n",
      "   map 83% reduce 0%\n",
      "   map 84% reduce 0%\n",
      "   map 85% reduce 0%\n",
      "   map 86% reduce 0%\n",
      "   map 87% reduce 0%\n",
      "   map 88% reduce 0%\n",
      "   map 89% reduce 0%\n",
      "   map 90% reduce 0%\n",
      "   map 91% reduce 0%\n",
      "   map 92% reduce 0%\n",
      "   map 93% reduce 0%\n",
      "   map 94% reduce 0%\n",
      "   map 95% reduce 0%\n",
      "   map 96% reduce 0%\n",
      "   map 97% reduce 0%\n",
      "   map 98% reduce 0%\n",
      "   map 99% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 17%\n",
      "   map 100% reduce 67%\n",
      "   map 100% reduce 68%\n",
      "   map 100% reduce 69%\n",
      "   map 100% reduce 70%\n",
      "   map 100% reduce 71%\n",
      "   map 100% reduce 72%\n",
      "   map 100% reduce 73%\n",
      "   map 100% reduce 74%\n",
      "   map 100% reduce 75%\n",
      "   map 100% reduce 76%\n",
      "   map 100% reduce 77%\n",
      "   map 100% reduce 78%\n",
      "   map 100% reduce 79%\n",
      "   map 100% reduce 80%\n",
      "   map 100% reduce 81%\n",
      "   map 100% reduce 82%\n",
      "   map 100% reduce 83%\n",
      "   map 100% reduce 84%\n",
      "   map 100% reduce 85%\n",
      "   map 100% reduce 86%\n",
      "   map 100% reduce 87%\n",
      "   map 100% reduce 88%\n",
      "   map 100% reduce 89%\n",
      "   map 100% reduce 90%\n",
      "   map 100% reduce 91%\n",
      "   map 100% reduce 92%\n",
      "   map 100% reduce 93%\n",
      "   map 100% reduce 94%\n",
      "   map 100% reduce 95%\n",
      "   map 100% reduce 96%\n",
      "   map 100% reduce 97%\n",
      "   map 100% reduce 98%\n",
      "   map 100% reduce 99%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1506640654827_3155 completed successfully\n",
      "  Output directory: hdfs:///user/jenncasper/hw550_outputs/similarities_10k\n",
      "Counters: 49\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=9354549\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=4865118782\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=4514105287\n",
      "\t\tFILE: Number of bytes written=6076341215\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=9354825\n",
      "\t\tHDFS: Number of bytes written=4865118782\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tRack-local map tasks=2\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=10839058944\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=37497489920\n",
      "\t\tTotal time spent by all map tasks (ms)=7056679\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=21170037\n",
      "\t\tTotal time spent by all reduce tasks (ms)=14647457\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=73237285\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=7056679\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=14647457\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=22818760\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=67758\n",
      "\t\tInput split bytes=276\n",
      "\t\tMap input records=1000\n",
      "\t\tMap output bytes=9220436129\n",
      "\t\tMap output materialized bytes=1561837998\n",
      "\t\tMap output records=157512744\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPhysical memory (bytes) snapshot=1993293824\n",
      "\t\tReduce input groups=91960293\n",
      "\t\tReduce input records=157512744\n",
      "\t\tReduce output records=25453679\n",
      "\t\tReduce shuffle bytes=1561837998\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=472538232\n",
      "\t\tTotal committed heap usage (bytes)=2121793536\n",
      "\t\tVirtual memory (bytes) snapshot=11454398464\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Removing HDFS temp directory hdfs:///user/jenncasper/tmp/mrjob/similarity10k.jenncasper.20171013.005638.684205...\n",
      "Removing temp directory /tmp/similarity10k.jenncasper.20171013.005638.684205...\n",
      "[Errno 2] No such file or directory: '/tmp/similarity10k.jenncasper.20171013.005638.684205'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jenncasper/.conda/envs/py27/lib/python2.7/site-packages/mrjob/runner.py\", line 552, in _cleanup_local_tmp\n",
      "    shutil.rmtree(self._local_tmp_dir)\n",
      "  File \"/home/jenncasper/.conda/envs/py27/lib/python2.7/shutil.py\", line 239, in rmtree\n",
      "    onerror(os.listdir, path, sys.exc_info())\n",
      "  File \"/home/jenncasper/.conda/envs/py27/lib/python2.7/shutil.py\", line 237, in rmtree\n",
      "    names = os.listdir(path)\n",
      "OSError: [Errno 2] No such file or directory: '/tmp/similarity10k.jenncasper.20171013.005638.684205'\n"
     ]
    }
   ],
   "source": [
    "# similarity10k.py for all data\n",
    "!hadoop fs -rm -r hw550_outputs/similarities_10k\n",
    "OUTPUT_PATH = os.path.join(OUTPUT_PATH_BASE,'hw550_outputs/similarities_10k')\n",
    "!python similarity10k.py \\\n",
    "    -r hadoop hdfs:///user/jenncasper/hw550_outputs/index_10k \\\n",
    "    --output-dir={OUTPUT_PATH} \\\n",
    "    --no-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\r\n",
      "-rw-r--r--   3 jenncasper users          0 2017-10-13 06:01 /user/jenncasper/hw550_outputs/similarities_10k/_SUCCESS\r\n",
      "-rw-r--r--   3 jenncasper users      4.5 G 2017-10-13 06:01 /user/jenncasper/hw550_outputs/similarities_10k/part-00000\r\n"
     ]
    }
   ],
   "source": [
    "# check the output for the similarities test\n",
    "!hadoop fs -ls -h {OUTPUT_PATH}\n",
    "!hadoop fs -cat {OUTPUT_PATH}/* > similarities_sorted\n",
    "!head -20 similarities_sorted > similarities_sorted_top20\n",
    "!tail -20 similarities_sorted > similarities_sorted_bottom20\n",
    "!head -1000 similarities_sorted > similarities_sorted_top1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### similarity10k stats\n",
    "\n",
    "    Map input records=1000\n",
    "    Map output records=157512744\n",
    "    Reduce input records=157512744\n",
    "    Reduce output records=25453679\n",
    "    CPU time spent (ms)=22818760\n",
    "    Rack-local map tasks=2\n",
    "\tLaunched map tasks=2\n",
    "\tLaunched reduce tasks=1\n",
    "\tOther local map tasks=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# END STUDENT CODE 5.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top/Bottom 20 results - Similarity measures - sorted by cosine\n",
      "(From the entire data set)\n",
      "\n",
      "                          pair |         cosine |        jaccard |        overlap |           dice |        average\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "                     may - one |       0.950675 |       0.905433 |       0.975081 |       0.950370 |       0.945390\n",
      "                    one - time |       0.943432 |       0.891481 |       0.983221 |       0.942627 |       0.940190\n",
      "                    one - well |       0.932641 |       0.872233 |       0.974157 |       0.931757 |       0.927697\n",
      "                    may - well |       0.921278 |       0.853783 |       0.938202 |       0.921125 |       0.908597\n",
      "                   first - one |       0.915763 |       0.840932 |       0.981087 |       0.913594 |       0.912844\n",
      "                   one - would |       0.915162 |       0.839594 |       0.983353 |       0.912804 |       0.912728\n",
      "                    may - time |       0.908206 |       0.831653 |       0.922819 |       0.908090 |       0.892692\n",
      "                    one - part |       0.904548 |       0.821393 |       0.976019 |       0.901939 |       0.900975\n",
      "                  time - would |       0.896095 |       0.811065 |       0.923900 |       0.895677 |       0.881684\n",
      "                   may - would |       0.895526 |       0.809231 |       0.938169 |       0.894558 |       0.884371\n",
      "                    made - one |       0.893020 |       0.800607 |       0.978960 |       0.889264 |       0.890463\n",
      "                   time - well |       0.890137 |       0.802020 |       0.892135 |       0.890135 |       0.868607\n",
      "                   great - one |       0.890088 |       0.795132 |       0.981227 |       0.885876 |       0.888081\n",
      "                  first - time |       0.889994 |       0.801242 |       0.914894 |       0.889655 |       0.873946\n",
      "                    one - upon |       0.889555 |       0.794534 |       0.978803 |       0.885505 |       0.887099\n",
      "                   first - may |       0.883822 |       0.790486 |       0.923168 |       0.882985 |       0.870115\n",
      "                    may - part |       0.878760 |       0.781947 |       0.924460 |       0.877632 |       0.865700\n",
      "                    must - one |       0.875534 |       0.770010 |       0.979381 |       0.870063 |       0.873747\n",
      "                   part - well |       0.875172 |       0.777320 |       0.904077 |       0.874710 |       0.857820\n",
      "                  great - time |       0.874384 |       0.774633 |       0.924906 |       0.873006 |       0.861732\n",
      "\n",
      "          assembled - relation |       0.008145 |       0.002770 |       0.020833 |       0.005525 |       0.009318\n",
      "                 lay - therapy |       0.008137 |       0.003344 |       0.015625 |       0.006667 |       0.008443\n",
      "           fundamental - stood |       0.008128 |       0.003831 |       0.011628 |       0.007634 |       0.007805\n",
      "           concerning - inside |       0.008125 |       0.003984 |       0.010101 |       0.007937 |       0.007537\n",
      "            churches - prevent |       0.008098 |       0.003226 |       0.016393 |       0.006431 |       0.008537\n",
      "                got - multiple |       0.008091 |       0.003401 |       0.014925 |       0.006780 |       0.008299\n",
      "                 phase - stood |       0.008081 |       0.003817 |       0.011494 |       0.007605 |       0.007749\n",
      "           arrival - essential |       0.008056 |       0.004000 |       0.009346 |       0.007968 |       0.007343\n",
      "               five - sympathy |       0.008056 |       0.003378 |       0.014925 |       0.006734 |       0.008273\n",
      "                  layer - wife |       0.008040 |       0.003759 |       0.011765 |       0.007491 |       0.007764\n",
      "           love - proportional |       0.008019 |       0.002933 |       0.018519 |       0.005848 |       0.008829\n",
      "           population - window |       0.007946 |       0.003876 |       0.010101 |       0.007722 |       0.007411\n",
      "               suggests - went |       0.007937 |       0.002688 |       0.020408 |       0.005362 |       0.009099\n",
      "                related - stay |       0.007807 |       0.003610 |       0.011765 |       0.007194 |       0.007594\n",
      "          implications - round |       0.007797 |       0.003289 |       0.014286 |       0.006557 |       0.007982\n",
      "                  came - tumor |       0.007605 |       0.002033 |       0.026316 |       0.004057 |       0.010003\n",
      "                  ever - tumor |       0.007564 |       0.002012 |       0.026316 |       0.004016 |       0.009977\n",
      "                 let - therapy |       0.007511 |       0.002941 |       0.015625 |       0.005865 |       0.007985\n",
      "                cardiac - took |       0.007381 |       0.002252 |       0.021739 |       0.004494 |       0.008967\n",
      "               relation - snow |       0.006745 |       0.002611 |       0.014286 |       0.005208 |       0.007213\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "print \"\\nTop/Bottom 20 results - Similarity measures - sorted by cosine\"\n",
    "print \"(From the entire data set)\"\n",
    "print ''*117\n",
    "print \"{0:>30} |{1:>15} |{2:>15} |{3:>15} |{4:>15} |{5:>15}\".format(\n",
    "        \"pair\", \"cosine\", \"jaccard\", \"overlap\", \"dice\", \"average\")\n",
    "print '-'*117\n",
    "\n",
    "with open('similarities_sorted_top20', 'r') as f:\n",
    "    for line in f:\n",
    "        cosine, stripe = line.strip().split('\\t')\n",
    "        pair, avg, sim_dict = json.loads(stripe)\n",
    "        print \"{0:>30} |{1:>15f} |{2:>15f} |{3:>15f} |{4:>15f} |{5:>15f}\".format(pair, \n",
    "                                                                                 float(sim_dict['cosine']), \n",
    "                                                                                 float(sim_dict['jaccard']), \n",
    "                                                                                 float(sim_dict['overlap']), \n",
    "                                                                                 float(sim_dict['dice']), \n",
    "                                                                                 float(avg))\n",
    "        \n",
    "print ''*117\n",
    "\n",
    "with open('similarities_sorted_bottom20', 'r') as f:\n",
    "    for line in f:\n",
    "        cosine, stripe = line.strip().split('\\t')\n",
    "        pair, avg, sim_dict = json.loads(stripe)\n",
    "        print \"{0:>30} |{1:>15f} |{2:>15f} |{3:>15f} |{4:>15f} |{5:>15f}\".format(pair, \n",
    "                                                                                 float(sim_dict['cosine']), \n",
    "                                                                                 float(sim_dict['jaccard']), \n",
    "                                                                                 float(sim_dict['overlap']), \n",
    "                                                                                 float(sim_dict['dice']), \n",
    "                                                                                 float(avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 NOTES\n",
    "\n",
    "This was a hefty section that took a great deal of time and effort. If I grasped the req word and vocab concept and executed the 10K frequent words and 1K vocab correctly, the resulting pairs sorted by cosine differed from the example. Further time is needed to explore this as the pairs aren't particularly compelling. The NLTK stop words were used on the freq word list, but perhaps this was not enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Top/Bottom 20 results - Similarity measures - sorted by cosine\n",
    "(From the entire data set)\n",
    "\n",
    "                          pair |         cosine |        jaccard |        overlap |           dice |        average\n",
    "---------------------------------------------------------------------------------------------------------------------\n",
    "                   cons - pros |       0.894427 |       0.800000 |       1.000000 |       0.888889 |       0.895829\n",
    "            forties - twenties |       0.816497 |       0.666667 |       1.000000 |       0.800000 |       0.820791\n",
    "                    own - time |       0.809510 |       0.670563 |       0.921168 |       0.802799 |       0.801010\n",
    "                 little - time |       0.784197 |       0.630621 |       0.926101 |       0.773473 |       0.778598\n",
    "                  found - time |       0.783434 |       0.636364 |       0.883788 |       0.777778 |       0.770341\n",
    "                 nova - scotia |       0.774597 |       0.600000 |       1.000000 |       0.750000 |       0.781149\n",
    "                   hong - kong |       0.769800 |       0.615385 |       0.888889 |       0.761905 |       0.758995\n",
    "                   life - time |       0.769666 |       0.608789 |       0.925081 |       0.756829 |       0.765091\n",
    "                  time - world |       0.755476 |       0.585049 |       0.937500 |       0.738209 |       0.754058\n",
    "                  means - time |       0.752181 |       0.587117 |       0.902597 |       0.739854 |       0.745437\n",
    "                   form - time |       0.749943 |       0.588418 |       0.876733 |       0.740885 |       0.738995\n",
    "       infarction - myocardial |       0.748331 |       0.560000 |       1.000000 |       0.717949 |       0.756570\n",
    "                 people - time |       0.745788 |       0.573577 |       0.923875 |       0.729010 |       0.743063\n",
    "                 angeles - los |       0.745499 |       0.586207 |       0.850000 |       0.739130 |       0.730209\n",
    "                  little - own |       0.739343 |       0.585834 |       0.767296 |       0.738834 |       0.707827\n",
    "                    life - own |       0.737053 |       0.582217 |       0.778502 |       0.735951 |       0.708430\n",
    "          anterior - posterior |       0.733388 |       0.576471 |       0.790323 |       0.731343 |       0.707881\n",
    "                  power - time |       0.719611 |       0.533623 |       0.933586 |       0.695898 |       0.720680\n",
    "              dearly - install |       0.707107 |       0.500000 |       1.000000 |       0.666667 |       0.718443\n",
    "                   found - own |       0.704802 |       0.544134 |       0.710949 |       0.704776 |       0.666165\n",
    "\n",
    "           arrival - essential |       0.008258 |       0.004098 |       0.009615 |       0.008163 |       0.007534\n",
    "         governments - surface |       0.008251 |       0.003534 |       0.014706 |       0.007042 |       0.008383\n",
    "                king - lesions |       0.008178 |       0.003106 |       0.017857 |       0.006192 |       0.008833\n",
    "              clinical - stood |       0.008178 |       0.003831 |       0.011905 |       0.007634 |       0.007887\n",
    "               till - validity |       0.008172 |       0.003367 |       0.015625 |       0.006711 |       0.008469\n",
    "            evidence - started |       0.008159 |       0.003802 |       0.012048 |       0.007576 |       0.007896\n",
    "               forces - record |       0.008152 |       0.003876 |       0.011364 |       0.007722 |       0.007778\n",
    "               primary - stone |       0.008146 |       0.004065 |       0.009091 |       0.008097 |       0.007350\n",
    "             beneath - federal |       0.008134 |       0.004082 |       0.008403 |       0.008130 |       0.007187\n",
    "                factors - rose |       0.008113 |       0.004032 |       0.009346 |       0.008032 |       0.007381\n",
    "           evening - functions |       0.008069 |       0.004049 |       0.008333 |       0.008065 |       0.007129\n",
    "                   bone - told |       0.008061 |       0.003704 |       0.012346 |       0.007380 |       0.007873\n",
    "             building - occurs |       0.008002 |       0.003891 |       0.010309 |       0.007752 |       0.007489\n",
    "                 company - fig |       0.007913 |       0.003257 |       0.015152 |       0.006494 |       0.008204\n",
    "               chronic - north |       0.007803 |       0.003268 |       0.014493 |       0.006515 |       0.008020\n",
    "             evaluation - king |       0.007650 |       0.003030 |       0.015625 |       0.006042 |       0.008087\n",
    "             resulting - stood |       0.007650 |       0.003663 |       0.010417 |       0.007299 |       0.007257\n",
    "                 agent - round |       0.007515 |       0.003289 |       0.012821 |       0.006557 |       0.007546\n",
    "         afterwards - analysis |       0.007387 |       0.003521 |       0.010204 |       0.007018 |       0.007032\n",
    "            posterior - spirit |       0.007156 |       0.002660 |       0.016129 |       0.005305 |       0.007812"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  HW5.6  <a name=\"5.6\"></a> Evaluation of synonyms that your discovered (~3 hr)\n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "\n",
    "In this part of the assignment you will evaluate the success of you synonym detector (developed in response to HW5.4).\n",
    "Take the top 1,000 closest/most similar/correlative pairs of words as determined by your measure in HW5.4, and use the synonyms function in the accompanying python code:\n",
    "\n",
    "nltk_synonyms.py\n",
    "\n",
    "Note: This will require installing the python nltk package:\n",
    "\n",
    "http://www.nltk.org/install.html\n",
    "\n",
    "and downloading its data with nltk.download().\n",
    "\n",
    "For each (word1,word2) pair, check to see if word1 is in the list, \n",
    "synonyms(word2), and vice-versa. If one of the two is a synonym of the other, \n",
    "then consider this pair a 'hit', and then report the precision, recall, and F1 measure  of \n",
    "your detector across your 1,000 best guesses. Report the macro averages of these measures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Calculate performance measures:\n",
    "$$Precision (P) = \\frac{TP}{TP + FP} $$  \n",
    "$$Recall (R) = \\frac{TP}{TP + FN} $$  \n",
    "$$F1 = \\frac{2 * ( precision * recall )}{precision + recall}$$\n",
    "\n",
    "\n",
    "We calculate Precision by counting the number of hits and dividing by the number of occurances in our top1000 (opportunities)   \n",
    "We calculate Recall by counting the number of hits, and dividing by the number of synonyms in wordnet (syns)\n",
    "\n",
    "\n",
    "Other diagnostic measures not implemented here:  https://en.wikipedia.org/wiki/F1_score#Diagnostic_Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/jenncasper/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the nltk wordnet\n",
    "import nltk\n",
    "\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Hits: 9 out of top 1000\n",
      "Number of words without synonyms: 236\n",
      "\n",
      "Precision\t0.00385993574542\n",
      "Recall\t\t0.0187437502717\n",
      "F1\t\t0.00442760136946\n",
      "\n",
      "Words without synonyms:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[] would\n",
      "[] would\n",
      "[] would\n",
      "[] upon\n",
      "[] could\n",
      "[] would\n",
      "[] upon\n",
      "[] would\n",
      "[] would\n",
      "[] upon\n",
      "[] would\n",
      "[] could\n",
      "[] upon\n",
      "[] would\n",
      "[] would\n",
      "[] could\n",
      "[] upon\n",
      "[] upon\n",
      "[] could\n",
      "[] would\n",
      "[] would\n",
      "[] would\n",
      "[] would\n",
      "[] upon\n",
      "[] upon\n",
      "[] would\n",
      "[] could\n",
      "[] could\n",
      "[] would\n",
      "[] upon\n",
      "[] could\n",
      "[] could\n",
      "[] could\n",
      "[] without\n",
      "[] could\n",
      "[] would\n",
      "[] could\n",
      "[] upon\n",
      "[] hong\n",
      "[] kong\n",
      "[] without\n",
      "[] upon\n",
      "[] would\n",
      "[] would\n",
      "[] without\n",
      "[] would\n",
      "[] would\n",
      "[] upon\n",
      "[] upon\n",
      "[] would\n",
      "[] could\n",
      "[] would\n",
      "[] would\n",
      "[] could\n",
      "[] upon\n",
      "[] would\n",
      "[] could\n",
      "[] without\n",
      "[] could\n",
      "[] could\n",
      "[] would\n",
      "[] upon\n",
      "[] upon\n",
      "[] would\n",
      "[] would\n",
      "[] upon\n",
      "[] without\n",
      "[] would\n",
      "[] upon\n",
      "[] angeles\n",
      "[] los\n",
      "[] upon\n",
      "[] upon\n",
      "[] could\n",
      "[] would\n",
      "[] without\n",
      "[] upon\n",
      "[] upon\n",
      "[] upon\n",
      "[] without\n",
      "[] upon\n",
      "[] without\n",
      "[] could\n",
      "[] could\n",
      "[] without\n",
      "[] could\n",
      "[] upon\n",
      "[] upon\n",
      "[] without\n",
      "[] could\n",
      "[] upon\n",
      "[] could\n",
      "[] could\n",
      "[] upon\n",
      "[] could\n",
      "[] would\n",
      "[] would\n",
      "[] upon\n",
      "[] could\n",
      "[] could\n",
      "[] shall\n",
      "[] would\n",
      "[] could\n",
      "[] without\n",
      "[] without\n",
      "[] francisco\n",
      "[] san\n",
      "[] would\n",
      "[] could\n",
      "[] would\n",
      "[] shall\n",
      "[] upon\n",
      "[] would\n",
      "[] would\n",
      "[] would\n",
      "[] shall\n",
      "[] upon\n",
      "[] would\n",
      "[] shall\n",
      "[] would\n",
      "[] per\n",
      "[] without\n",
      "[] would\n",
      "[] would\n",
      "[] upon\n",
      "[] upon\n",
      "[] could\n",
      "[] would\n",
      "[] shall\n",
      "[] could\n",
      "[] would\n",
      "[] could\n",
      "[] would\n",
      "[] would\n",
      "[] without\n",
      "[] upon\n",
      "[] upon\n",
      "[] without\n",
      "[] could\n",
      "[] would\n",
      "[] without\n",
      "[] would\n",
      "[] among\n",
      "[] without\n",
      "[] would\n",
      "[] could\n",
      "[] shall\n",
      "[] would\n",
      "[] upon\n",
      "[] without\n",
      "[] could\n",
      "[] would\n",
      "[] shall\n",
      "[] shall\n",
      "[] upon\n",
      "[] shall\n",
      "[] upon\n",
      "[] upon\n",
      "[] would\n",
      "[] without\n",
      "[] would\n",
      "[] without\n",
      "[] without\n",
      "[] upon\n",
      "[] would\n",
      "[] upon\n",
      "[] without\n",
      "[] shall\n",
      "[] could\n",
      "[] could\n",
      "[] upon\n",
      "[] shall\n",
      "[] could\n",
      "[] upon\n",
      "[] would\n",
      "[] upon\n",
      "[] shall\n",
      "[] shall\n",
      "[] could\n",
      "[] upon\n",
      "[] upon\n",
      "[] could\n",
      "[] shall\n",
      "[] without\n",
      "[] would\n",
      "[] could\n",
      "[] upon\n",
      "[] upon\n",
      "[] could\n",
      "[] would\n",
      "[] would\n",
      "[] among\n",
      "[] could\n",
      "[] among\n",
      "[] would\n",
      "[] upon\n",
      "[] without\n",
      "[] among\n",
      "[] upon\n",
      "[] upon\n",
      "[] upon\n",
      "[] would\n",
      "[] among\n",
      "[] without\n",
      "[] could\n",
      "[] would\n",
      "[] upon\n",
      "[] among\n",
      "[] without\n",
      "[] would\n",
      "[] would\n",
      "[] among\n",
      "[] upon\n",
      "[] could\n",
      "[] without\n",
      "[] shall\n",
      "[] would\n",
      "[] could\n",
      "[] without\n",
      "[] would\n",
      "[] could\n",
      "[] upon\n",
      "[] would\n",
      "[] could\n",
      "[] would\n",
      "[] could\n",
      "[] would\n",
      "[] upon\n",
      "[] would\n",
      "[] would\n",
      "[] upon\n",
      "[] could\n",
      "[] shall\n",
      "[] upon\n",
      "[] upon\n",
      "[] would\n"
     ]
    }
   ],
   "source": [
    "''' Performance measures '''\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import json\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "import sys\n",
    "\n",
    "#print all the synset element of an element\n",
    "def synonyms(string):\n",
    "    syndict = {}\n",
    "    for i,j in enumerate(wn.synsets(string)):\n",
    "        syns = j.lemma_names()\n",
    "        for syn in syns:\n",
    "            syndict.setdefault(syn,1)\n",
    "    return syndict.keys()\n",
    "\n",
    "hits = []\n",
    "\n",
    "TP = 0\n",
    "FP = 0\n",
    "\n",
    "TOTAL = 0\n",
    "flag = False # so we don't double count, but at the same time don't miss hits\n",
    "\n",
    "top1000sims = []\n",
    "with open(\"similarities_sorted_top1000\",\"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        cosine, stripe = line.strip().split('\\t')\n",
    "        pair, avg, sim_dict = json.loads(stripe)\n",
    "        lisst = [pair, avg]\n",
    "        top1000sims.append(lisst)\n",
    "\n",
    "        #line = line.strip()\n",
    "        #avg,lisst = line.split(\"\\t\")\n",
    "        #lisst = json.loads(lisst)\n",
    "        #lisst.append(avg)\n",
    "        #top1000sims.append(lisst)\n",
    "\n",
    "measures = {}\n",
    "not_in_wordnet = []\n",
    "\n",
    "for line in top1000sims:\n",
    "    TOTAL += 1\n",
    "\n",
    "    pair = line[0]\n",
    "    words = pair.split(\" - \")\n",
    "    #print words\n",
    "    for word in words:\n",
    "        if word not in measures:\n",
    "            measures[word] = {\"syns\":0,\"opps\": 0,\"hits\":0}\n",
    "        measures[word][\"opps\"] += 1 \n",
    "    \n",
    "    syns0 = synonyms(words[0])\n",
    "    measures[words[1]][\"syns\"] = len(syns0)\n",
    "    if len(syns0) == 0:\n",
    "        not_in_wordnet.append(words[0])\n",
    "        \n",
    "    if words[1] in syns0:\n",
    "        TP += 1\n",
    "        hits.append(line)\n",
    "        flag = True\n",
    "        measures[words[1]][\"hits\"] += 1\n",
    "        \n",
    "    syns1 = synonyms(words[1]) \n",
    "    measures[words[0]][\"syns\"] = len(syns1)\n",
    "    if len(syns1) == 0:\n",
    "        not_in_wordnet.append(words[1])\n",
    "\n",
    "    if words[0] in syns1:\n",
    "        if flag == False:\n",
    "            TP += 1\n",
    "            hits.append(line)\n",
    "            measures[words[0]][\"hits\"] += 1\n",
    "            \n",
    "    flag = False    \n",
    "\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "\n",
    "for key in measures:\n",
    "    p,r,f = 0,0,0\n",
    "    if measures[key][\"hits\"] > 0 and measures[key][\"syns\"] > 0:\n",
    "        p = measures[key][\"hits\"]/measures[key][\"opps\"]\n",
    "        r = measures[key][\"hits\"]/measures[key][\"syns\"]\n",
    "        f = 2 * (p*r)/(p+r)\n",
    "    \n",
    "    # For calculating measures, only take into account words that have synonyms in wordnet\n",
    "    if measures[key][\"syns\"] > 0:\n",
    "        precision.append(p)\n",
    "        recall.append(r)\n",
    "        f1.append(f)\n",
    "\n",
    "    \n",
    "# Take the mean of each measure    \n",
    "print \"\"*110    \n",
    "print \"Number of Hits:\",TP, \"out of top\",TOTAL\n",
    "print \"Number of words without synonyms:\",len(not_in_wordnet)\n",
    "print \"\"*110 \n",
    "print \"Precision\\t\", np.mean(precision)\n",
    "print \"Recall\\t\\t\", np.mean(recall)\n",
    "print \"F1\\t\\t\", np.mean(f1)\n",
    "print \"\"*110  \n",
    "\n",
    "print \"Words without synonyms:\"\n",
    "print \"-\"*100\n",
    "\n",
    "for word in not_in_wordnet:\n",
    "    print synonyms(word),word\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 NOTES\n",
    "\n",
    "The popular pairs resulting from the 10K most frequent words with the 1K vocabulary were still relatively common words which resulted in pairs that weren't particularly interesting. I would go back and adjust the frequent word constraints, as discussed in the sync slides, to see how to get a better fi for this data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "Number of Hits: 31 out of top 1000\n",
    "Number of words without synonyms: 67\n",
    "\n",
    "Precision\t0.0280214404967\n",
    "Recall\t\t0.0178598869579\n",
    "F1\t\t0.013965517619\n",
    "\n",
    "Words without synonyms:\n",
    "----------------------------------------------------------------------------------------------------\n",
    "[] scotia\n",
    "[] hong\n",
    "[] kong\n",
    "[] angeles\n",
    "[] los\n",
    "[] nor\n",
    "[] themselves\n",
    "[] \n",
    "......."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  HW5.7  <a name=\"5.7\"></a> OPTIONAL: using different vocabulary subsets\n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "\n",
    "Repeat HW5 using vocabulary words ranked from 8001,-10,000;  7001,-10,000; 6001,-10,000; 5001,-10,000; 3001,-10,000; and 1001,-10,000;\n",
    "Dont forget to report you Cluster configuration.\n",
    "\n",
    "Generate the following graphs:\n",
    "-- vocabulary size (X-Axis) versus CPU time for indexing\n",
    "-- vocabulary size (X-Axis) versus number of pairs processed\n",
    "-- vocabulary size (X-Axis) versus F1 measure, Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  HW5.8  <a name=\"5.8\"></a> OPTIONAL: filter stopwords\n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "There is also a corpus of stopwords, that is, high-frequency words like \"the\", \"to\" and \"also\" that we sometimes want to filter out of a document before further processing. Stopwords usually have little lexical content, and their presence in a text fails to distinguish it from other texts. Python's nltk comes with a prebuilt list of stopwords (see below). Using this stopword list filter out these tokens from your analysis and rerun the experiments in 5.5 and disucuss the results of using a stopword list and without using a stopword list.\n",
    "\n",
    "> from nltk.corpus import stopwords\n",
    ">> stopwords.words('english')\n",
    "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours',\n",
    "'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers',\n",
    "'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves',\n",
    "'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are',\n",
    "'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does',\n",
    "'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until',\n",
    "'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into',\n",
    "'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down',\n",
    "'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here',\n",
    "'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\n",
    "'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so',\n",
    "'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  HW5.9 <a name=\"5.9\"></a> OPTIONAL \n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "There are many good ways to build our synonym detectors, so for this optional homework, \n",
    "measure co-occurrence by (left/right/all) consecutive words only, \n",
    "or make stripes according to word co-occurrences with the accompanying \n",
    "2-, 3-, or 4-grams (note here that your output will no longer \n",
    "be interpretable as a network) inside of the 5-grams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  HW5.10 <a name=\"5.10\"></a> OPTIONAL \n",
    "[Back to Table of Contents](#TOC)\n",
    "\n",
    "Once again, benchmark your top 10,000 associations (as in 5.5), this time for your\n",
    "results from 5.6. Has your detector improved?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "toc": {
   "nav_menu": {
    "height": "511px",
    "width": "251px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
